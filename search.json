[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/16BHW3/index.html",
    "href": "posts/16BHW3/index.html",
    "title": "PIC16B HW3",
    "section": "",
    "text": "In this tutorial, we are going to build a simple message bank with flask fundamentals, database skills, and basic CSS. The app we build should be able to:  1&gt; Allow the user to submit messages to the bank  2&gt; Allow the viewer to view a sample of the messages currently stored in the bank\n\n\n\n\n\nLet’s start with creating a collection of html files in our project folder templates  Template Reference: mnist demo & simple form demo View my html files folder: myhtmls 1&gt; base.html  This file should exhibit a header of the website “A Simple Message Bank” with two navigation links to message submission and viewing 2&gt; submit.html (should extend) base.html  This file should contain: 1) Two text boxes for user input 2) “Submit” button to submit the message to the message bank  3&gt; view.html (should extend) base.html  This file should contain a board that exhibits messages randomly selected for viewing  4&gt; hello.html (should extend) base.html  This file contains a greeting page to users\nNow we need to create a app.py file to write some codes:\n\n\nThis function creates the database of messages messages_db, a table messages, and return the connection g.message.db\n\n# Database connection\ndef get_message_db():\n    try:\n        return g.message_db\n    except AttributeError:\n        # Connect to the database message_db, ensuring the connection is an attribute of g.\n        g.message_db = sqlite3.connect(\"messages_db.sqlite\")\n        # This SQL Command is to first check whether a table called messages exists in the created database\n        # And then it creates a table which includes two text columns (handle and message)\n        cmd = '''\n        CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            handle TEXT NOT NULL,\n            message TEXT NOT NULL\n        )\n        '''\n        cursor = g.message_db.cursor()\n        cursor.execute(cmd)\n        g.message_db.commit()\n        # Return the connection g.message_db\n        return g.message_db\n\n\n\n\nThis function handles inserting a user messgae into the dabase of messages\n\n# Insert values into database\ndef insert_message(request):\n    #This SQL command insert both handle and message into two corresponding columns in the table\n    cmd = 'INSERT INTO messages (handle, message) VALUES (?, ?)'\n    #Here I specify the column name of handle as \"name\"\n    handle = request.form[\"name\"]\n    message = request.form[\"message\"]\n    db = get_message_db()\n    #Using cursor to insert the message into message database\n    cursor = db.cursor()\n    #We need provide the handle, the message itself.\n    cursor.execute(cmd, (handle, message))\n    #When working directly with SQL commands, it's neccessary to run db.commit() after inserting a row into db\n    #This is to ensure row insertion has been saved\n    g.message_db.commit()\n    \n\n\n\n\nThis function ensure transmit and receive data, supporting both POST and GET methods\n\n# Submit message route\n# 'POST' and 'GET' splites two returned pages. Ensure the page both transmit and receive data.\n@app.route('/submit', methods=['POST', 'GET'])\n\ndef submit():\n    # In POST case, call insert_message () and if it runs successfuly, render with a \"Thank you\" note\n    if request.method == 'POST':\n        insert_message(request)\n        flash('Thank you for your submission!')\n        return redirect(url_for('view'))\n    else:\n        return render_template('submit.html')\n\n\n\n\n\n\n\nThis function should returns to a collection of n random messages from the database\n\ndef random_messages(n):\n    db_connection = get_message_db()\n    # The cursor is used to execute SQL command and process with returned results\n    cursor = db_connection.cursor()\n    # In this SQL command, 'ORDER BY RANDOM' ensures the result is random, and 'LIMIT' ensures a predefined n number of returned messages\n    cmd = 'SELECT handle, message FROM messages ORDER BY RANDOM() LIMIT ?;'\n    # fetchall() is to get all matched records\n    result = cursor.execute(cmd, (n,)).fetchall()\n    return result \n#This function should return a result of a list, each contains handle and message\n\n\n\n\nThis function first call random_mesages to grab some random messages and pass these messages as an argument to render_template\n\ndef view():\n    #The function returns 5 rows of handle and message\n    result = random_messages(5)\n    # message=results passes the randome messages obtained from the database to the template\n    return render_template('view.html',messages=result)\n\n\n\n\n\n\n# Home route: Directs to the main page. Renders 'hello.html'\n#def main():\n@app.route('/')\ndef home():\n    return render_template('hello.html')\n\n# Hello route: Directs to a page using the '/hello' URL. Also renders \"hello.html\"\n@app.route('/hello')\ndef hello():\n    return render_template('hello.html')\n\n# Submit message route: Handles from submissions\n# On POST, it processes and inserts the message, then redirects to the 'view' route. \n# On GET, it shows the submission form by rendering 'submit.html'.\n@app.route('/submit', methods=['POST', 'GET'])\ndef submit():\n    if request.method == 'POST':\n        insert_message(request)\n        flash('Thank you for your submission!')\n        return redirect(url_for('view'))\n    else:\n        return render_template('submit.html')\n\n# View Route: Displays a list of messages by fetching a predefined number (e.g., 5) of random messages and rendering them on 'view.html'.    \n@app.route('/view')\ndef view():\n    result = random_messages(5)\n    return render_template('view.html',messages=result)\n\n# Random Message Route: Similar to the view route, show a varying set of 5 random messages each time the '/random' URL is accessed. \n# Renders 'random.html' with the messages.\n@app.route('/random')\ndef show_random_messages():\n    messages = random_messages(5)  # Fetch 5 random messages\n    return render_template('random.html', messages=messages)\n\n\n\n\n\n\nNote: please view the complete collection of html files here: myhtmls Today we only discuss how base.html is designed\n\n\n\nScreen Shot 2024-02-14 at 10.55.41 PM.png\n\n\n\n&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&lt;!-- Linking external CSS from the 'static' folder for styling --&gt;\n  &lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\"&gt;\n  &lt;style&gt;\n    /* Inline CSS for basic styling */\n    body {\n      font-family: Arial, sans-serif; /* Setting the font style */\n      background-color: #f4f4f4; /* Grey background */\n      margin: 0; /* Remove default margin */\n      padding: 0; \n    }\n    nav {\n      background-color: #333; /* Dark background for nav */\n      color: white; /* White text color */\n      padding: 10px; /* Padding around nav content */\n    nav ul {\n      padding: 0;\n      list-style: none; /* No bullet points for list */\n    }\n    nav ul li {\n      display: inline; /* Inline display for list items */\n      margin-right: 10px; /* Space between navigation items */\n    }\n    nav a {\n      color: white;\n      text-decoration: none;\n    }\n    .content {\n      margin: 15px; /* Margin around the content section */\n    }\n  &lt;/style&gt;\n  &lt;!-- Dynamic title with a fallback/static part \" - PIC16B Website\" --&gt;\n  &lt;title&gt;{% block title %}{% endblock %} - PIC16B Website&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;!-- Navigation bar --&gt;\n  &lt;nav&gt;\n    &lt;h1&gt;A Simple Message Bank&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;!-- Navigation links to different routes/pages --&gt;\n      &lt;li&gt;&lt;a href=\"{{ url_for('submit') }}\"&gt;Submit a message&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\"{{ url_for('view')}}\"&gt;View messages&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/nav&gt;\n &lt;!-- Main content section --&gt;\n  &lt;section class=\"content\"&gt;\n    &lt;header&gt;\n      &lt;!-- Placeholder for header content, can be overridden in child templates --&gt;\n      {% block header %}{% endblock %}\n    &lt;/header&gt;\n    {% block content %}{% endblock %}\n  &lt;/section&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\n\n\nScreen Shot 2024-02-14 at 11.11.05 PM.png\n\n\n\n\n\nScreen Shot 2024-02-14 at 11.27.36 PM.png"
  },
  {
    "objectID": "posts/16BHW3/index.html#instructions-a-step-by-step-guide",
    "href": "posts/16BHW3/index.html#instructions-a-step-by-step-guide",
    "title": "PIC16B HW3",
    "section": "",
    "text": "Let’s start with creating a collection of html files in our project folder templates  Template Reference: mnist demo & simple form demo View my html files folder: myhtmls 1&gt; base.html  This file should exhibit a header of the website “A Simple Message Bank” with two navigation links to message submission and viewing 2&gt; submit.html (should extend) base.html  This file should contain: 1) Two text boxes for user input 2) “Submit” button to submit the message to the message bank  3&gt; view.html (should extend) base.html  This file should contain a board that exhibits messages randomly selected for viewing  4&gt; hello.html (should extend) base.html  This file contains a greeting page to users\nNow we need to create a app.py file to write some codes:\n\n\nThis function creates the database of messages messages_db, a table messages, and return the connection g.message.db\n\n# Database connection\ndef get_message_db():\n    try:\n        return g.message_db\n    except AttributeError:\n        # Connect to the database message_db, ensuring the connection is an attribute of g.\n        g.message_db = sqlite3.connect(\"messages_db.sqlite\")\n        # This SQL Command is to first check whether a table called messages exists in the created database\n        # And then it creates a table which includes two text columns (handle and message)\n        cmd = '''\n        CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            handle TEXT NOT NULL,\n            message TEXT NOT NULL\n        )\n        '''\n        cursor = g.message_db.cursor()\n        cursor.execute(cmd)\n        g.message_db.commit()\n        # Return the connection g.message_db\n        return g.message_db\n\n\n\n\nThis function handles inserting a user messgae into the dabase of messages\n\n# Insert values into database\ndef insert_message(request):\n    #This SQL command insert both handle and message into two corresponding columns in the table\n    cmd = 'INSERT INTO messages (handle, message) VALUES (?, ?)'\n    #Here I specify the column name of handle as \"name\"\n    handle = request.form[\"name\"]\n    message = request.form[\"message\"]\n    db = get_message_db()\n    #Using cursor to insert the message into message database\n    cursor = db.cursor()\n    #We need provide the handle, the message itself.\n    cursor.execute(cmd, (handle, message))\n    #When working directly with SQL commands, it's neccessary to run db.commit() after inserting a row into db\n    #This is to ensure row insertion has been saved\n    g.message_db.commit()\n    \n\n\n\n\nThis function ensure transmit and receive data, supporting both POST and GET methods\n\n# Submit message route\n# 'POST' and 'GET' splites two returned pages. Ensure the page both transmit and receive data.\n@app.route('/submit', methods=['POST', 'GET'])\n\ndef submit():\n    # In POST case, call insert_message () and if it runs successfuly, render with a \"Thank you\" note\n    if request.method == 'POST':\n        insert_message(request)\n        flash('Thank you for your submission!')\n        return redirect(url_for('view'))\n    else:\n        return render_template('submit.html')\n\n\n\n\n\n\n\nThis function should returns to a collection of n random messages from the database\n\ndef random_messages(n):\n    db_connection = get_message_db()\n    # The cursor is used to execute SQL command and process with returned results\n    cursor = db_connection.cursor()\n    # In this SQL command, 'ORDER BY RANDOM' ensures the result is random, and 'LIMIT' ensures a predefined n number of returned messages\n    cmd = 'SELECT handle, message FROM messages ORDER BY RANDOM() LIMIT ?;'\n    # fetchall() is to get all matched records\n    result = cursor.execute(cmd, (n,)).fetchall()\n    return result \n#This function should return a result of a list, each contains handle and message\n\n\n\n\nThis function first call random_mesages to grab some random messages and pass these messages as an argument to render_template\n\ndef view():\n    #The function returns 5 rows of handle and message\n    result = random_messages(5)\n    # message=results passes the randome messages obtained from the database to the template\n    return render_template('view.html',messages=result)\n\n\n\n\n\n\n# Home route: Directs to the main page. Renders 'hello.html'\n#def main():\n@app.route('/')\ndef home():\n    return render_template('hello.html')\n\n# Hello route: Directs to a page using the '/hello' URL. Also renders \"hello.html\"\n@app.route('/hello')\ndef hello():\n    return render_template('hello.html')\n\n# Submit message route: Handles from submissions\n# On POST, it processes and inserts the message, then redirects to the 'view' route. \n# On GET, it shows the submission form by rendering 'submit.html'.\n@app.route('/submit', methods=['POST', 'GET'])\ndef submit():\n    if request.method == 'POST':\n        insert_message(request)\n        flash('Thank you for your submission!')\n        return redirect(url_for('view'))\n    else:\n        return render_template('submit.html')\n\n# View Route: Displays a list of messages by fetching a predefined number (e.g., 5) of random messages and rendering them on 'view.html'.    \n@app.route('/view')\ndef view():\n    result = random_messages(5)\n    return render_template('view.html',messages=result)\n\n# Random Message Route: Similar to the view route, show a varying set of 5 random messages each time the '/random' URL is accessed. \n# Renders 'random.html' with the messages.\n@app.route('/random')\ndef show_random_messages():\n    messages = random_messages(5)  # Fetch 5 random messages\n    return render_template('random.html', messages=messages)\n\n\n\n\n\n\nNote: please view the complete collection of html files here: myhtmls Today we only discuss how base.html is designed\n\n\n\nScreen Shot 2024-02-14 at 10.55.41 PM.png\n\n\n\n&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&lt;!-- Linking external CSS from the 'static' folder for styling --&gt;\n  &lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\"&gt;\n  &lt;style&gt;\n    /* Inline CSS for basic styling */\n    body {\n      font-family: Arial, sans-serif; /* Setting the font style */\n      background-color: #f4f4f4; /* Grey background */\n      margin: 0; /* Remove default margin */\n      padding: 0; \n    }\n    nav {\n      background-color: #333; /* Dark background for nav */\n      color: white; /* White text color */\n      padding: 10px; /* Padding around nav content */\n    nav ul {\n      padding: 0;\n      list-style: none; /* No bullet points for list */\n    }\n    nav ul li {\n      display: inline; /* Inline display for list items */\n      margin-right: 10px; /* Space between navigation items */\n    }\n    nav a {\n      color: white;\n      text-decoration: none;\n    }\n    .content {\n      margin: 15px; /* Margin around the content section */\n    }\n  &lt;/style&gt;\n  &lt;!-- Dynamic title with a fallback/static part \" - PIC16B Website\" --&gt;\n  &lt;title&gt;{% block title %}{% endblock %} - PIC16B Website&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;!-- Navigation bar --&gt;\n  &lt;nav&gt;\n    &lt;h1&gt;A Simple Message Bank&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;!-- Navigation links to different routes/pages --&gt;\n      &lt;li&gt;&lt;a href=\"{{ url_for('submit') }}\"&gt;Submit a message&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\"{{ url_for('view')}}\"&gt;View messages&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/nav&gt;\n &lt;!-- Main content section --&gt;\n  &lt;section class=\"content\"&gt;\n    &lt;header&gt;\n      &lt;!-- Placeholder for header content, can be overridden in child templates --&gt;\n      {% block header %}{% endblock %}\n    &lt;/header&gt;\n    {% block content %}{% endblock %}\n  &lt;/section&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\n\n\nScreen Shot 2024-02-14 at 11.11.05 PM.png\n\n\n\n\n\nScreen Shot 2024-02-14 at 11.27.36 PM.png"
  },
  {
    "objectID": "posts/16BHW5/index.html",
    "href": "posts/16BHW5/index.html",
    "title": "PIC16B HW5",
    "section": "",
    "text": "Tutorial 5: Image Classification in Keras through Tensorflow Datasets\nThis blog tutorial will present different approaches to conduct image classification in Keras with data fed through Tensorflow Datasets.\n\n\nBackground Knowledge:\n· Keras: Keras 3 functions as an independent library capable of interfacing with various computational backends, including TensorFlow, PyTorch, and JAX, offering flexibility in choosing the underlying framework for deep learning projects.\n· TensorFlow Datasets: This feature offers a streamlined approach to managing datasets for training, validation, and testing purposes, enhancing the efficiency of data handling in machine learning workflows.\n· Data augmentation: Through data augmentation, we can generate additional variations of our dataset, enhancing the model’s ability to learn and generalize from diverse patterns more effectively.\n· Transfer learning: Transfer learning uses the knowledge gained from previously trained models to tackle new, related problems, saving time and computational resources during model development.\n\n\nInstructions:\n1.Load Packages and Obtain Data\nWe firstly include a block that includes all import statements with a brief introduction of their implications:\n\nimport os # 'os' allows interaction wth the operation system\nos.environ[\"KERAS_BACKEND\"] = \"torch\"\n\nfrom keras import utils # 'utils' contains utilities for data processing and sequence propocessing\nimport tensorflow_datasets as tfds # TFDS library is a collection of dataset to use with TensorFlow\nimport matplotlib.pyplot as plt # 'pyplot' in 'matplotlib' library creates data visualization\nimport numpy as np # 'numpy' supports mathematical operations\n\nfrom random import randint # 'randit' generates randome integers with a specified range\n\nimport keras # 'keras' supports deep neural networks experimentation\nfrom keras import layers # 'layers' is building blocks of networks in Keras, contains functions like 'Dense', 'Conv2D', etc.\n\nBy utilizing Kaggle, we gain access to a dataset featuring labeled images of cats and dogs. By executing the code below, we successfully establish datasets designated for training, validation, and testing purposes.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\nWe use the following code to resize all different sized images in datasets to a fixed size of 150x150\n\nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\n\nThe next block uses batch_size to determine “how many data points are gathered from the directory”:\n\nfrom tensorflow import data as tf_data\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nWe now write a function to create two-row visualization with one row of cats and one row of dogs\n\nclass_names = ['cat', 'dog']\n\ndef visualize(ds):\n  plt.figure(figsize=(10, 10)) #figure size\n  for images, labels in ds.take(1):  # Take one batch at this step\n        cat_count = 0\n        dog_count = 0\n        while cat_count &lt; 3 or dog_count &lt; 3:\n            i = randint(0, 63)  # We before set batch size to 64\n            if cat_count &lt; 3 and labels[i] == 0:  # If we need more cats and found one\n                ax = plt.subplot(2, 3, cat_count + 1) # plot the cat image\n                plt.imshow(images[i].numpy().astype(\"uint8\")) # show the image\n                plt.title(class_names[labels[i]]) # set the title of images\n                cat_count += 1 # increment the cat counter\n            elif dog_count &lt; 3 and labels[i] == 1:  # If we need more dogs and found one\n                ax = plt.subplot(2, 3, dog_count + 4)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(class_names[labels[i]])\n                dog_count += 1\n            if cat_count == 3 and dog_count == 3:\n                break  # Exit once 3 cats and 3 dogs have been displayed\n  plt.tight_layout() # adjust layout\n  plt.show()\n\nvisualize(train_ds)# Update the function call\n\n\n\n\n\n\n\n\nThe following code will create an iterator called labels_iterator:\nlabels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\nWe will compute the number of image in the training set with label 0 (“cat”) and label 1 (“dog”). In the baseline machine learning model, we will examine how accurate it works in our case. Baseline model will be our benchmark for improvement.\n\nlabels_iterator = train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\n# Initialize counters for each label\nlabel_0_cat = 0\nlabel_1_dog = 0\n\nfor label in labels_iterator: # iterate through the labels_iterator to count labels\n    if label == 0:\n        label_0_cat += 1 # add counts\n    elif label == 1:\n        label_1_dog += 1\n\nprint(f\"Number of 'cat' images (label 0): {label_0_cat}\")\nprint(f\"Number of 'dog' images (label 1): {label_1_dog}\")\n\nNumber of 'cat' images (label 0): 4637\nNumber of 'dog' images (label 1): 4668\n\n\n4668 &gt; 4637, the baseline accuracy is calculated by “the most frequent label”/ “total label”; In this case, it is calculated by dog/(dog+cat)\n\nprint(\"The baseline accuracy is\", label_1_dog/(label_1_dog+label_0_cat))\n\nThe baseline accuracy is 0.5016657710908113\n\n\n2. Model 1\n“The simplest way to make a model is by using the keras.models.Sequential API, which allows you to construct a model by simply passing a list of layers.”\nLet’s start to construct model 1 (a keras.Sequential model) using at least two Conv2D layers, at least two MaxPooling2D layers, at least one Flatten layer, at least one Dense layer, and at least one Dropout layer.\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\"\"\"\nConv2D layer: creates convolution kernal, produces a tensor of outputs\nMaxPooling 2D layer: reduces the dimensionality of the featured maps\nFlatten layer: Converts 2D feature maps into 1D feature vector\nDropout layer: reduces overfitting by dropping a portion of the input\nDense layer: performs classification based on processed previous layers\nReLu: applied element-wise, directly output positive numbers, if negative, output zero,\n\"\"\"\nmodel1 = keras.models.Sequential([\n    # define shape:\n    layers.Input((150,150,3)), #the shape indicates the model input images 150 pixesl in height, 150 pixels in width, 3 channels (RGB color channels)\n    layers.Dropout(0.3), # randomly drop out 30% of the input\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    #learning a total of 32 filters\n    layers.MaxPooling2D((2, 2)),\n    #use Max Pooling to reduce the spatial dimensions of the output volume\n    layers.Conv2D(64, (3, 3), activation='relu'), #relu: recitified linear unit\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(), #flattens the input, makes the multidimensional input 1D\n    layers.Dense(64, activation='relu'),\n    layers.Dense(64, activation='sigmoid') # sigmoid for the cat/dog binary classification\n\n])\nmodel1.summary()\n\nModel: \"sequential_39\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dropout_33 (Dropout)        (None, 150, 150, 3)       0         \n                                                                 \n conv2d_70 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_64 (MaxPooli  (None, 74, 74, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_71 (Conv2D)          (None, 72, 72, 64)        18496     \n                                                                 \n max_pooling2d_65 (MaxPooli  (None, 36, 36, 64)        0         \n ng2D)                                                           \n                                                                 \n flatten_39 (Flatten)        (None, 82944)             0         \n                                                                 \n dense_72 (Dense)            (None, 64)                5308480   \n                                                                 \n dense_73 (Dense)            (None, 64)                4160      \n                                                                 \n=================================================================\nTotal params: 5332032 (20.34 MB)\nTrainable params: 5332032 (20.34 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nWe first complile the model and then train the model\n\nmodel1.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nhistory = model1.fit(train_ds, epochs=20, validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 16s 75ms/step - loss: 15.2972 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5821\nEpoch 2/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.7036 - accuracy: 0.6230 - val_loss: 0.6735 - val_accuracy: 0.5997\nEpoch 3/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5900 - accuracy: 0.6874 - val_loss: 0.7037 - val_accuracy: 0.5924\nEpoch 4/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5278 - accuracy: 0.7368 - val_loss: 0.7068 - val_accuracy: 0.6135\nEpoch 5/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.4638 - accuracy: 0.7823 - val_loss: 0.7622 - val_accuracy: 0.6144\nEpoch 6/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.4135 - accuracy: 0.8124 - val_loss: 0.8646 - val_accuracy: 0.6045\nEpoch 7/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.4326 - accuracy: 0.8048 - val_loss: 0.9029 - val_accuracy: 0.6230\nEpoch 8/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.4031 - accuracy: 0.8211 - val_loss: 0.8811 - val_accuracy: 0.6333\nEpoch 9/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.3462 - accuracy: 0.8520 - val_loss: 0.9374 - val_accuracy: 0.6148\nEpoch 10/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.3159 - accuracy: 0.8674 - val_loss: 0.9894 - val_accuracy: 0.6118\nEpoch 11/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.2923 - accuracy: 0.8792 - val_loss: 1.1118 - val_accuracy: 0.6156\nEpoch 12/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2548 - accuracy: 0.8966 - val_loss: 1.2389 - val_accuracy: 0.6208\nEpoch 13/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.2217 - accuracy: 0.9104 - val_loss: 1.1945 - val_accuracy: 0.6341\nEpoch 14/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.1966 - accuracy: 0.9164 - val_loss: 1.3416 - val_accuracy: 0.6367\nEpoch 15/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.1637 - accuracy: 0.9322 - val_loss: 1.4218 - val_accuracy: 0.6161\nEpoch 16/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.1591 - accuracy: 0.9382 - val_loss: 1.4969 - val_accuracy: 0.6225\nEpoch 17/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.1623 - accuracy: 0.9344 - val_loss: 1.4675 - val_accuracy: 0.6466\nEpoch 18/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.1283 - accuracy: 0.9515 - val_loss: 1.6020 - val_accuracy: 0.6410\nEpoch 19/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.1174 - accuracy: 0.9562 - val_loss: 1.6733 - val_accuracy: 0.6260\nEpoch 20/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.1317 - accuracy: 0.9500 - val_loss: 1.6680 - val_accuracy: 0.6475\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n\n\n\n\n\n\n\nValidation Accuracy: The accuracy of my model stabilized between 59% and 64% during training.\nComparison to Baseline: Compare to the baseline accuracy 50%, there is a 10% improvement.\nOverfitting Observation: I observe an overfitting in model 1. This suggests the model 1 cannot fits too closely to the training dataset.\n3.Model 2: Model with Data Augmentation\nIn the model2, we’re incorporating layers that perform data augmentation. This technique involves adding altered versions of existing images to the training dataset. Even when an image is rotated/fliped to a certain degree, it remains itself. By including these rotated or “flipped” images in our training process, we aim to enable the model to identify and understand the “unchanging characteristics” of the input images\nStep 1: we first create a keras.layers.RandomFlip() layer, plotting the original image and some copies to show the application of RandomFlip()\n\n# Select an example from the training dataset\nfor images, _ in train_ds.take(1):\n    image = images[0]\n    break\n\n# Create a keras.layers.RandomFlip()layer\nrandom_flip = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")\n# flip radnomly in vertical and horizontal directions\n\n# flip randomly for serveral times and plot images\nplt.figure(figsize=(10, 2))  # set image size\nplt.subplot(1, 5, 1)  # original image\nplt.imshow(image.numpy().astype(\"uint8\"))\nplt.title(\"Original\")\nfor i in range(2, 6):  # flip four times\n    flipped_image = random_flip(image, training=True)\n    plt.subplot(1, 5, i)\n    plt.imshow(flipped_image.numpy().astype(\"uint8\"))\n    plt.title(f\"Flipped {i-1}\")  # plot flipped images with corresponding titles\nplt.show()\n\n\n\n\n\n\n\n\nStep 2: we then create keras.layers.RandomRotation layer. Then, we make a plot of both the original image and a few copies to which RandomRotation() has been applied.\n\n# create a keras.layers.RandomRotation, set random rotation factor as 0.24\nrandom_rotation = tf.keras.layers.RandomRotation(0.24)\n\nplt.figure(figsize=(10, 2))  # set size\nplt.subplot(1, 5, 1)\nplt.imshow(image.numpy().astype(\"uint8\"))\nplt.title(\"Original\")\nfor i in range(2, 6):  # rotates randomly four times\n    rotated_image = random_rotation(image, training=True)\n    plt.subplot(1, 5, i)\n    plt.imshow(rotated_image.numpy().astype(\"uint8\"))\n    plt.title(f\"Rotated {i-1}\")  # plot rotatated images\nplt.show()\n\n\n\n\n\n\n\n\nStep 3: we then create a new keras.models.Sequential model called model2 in which “the first two layers are augmentation layers” with the usage of a RandomFlip() layer and a RandomRotation() layer.\n\nmodel2 = keras.models.Sequential([\n    layers.Input((150,150,3)),\n    layers.RandomFlip(\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.24),\n    layers.Conv2D(32, (3, 3), activation='relu'),#learning a total of 32 filters\n    layers.MaxPooling2D((2, 2)),\n    #use Max Pooling to reduce the spatial dimensions of the output volume\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(), #flattens the input, makes the multidimensional input 1D\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.3), # randomly drop out 30% of the input\n    layers.Dense(64, activation='softmax') # normalize the outputs, convert from weighted sum values into probabilities that sum to one\n\n])\nmodel2.summary()\n\nModel: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_8 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_8 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n conv2d_18 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_18 (MaxPooli  (None, 74, 74, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_19 (Conv2D)          (None, 72, 72, 64)        18496     \n                                                                 \n max_pooling2d_19 (MaxPooli  (None, 36, 36, 64)        0         \n ng2D)                                                           \n                                                                 \n flatten_9 (Flatten)         (None, 82944)             0         \n                                                                 \n dense_18 (Dense)            (None, 64)                5308480   \n                                                                 \n dropout_9 (Dropout)         (None, 64)                0         \n                                                                 \n dense_19 (Dense)            (None, 64)                4160      \n                                                                 \n=================================================================\nTotal params: 5332032 (20.34 MB)\nTrainable params: 5332032 (20.34 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel2.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model2.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 7s 36ms/step - loss: 0.5868 - accuracy: 0.6992 - val_loss: 0.5566 - val_accuracy: 0.7184\nEpoch 2/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5708 - accuracy: 0.7112 - val_loss: 0.5493 - val_accuracy: 0.7244\nEpoch 3/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5708 - accuracy: 0.7065 - val_loss: 0.5606 - val_accuracy: 0.7240\nEpoch 4/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5692 - accuracy: 0.7074 - val_loss: 0.5529 - val_accuracy: 0.7214\nEpoch 5/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.5632 - accuracy: 0.7189 - val_loss: 0.5474 - val_accuracy: 0.7266\nEpoch 6/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5658 - accuracy: 0.7091 - val_loss: 0.5465 - val_accuracy: 0.7240\nEpoch 7/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5518 - accuracy: 0.7175 - val_loss: 0.5333 - val_accuracy: 0.7347\nEpoch 8/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5664 - accuracy: 0.7088 - val_loss: 0.5502 - val_accuracy: 0.7188\nEpoch 9/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5593 - accuracy: 0.7157 - val_loss: 0.5410 - val_accuracy: 0.7309\nEpoch 10/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5597 - accuracy: 0.7113 - val_loss: 0.5422 - val_accuracy: 0.7296\nEpoch 11/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5496 - accuracy: 0.7244 - val_loss: 0.5453 - val_accuracy: 0.7188\nEpoch 12/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5475 - accuracy: 0.7282 - val_loss: 0.5550 - val_accuracy: 0.7145\nEpoch 13/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5682 - accuracy: 0.7145 - val_loss: 0.5440 - val_accuracy: 0.7253\nEpoch 14/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5588 - accuracy: 0.7091 - val_loss: 0.5410 - val_accuracy: 0.7309\nEpoch 15/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5571 - accuracy: 0.7234 - val_loss: 0.5609 - val_accuracy: 0.7223\nEpoch 16/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5517 - accuracy: 0.7222 - val_loss: 0.5586 - val_accuracy: 0.7180\nEpoch 17/20\n146/146 [==============================] - 5s 33ms/step - loss: 0.5535 - accuracy: 0.7207 - val_loss: 0.5363 - val_accuracy: 0.7283\nEpoch 18/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5566 - accuracy: 0.7175 - val_loss: 0.5341 - val_accuracy: 0.7386\nEpoch 19/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5469 - accuracy: 0.7258 - val_loss: 0.5296 - val_accuracy: 0.7360\nEpoch 20/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5519 - accuracy: 0.7183 - val_loss: 0.5311 - val_accuracy: 0.7304\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n\n\n\n\n\n\n\nValidation Accuracy: The accuracy of my model stabilized between 69% and 73% during training.\nComparison to model1: Compare to the model1 59%-64% accuracy, there is an around 9% improvement.\nOverfitting Observation: I observe little overfitting in model 2. This suggests the model2 fits coser than model1 to the training dataset. cool.\n4.Model 3: Model with Data Preprocessing\nBy normalizing RGB values from between 0 to 255 to between 0 and 1 (or possibly between -1 and 1), many models can be trained faster. If we handle weight scaling prior to the training proess, we can spend more traning energy handling actual signal and have the weights adjust to the data scale.\nThe following code creates a preprocessing layer called preprocessor which can be slot into our model pipeline:\n\ni = keras.Input(shape=(150, 150, 3))\n# The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs = i, outputs = x)\n\n\nmodel3 = keras.models.Sequential([\n    layers.Input((150,150,3)),\n    preprocessor,\n    layers.RandomFlip(\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.24),\n    layers.Conv2D(32, (3, 3), activation='relu'),#learning a total of 32 filters\n    layers.MaxPooling2D((2, 2)),\n    #use Max Pooling to reduce the spatial dimensions of the output volume\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(), #flattens the input, makes the multidimensional input 1D\n\n    layers.Dropout(0.3), # randomly drop out 30% of the input\n    layers.Dense(64, activation='softmax') # normalize the outputs, convert from weighted sum values into probabilities that sum to one\n\n])\nmodel3.summary()\n\nModel: \"sequential_40\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n model_5 (Functional)        (None, 150, 150, 3)       0         \n                                                                 \n random_flip_36 (RandomFlip  (None, 150, 150, 3)       0         \n )                                                               \n                                                                 \n random_rotation_36 (Random  (None, 150, 150, 3)       0         \n Rotation)                                                       \n                                                                 \n conv2d_72 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_66 (MaxPooli  (None, 74, 74, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_73 (Conv2D)          (None, 72, 72, 64)        18496     \n                                                                 \n max_pooling2d_67 (MaxPooli  (None, 36, 36, 64)        0         \n ng2D)                                                           \n                                                                 \n flatten_40 (Flatten)        (None, 82944)             0         \n                                                                 \n dropout_34 (Dropout)        (None, 82944)             0         \n                                                                 \n dense_74 (Dense)            (None, 64)                5308480   \n                                                                 \n=================================================================\nTotal params: 5327872 (20.32 MB)\nTrainable params: 5327872 (20.32 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel3.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model3.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 116s 40ms/step - loss: 0.3754 - accuracy: 0.8347 - val_loss: 0.4780 - val_accuracy: 0.8147\nEpoch 2/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3760 - accuracy: 0.8321 - val_loss: 0.4999 - val_accuracy: 0.8091\nEpoch 3/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3707 - accuracy: 0.8374 - val_loss: 0.4653 - val_accuracy: 0.8138\nEpoch 4/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3797 - accuracy: 0.8280 - val_loss: 0.4800 - val_accuracy: 0.8108\nEpoch 5/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3780 - accuracy: 0.8320 - val_loss: 0.4570 - val_accuracy: 0.8224\nEpoch 6/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.3760 - accuracy: 0.8352 - val_loss: 0.4634 - val_accuracy: 0.8160\nEpoch 7/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3765 - accuracy: 0.8345 - val_loss: 0.4479 - val_accuracy: 0.8151\nEpoch 8/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3763 - accuracy: 0.8321 - val_loss: 0.5011 - val_accuracy: 0.8091\nEpoch 9/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3742 - accuracy: 0.8321 - val_loss: 0.4702 - val_accuracy: 0.8108\nEpoch 10/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3705 - accuracy: 0.8334 - val_loss: 0.4505 - val_accuracy: 0.8169\nEpoch 11/20\n146/146 [==============================] - 5s 38ms/step - loss: 0.3709 - accuracy: 0.8354 - val_loss: 0.4823 - val_accuracy: 0.8117\nEpoch 12/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3748 - accuracy: 0.8328 - val_loss: 0.4942 - val_accuracy: 0.8065\nEpoch 13/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3720 - accuracy: 0.8325 - val_loss: 0.4717 - val_accuracy: 0.8104\nEpoch 14/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3700 - accuracy: 0.8348 - val_loss: 0.5093 - val_accuracy: 0.8113\nEpoch 15/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3726 - accuracy: 0.8347 - val_loss: 0.4981 - val_accuracy: 0.8095\nEpoch 16/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3694 - accuracy: 0.8329 - val_loss: 0.5493 - val_accuracy: 0.7962\nEpoch 17/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.3650 - accuracy: 0.8408 - val_loss: 0.4625 - val_accuracy: 0.8212\nEpoch 18/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.3723 - accuracy: 0.8357 - val_loss: 0.4866 - val_accuracy: 0.8083\nEpoch 19/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3674 - accuracy: 0.8414 - val_loss: 0.5071 - val_accuracy: 0.8100\nEpoch 20/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3610 - accuracy: 0.8402 - val_loss: 0.4767 - val_accuracy: 0.8061\n\n\nException ignored in: &lt;function _xla_gc_callback at 0x7a26d6e763b0&gt;\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n    def _xla_gc_callback(*args):\nKeyboardInterrupt: \n\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n\n\n\n\n\n\n\nValidation Accuracy: The accuracy of my model stabilized between 81% and 82% during training.\nComparison to model2: Compare to the model2 68%-72%, there is an around 11% improvement.\nOverfitting Observation: I observe little overfitting in model 3.\n5.Model 4: Model with Transfer Learning\nTo improve our model training, we could also access to pre-existing “base models” and incorporate it into a full model our current project, then continue training.\nWe paste the following code to download MobileNetV3Large and configured it as a layer we could include in our model.\n\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training = False)\nbase_model_layer = keras.Model(inputs = i, outputs = x)\n# preprocessing layers are included in MobileNetV3Large.\n\nWARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n\n\n\nmodel4 = keras.models.Sequential([\n    layers.Input((150,150,3)),\n    base_model_layer, # add this layer we defined above\n    # we keep data augmentation layers from Part 3\n    layers.RandomFlip(\"horizontal_and_vertical\"),\n    layers.RandomRotation(0.24),\n    layers.Flatten(), #flattens the input, makes the multidimensional input 1D\n    layers.Dropout(0.3), # I put an additionaly dropout layer; we don't need a lot additional layers\n    layers.Dense(2)# we have Dense(2) layer at the very end to actually perform the classification\n\n])\nmodel4.summary()\n\nModel: \"sequential_35\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n model_7 (Functional)        (None, 5, 5, 960)         2996352   \n                                                                 \n random_flip_34 (RandomFlip  (None, 5, 5, 960)         0         \n )                                                               \n                                                                 \n random_rotation_34 (Random  (None, 5, 5, 960)         0         \n Rotation)                                                       \n                                                                 \n flatten_35 (Flatten)        (None, 24000)             0         \n                                                                 \n dropout_29 (Dropout)        (None, 24000)             0         \n                                                                 \n dense_66 (Dense)            (None, 2)                 48002     \n                                                                 \n=================================================================\nTotal params: 3044354 (11.61 MB)\nTrainable params: 48002 (187.51 KB)\nNon-trainable params: 2996352 (11.43 MB)\n_________________________________________________________________\n\n\n*Model4 Summary Analysis: The base_model_layer is nuanced: There are 48002 trainable parameters in the model 4. 3044354 parameters in total.\n\nmodel4.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model4.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 123s 52ms/step - loss: 0.4829 - accuracy: 0.9542 - val_loss: 0.5246 - val_accuracy: 0.9480\nEpoch 2/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.3985 - accuracy: 0.9549 - val_loss: 0.4381 - val_accuracy: 0.9488\nEpoch 3/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.3666 - accuracy: 0.9531 - val_loss: 0.4337 - val_accuracy: 0.9441\nEpoch 4/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.3244 - accuracy: 0.9344 - val_loss: 0.3844 - val_accuracy: 0.9187\nEpoch 5/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.3517 - accuracy: 0.9459 - val_loss: 0.4143 - val_accuracy: 0.9514\nEpoch 6/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3307 - accuracy: 0.9553 - val_loss: 0.4066 - val_accuracy: 0.9523\nEpoch 7/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.3237 - accuracy: 0.9562 - val_loss: 0.3870 - val_accuracy: 0.9518\nEpoch 8/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3117 - accuracy: 0.9558 - val_loss: 0.4322 - val_accuracy: 0.9553\nEpoch 9/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.3841 - accuracy: 0.9525 - val_loss: 0.4759 - val_accuracy: 0.9458\nEpoch 10/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.3867 - accuracy: 0.9524 - val_loss: 0.4956 - val_accuracy: 0.9536\nEpoch 11/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4344 - accuracy: 0.9569 - val_loss: 0.5131 - val_accuracy: 0.9514\nEpoch 12/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.4486 - accuracy: 0.9560 - val_loss: 0.5210 - val_accuracy: 0.9493\nEpoch 13/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.4467 - accuracy: 0.9546 - val_loss: 0.4882 - val_accuracy: 0.9471\nEpoch 14/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.4211 - accuracy: 0.9472 - val_loss: 0.4840 - val_accuracy: 0.9463\nEpoch 15/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.4233 - accuracy: 0.9481 - val_loss: 0.4769 - val_accuracy: 0.9471\nEpoch 16/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4114 - accuracy: 0.9470 - val_loss: 0.4656 - val_accuracy: 0.9458\nEpoch 17/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4184 - accuracy: 0.9533 - val_loss: 0.4867 - val_accuracy: 0.9501\nEpoch 18/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.4150 - accuracy: 0.9545 - val_loss: 0.4799 - val_accuracy: 0.9501\nEpoch 19/20\n146/146 [==============================] - 7s 48ms/step - loss: 0.4163 - accuracy: 0.9538 - val_loss: 0.4944 - val_accuracy: 0.9531\nEpoch 20/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.4306 - accuracy: 0.9569 - val_loss: 0.4911 - val_accuracy: 0.9518\n\n\nException ignored in: &lt;function _xla_gc_callback at 0x7a26d6e763b0&gt;\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n    def _xla_gc_callback(*args):\nKeyboardInterrupt: \n\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.show()\n\n\n\n\n\n\n\n\nValidation Accuracy: The accuracy of my model4 stabilized between 94% and 97% during training.\nComparison to model1: Compare to the model1’s 63% accuracy, there is an around 45% improvement.\nOverfitting Observation: we don’t observe much overfitting in model 4.\n6. Score on Test Data\nNow let’s evaluate the accuracy of our most performant model on the unseen test_ds: We choose Model 4!\n\nresults = model4.evaluate(test_ds) # Evaluate the model on the test dataset\nprint(f'Test accuracy is {results[1]}') # f-string allows embeded expressions inside string literals for formatting\nprint(f'Test lost is {results[0]}') # inside the braces, expressions are evaluated\n\n37/37 [==============================] - 1s 38ms/step - loss: 0.4854 - accuracy: 0.9570\nTest accuracy is 0.9570077657699585\nTest lost is 0.48544150590896606\n\n\nThe entire f-string generates a string that includes both the static text and the evaluated expression, which is then passed to the print function to be displayed.\nHere is a recap about f-string if you need: f-string documentation1; f-string documentation2\nIn this way, we evaluate the accuracy of our most performant model4 on the unseen test_ds,\nits latest test accuracy is approximately 95.70%.\nAt the end, just for reference, we also present accuracy of model1, model2, model3.\n\nresults = model1.evaluate(test_ds)\nprint(f'Test accuracy is {results[1]}') #\nprint(f'Test lost is {results[0]}')\n\n37/37 [==============================] - 0s 12ms/step - loss: 1.7082 - accuracy: 0.6341\nTest accuracy is 0.6341358423233032\nTest lost is 1.7081671953201294\n\n\n\nresults = model2.evaluate(test_ds)\nprint(f'Test accuracy is {results[1]}') #\nprint(f'Test lost is {results[0]}')\n\n37/37 [==============================] - 0s 12ms/step - loss: 0.5341 - accuracy: 0.7360\nTest accuracy is 0.7360275387763977\nTest lost is 0.5340545773506165\n\n\n\nresults = model3.evaluate(test_ds)\nprint(f'Test accuracy is {results[1]}') #\nprint(f'Test lost is {results[0]}')\n\n37/37 [==============================] - 1s 13ms/step - loss: 0.4324 - accuracy: 0.8332\nTest accuracy is 0.8331900238990784\nTest lost is 0.4323917031288147\n\n\nThank you for your time reading this tutorial."
  },
  {
    "objectID": "posts/New/index.html",
    "href": "posts/New/index.html",
    "title": "PIC16B Final Project Report",
    "section": "",
    "text": "Option is a financial contract that give the buyer the right to buy or sell certain quantity of assets as specific strike price on or before maturity date, and the buyer needs to pay premium or “option price” in this context to the seller of this contract. Option pricing is a way to evaluate the fair value of an option which corresponds to its striking price, maturity time and risk involved with the stock. In this project, we aim to use one-dimension convolutional neural network to predict the intrinsic value of the call and put options with regard to its final payoff from the contract. Without loss of generality, we used the S&P 500 index as the stock of choice.\nThe whole project contains three parts: Data preprocessing, CNN model construction and result analysis, and Flask Web Application creation. We first utilize the API and Yahoo Finance to get rudimentary data, do systematic data preprocessing using various techniques, including cleaning, scaling, and database creation using sqlite3. Then we construct the 1D CNN model to predict the option price using pytorch. CNN, namely Convolutional Neural Network, is a type of neural network that is mainly used for image recognition and classification. Here we adopt the 1D version of CNN to predict the intrinsic value of the options. Then we proceed with a robust training session for hyperparameter tuning, early stopping, model evaluation, and result visualization. Finally, we create a web application using Flask to visualize the result and provide a user-friendly interface for users to interact with the model.\nAll code, data, and results are available on our GitHub repository: https://github.com/Yichen-Wang-2003/24W-PIC16B-Group4.git\nRegarding more details, please refer to the flow chart below."
  },
  {
    "objectID": "posts/New/index.html#data-acquisition",
    "href": "posts/New/index.html#data-acquisition",
    "title": "PIC16B Final Project Report",
    "section": "1.1 Data Acquisition",
    "text": "1.1 Data Acquisition\nFor the first step of our project is acquiring the data. We found the source data that satisfy our need: Optiondx[link]. This websites contains a text based datasets with end of date data for free. The following is the features. Then, realizing we might need real time stock price data for target, we utilize a package called yfinance which calls yahoo finance’s unofficial api to download data from a time range by yf.download function, which gets us an adjusted closed data at the end of each trading date.\n# getting stock prices for target evaluation\nimport pandas as pd\nimport yfinance as yf\n\ntarget = pd.DataFrame(yf.download(['SPY'], start=\"2023-06-01\", \n    end=\"2023-12-31\")['Adj Close'])\ntarget\n[*********************100%%**********************] 1 of 1 completed\n\n\n\n\n\n\n\n\nAdj Close\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n2023-06-01\n\n\n415.798767\n\n\n\n\n2023-06-02\n\n\n421.811676\n\n\n\n\n2023-06-05\n\n\n421.003418\n\n\n\n\n2023-06-06\n\n\n421.920135\n\n\n\n\n2023-06-07\n\n\n420.461212\n\n\n\n\n…\n\n\n…\n\n\n\n\n2023-12-22\n\n\n472.182892\n\n\n\n\n2023-12-26\n\n\n474.176697\n\n\n\n\n2023-12-27\n\n\n475.034058\n\n\n\n\n2023-12-28\n\n\n475.213501\n\n\n\n\n2023-12-29\n\n\n473.837769\n\n\n\n\n\n147 rows × 1 columns\n\n\n## 1.2 Data Cleaning\nFor data cleaning, we first import necessary packages including numpy, matplotlib, and sqlite3.\n# importing neccessary packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sqlite3\nWe have first removed all the contracts that are later than 2023 as a cutoff point which we will be unable to evaluate their target value at a future date.\n# Read in the data from Jan 2023 to May 2023\ndf_2023_h1 = pd.DataFrame()\nfor i in [202301, 202302, 202303, 202304,  202305]:\n    df_2023_h1 = pd.concat([df_2023_h1, pd.read_table(f'data/spy_eod_{i}.txt', \n    sep=',')], ignore_index=True)\ndf_2023_h1.columns = df_2023_h1.columns.str.strip()\n\n# also drop expiration date later than 2024\ndf_2023_h1 = df_2023_h1[df_2023_h1['[EXPIRE_DATE]'] &lt;= ' 2023-12-31']\ndf_2023_h1 = df_2023_h1[df_2023_h1['[EXPIRE_DATE]'] &gt;= ' 2023-06-01']\ndf_2023_h1 = df_2023_h1.reset_index()\nWe strip away all the spaces of the column names in this step for easier access, and removed the entries that target cannot be calculated.\n# change the string dates to datetime64\ndf_2023_h1['[QUOTE_DATE]'] = df_2023_h1['[QUOTE_DATE]'].apply(np.datetime64)\ndf_2023_h1['[EXPIRE_DATE]'] = df_2023_h1['[EXPIRE_DATE]'].apply(np.datetime64)\n\n# merge our adj close stock data on EXPIRE_DATE\ntarget['[EXPIRE_DATE]'] = target.index\ntarget['[EXPIRE_DATE]'].astype('datetime64[ns]')\n\ndf_2023_h1 = pd.merge(df_2023_h1, target, on = '[EXPIRE_DATE]')"
  },
  {
    "objectID": "posts/New/index.html#setting-targets",
    "href": "posts/New/index.html#setting-targets",
    "title": "PIC16B Final Project Report",
    "section": "1.3 Setting targets",
    "text": "1.3 Setting targets\nThen, we have to set a target for our machine learning model. We first utilized a naive estimation of the option price, then start to focus on the intrinsic value of call option. with price = (K - S).  Later, we set our target as intrinsic value of price based on payoff of call and put options, based on the function of discounted price = (K - S) * e^(-rt) where r is a risk free investment rate.\nfrom data_cleansing_function import target_setting\nimport inspect\nprint(inspect.getsource(target_setting))\ndf_2023_h1 = target_setting(df_2023_h1)\ntarget = df_2023_h1['discounted_price']\ndef target_setting(df):\n    \"\"\"\n    vectorized operation to calculate the target value based on formula\n    \"\"\"\n    df['-rt'] = -0.04*(df['[EXPIRE_UNIX]'] - df['[QUOTE_UNIXTIME]'])/(3600*365*24)  \n    # unix time is based on seconds\n    df['price_diff'] = df['[STRIKE]'] - df['Adj Close']\n    df['exp(-rt)'] = df['-rt'].apply(lambda x: math.exp(x))\n    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]   \n    df['discounted_price'] = df['price_diff'] * df['exp(-rt)']\n    return df\n    \nWe normalize all numerical columns with a standard scaler.\ndf_2023_h1 = df_2023_h1[['[EXPIRE_UNIX]', '[QUOTE_DATE]', '[EXPIRE_DATE]',\n '[STRIKE]', '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', '[C_ASK]', \n       '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]', 'Adj Close']]\n\ndf_2023_h1 = df_2023_h1.replace(r'^\\s*$', 0, regex=True)\n\n# Basic normalization and standardization\n# run block of code and catch warnings\nimport warnings\nfrom sklearn.preprocessing import StandardScaler\nwith warnings.catch_warnings():\n    # ignore all caught warnings\n    warnings.filterwarnings(\"ignore\")\n    # execute code that will generate warnings\n    numeric_cols = ['[EXPIRE_UNIX]', '[STRIKE]', '[UNDERLYING_LAST]', \n    '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', '[C_ASK]', \n       '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]']  \n    scaler = StandardScaler()\n    df_2023_h1[numeric_cols] = scaler.fit_transform(df_2023_h1[numeric_cols])\ntarget\n0        -279.724554\n1        -269.902630\n2        -260.080706\n3        -250.258782\n4        -245.347819\n             ...    \n127485    -17.254494\n127486    -12.346804\n127487     -7.439115\n127488     -2.531426\n127489      2.376263\nName: discounted_price, Length: 127490, dtype: float64\nOutput the data to sqlite database.\n# output to sqlite database for others to use\nconn = sqlite3.connect(\"data/tables.db\")\ndf_2023_h1.to_sql(\"df_2023_h1_feature\", conn, if_exists = \"replace\", index=False)\ntarget.to_sql(\"df_2023_h1_target\", conn, if_exists = \"replace\", index=False)\nconn.close()"
  },
  {
    "objectID": "posts/New/index.html#data-structures",
    "href": "posts/New/index.html#data-structures",
    "title": "PIC16B Final Project Report",
    "section": "1.4 Data Structures",
    "text": "1.4 Data Structures"
  },
  {
    "objectID": "posts/New/index.html#baseline-model-linear-regression",
    "href": "posts/New/index.html#baseline-model-linear-regression",
    "title": "PIC16B Final Project Report",
    "section": "Baseline model: Linear Regression",
    "text": "Baseline model: Linear Regression\nWe need to set a target for the neuron network to beat, if any model cannot beat a linear approximation of stock market in the long run it is a failure.\n# custom train test val split with a smaller dataset. \n# Read in the data from the database\nconn = sqlite3.connect('data/tables.db')\n# show database content\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\nprint(cursor.fetchall())\n# Extract two tables from it and store them in two pd df\nds = pd.read_sql_query(\"SELECT * from df_2023_h1_feature\", conn)\ntarget = pd.read_sql_query(\"SELECT * from df_2023_h1_target\", conn)\n\nds = ds.drop(['[QUOTE_DATE]', '[EXPIRE_DATE]', 'Adj Close'], axis=1)\n\nX_train = ds[0:10000]\ny_train = target[0:10000]\nX_val = ds[10001:11001]\ny_val = target[10001:11001]\nX_test = ds[11002: 12002]\ny_test = target[11002: 12002]\nprint(X_train.shape, y_train.shape, X_val.shape, y_val.shape, \n    X_test.shape, y_test.shape)\n[('df_2023_h1_feature',), ('df_2023_h1_target',)]\n(10000, 21) (10000, 1) (1000, 21) (1000, 1) (1000, 21) (1000, 1)\ntarget = pd.read_sql_query(\"SELECT * from df_2023_h1_target\", conn)\ntarget\n\n\n\n\n\n\n\n\ndiscounted_price\n\n\n\n\n\n\n0\n\n\n-279.724554\n\n\n\n\n1\n\n\n-269.902630\n\n\n\n\n2\n\n\n-260.080706\n\n\n\n\n3\n\n\n-250.258782\n\n\n\n\n4\n\n\n-245.347819\n\n\n\n\n…\n\n\n…\n\n\n\n\n127485\n\n\n-17.254494\n\n\n\n\n127486\n\n\n-12.346804\n\n\n\n\n127487\n\n\n-7.439115\n\n\n\n\n127488\n\n\n-2.531426\n\n\n\n\n127489\n\n\n2.376263\n\n\n\n\n\n127490 rows × 1 columns\n\n\nUtilizing a simple linear regression model from sklearn, we can get a baseline model to compare with our neural network.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\nreg = LinearRegression()\nreg.fit(X_train, y_train)\n\n\n\nLinearRegression()\nIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n\n\n\n\nLinearRegression\n\nLinearRegression()\n\n\n\n\n\nWith this code block we can output a r2_list to check r2 and mse for a range of values for their relationship with the distance with train set, and output plot graphs.\nr2_list = []\nmse_list = []\nX_list = []\nfor i in range(10):\n    X_test = ds.iloc[10000 + i * 10000:11000 + i * 10000]\n    y_test = target.iloc[10000 + i * 10000:11000 + i * 10000]\n    y_pred = reg.predict(X_test)\n    X_list.append(10000 + i * 10000)\n    r2_list.append(metrics.r2_score(y_true=y_test, y_pred=y_pred))\n    mse_list.append(metrics.mean_squared_error(y_true=y_test, y_pred=y_pred))\nplt.plot(X_list, r2_list)\nplt.title('R2 Score for baseline model')\nText(0.5, 1.0, 'R2 Score for baseline model')\n\n\n\nR2 Score baseline\n\n\nplt.plot(X_list, mse_list)\nplt.title('MSE Loss for baseline model')\nText(0.5, 1.0, 'MSE Loss for baseline model')\n\n\n\nMSE Loss baseline\n\n\nLinear regression model is not performing well after 80000 rows, which shows that the linear approximation of stock is not good enough for prediction further into the future. We shall see the CNN performance in the next section."
  },
  {
    "objectID": "posts/New/index.html#feature-and-target-selection",
    "href": "posts/New/index.html#feature-and-target-selection",
    "title": "PIC16B Final Project Report",
    "section": "2.1 Feature and Target Selection",
    "text": "2.1 Feature and Target Selection\nThe first step of our model building process is to select the features and target. We will use PyTorch to build the CNN model. PyTorch is a popular open-source machine learning library based on the Torch library, flexible and powerful for machine learning tasks. We will use the torch and torchvision libraries to build the CNN model.\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor \nimport sqlite3\nimport math\nAfter importing all the necessary libraries, we will load the preprocessed dataset from the database. By using the sqlite3 library, we can connect to the database and load the dataset into a pandas dataframe. As shown below, we first create a cursor and use the SQL command to fetch the data from the database. We have two tables in the database, one for feature, and the other for target.\n# Read in the data from the database\nconn = sqlite3.connect('tables.db')\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\nprint(cursor.fetchall())\n# Extract two tables from it and store them in two pd df\nds = pd.read_sql_query(\"SELECT * from df_2023_h1_feature\", conn)\ntarget = pd.read_sql_query(\"SELECT * from df_2023_h1_target\", conn)\n[('df_2023_h1_feature',), ('df_2023_h1_target',)]\nWe first take a look at the feature table named ds, and we make a copy of it for backup. As shown below, the feature table has a structure of 331609 rows × 22 columns, which has been preprossed in the previous section. We will then do feature selection from it.\nds_new = ds.copy()\nds\n\n\n\n\n\n\n\n\n\n\n\n\nIndex\n[QUOTE_UNIXTIME]\n[EXPIRE_UNIX]\n[STRIKE]\n[UNDERLYING_LAST]\n[C_DELTA]\n…\n\n\n\n\n0\n-1.69160\n-1.531564\n-1.054517\n-2.406592\n1.054125\n…\n\n\n1\n-1.69160\n-1.531564\n-0.936052\n-2.406592\n1.041020\n…\n\n\n2\n-1.69160\n-1.531564\n-0.888665\n-2.406592\n1.035470\n…\n\n\n3\n-1.69160\n-1.531564\n-0.876819\n-2.406592\n1.048893\n…\n\n\n4\n-1.69160\n-1.531564\n-0.864972\n-2.406592\n1.030873\n…\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n331604\n1.78216\n1.881977\n0.367073\n1.410238\n-0.175447\n…\n\n\n331605\n1.78216\n1.881977\n0.426306\n1.410238\n-0.288188\n…\n\n\n331606\n1.78216\n1.881977\n0.485538\n1.410238\n-0.406236\n…\n\n\n331607\n1.78216\n1.881977\n0.544771\n1.410238\n-0.524528\n…\n\n\n331608\n1.78216\n1.881977\n0.604004\n1.410238\n-0.647832\n…\n\n\n\nTheen we take a glance at the target table with merely one column named “discounted_price”. This column will be the target for our CNN model, as all feature engineering has been done in the data preprocessing phase.\ntarget\n\n\n\n\n\n\n\n\ndiscounted_price\n\n\n\n\n\n\n0\n\n\n-63.916774\n\n\n\n\n1\n\n\n-54.101350\n\n\n\n\n2\n\n\n-50.175181\n\n\n\n\n3\n\n\n-49.193639\n\n\n\n\n4\n\n\n-48.212096\n\n\n\n\n…\n\n\n…\n\n\n\n\n331604\n\n\n-18.619560\n\n\n\n\n331605\n\n\n-13.711848\n\n\n\n\n331606\n\n\n-8.804136\n\n\n\n\n331607\n\n\n-3.896425\n\n\n\n\n331608\n\n\n1.011287\n\n\n\n\n\n331609 rows × 1 columns\n\n\nFor the feature and target selections, we first concatenate the feature and target tables together.\n\n# Merge target and ds directly, as they match and have the same length\nds_new = pd.concat([ds_new, target], axis=1)\n\n\nds_new.columns\n\nIndex(['[QUOTE_UNIXTIME]', '[EXPIRE_UNIX]', '[STRIKE]', '[UNDERLYING_LAST]',\n       '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]', '[C_THETA]', '[C_RHO]', '[C_IV]',\n       '[C_VOLUME]', '[C_BID]', '[C_ASK]', '[P_DELTA]', '[P_GAMMA]',\n       '[P_VEGA]', '[P_THETA]', '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]',\n       '[P_ASK]', 'discounted_price'],\n      dtype='object')\n\n\nWe finalize the features and target_1 as our final features and target for the 1D CNN model. We select all option greeks for call and put as well as the quote and expire dates for features; and we multiply the “price_diff” by the exp(-rt) to get the target_1.\n\nfeatures = ds_new[['[QUOTE_UNIXTIME]', '[EXPIRE_UNIX]', '[STRIKE]', \n                   '[UNDERLYING_LAST]', '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]',\n       '[C_THETA]', '[C_RHO]', '[C_IV]', '[C_VOLUME]','[C_BID]', \n       '[C_ASK]', '[P_DELTA]', '[P_GAMMA]', '[P_VEGA]', '[P_THETA]',\n       '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]', '[P_ASK]']].values\ntarget_1= ds_new['discounted_price']"
  },
  {
    "objectID": "posts/New/index.html#train-validation-and-test-data-split",
    "href": "posts/New/index.html#train-validation-and-test-data-split",
    "title": "PIC16B Final Project Report",
    "section": "2.2 Train, Validation, and Test Data Split",
    "text": "2.2 Train, Validation, and Test Data Split\nAfter feature engineering, we now do the train, validation, and test data split. We will directly use slicing to create the three datasets but not sklearn’s train_test_split function, because each expire date has multiple strike prices, so we need to ensure the integrity of each expire date’s information. The proportion of the train, validation, and test datasets is 0.8, 0.1, and 0.1, respectively. We will use the first 80% of the data for training, the next 10% for validation, and the last 10% for testing.\n\n# Manually using slicing to create the train, validation and test dataset in percentage of 80, 10, 10\nX_train = features[:int(0.8*len(features))]\nX_val = features[int(0.8*len(features)):int(0.9*len(features))]\nX_test = features[int(0.9*len(features)):]\ny_train = target_1[:int(0.8*len(target_1))]\ny_val = target_1[int(0.8*len(target_1)):int(0.9*len(target_1))]\ny_test = target_1[int(0.9*len(target_1)):]\n\nThen we convert these datasets to PyTorch tensors, and then we print out the shapes of the three datasets to ensure that the data split is successful.\n\n# Convert the data to tensor\nX_train = torch.from_numpy(X_train).type(torch.Tensor)\nX_val = torch.from_numpy(X_val).type(torch.Tensor)\nX_test = torch.from_numpy(X_test).type(torch.Tensor)\ny_train = torch.from_numpy(y_train.values).type(torch.Tensor)\ny_val = torch.from_numpy(y_val.values).type(torch.Tensor)\ny_test = torch.from_numpy(y_test.values).type(torch.Tensor)\n\n\nprint(\"Train shapes:\", X_train.shape, y_train.shape)\nprint(\"Validation shapes:\", X_val.shape, y_val.shape)\nprint(\"Test shapes:\", X_test.shape, y_test.shape)\n\nTrain shapes: torch.Size([265287, 22]) torch.Size([265287])\nValidation shapes: torch.Size([33161, 22]) torch.Size([33161])\nTest shapes: torch.Size([33161, 22]) torch.Size([33161])\n\n\nWe need to do some unsqueeze operations to make the data suitable for the CNN model. The CNN model requires the input to be in the shape of (batch_size, channels, sequence_length), so we need to unsqueeze the second dimension of the input data to make it suitable for the CNN model.\n\nX_train = X_train.unsqueeze(2)\nprint(X_train.shape)\nX_val = X_val.unsqueeze(2)\nprint(X_val.shape)\nX_test = X_test.unsqueeze(2)\nprint(X_test.shape)\n\ntorch.Size([265287, 22, 1])\ntorch.Size([33161, 22, 1])\ntorch.Size([33161, 22, 1])"
  },
  {
    "objectID": "posts/New/index.html#d-cnn-model-construction",
    "href": "posts/New/index.html#d-cnn-model-construction",
    "title": "PIC16B Final Project Report",
    "section": "2.3 1D CNN Model Construction",
    "text": "2.3 1D CNN Model Construction\nAs all the data is ready, we now construct the 1D CNN Model for the intrinsic value prediction. Before building the class of the model, we first import all torch related libraries and then define the model, including the torch.nn.functional library.\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nIn order to ensure the robustness and generalization of the model, the CNN we create has the following structure:\n\nInitial Convolution Block:\n\nConv1d: 22 input channels, 64 output channels, kernel size=3, stride=1, padding=1\nBatchNorm1d: 64 features (output channels)\n\n\n\nInterpretation: The initial convolution block is used to extract the features from the input data, and the batch normalization layer is used to normalize the features to ensure that the features are in the same scale.\n\n\nResidual Chunk 1:\n\nConv1d: 64 input channels, 64 output channels, kernel size=3, padding=1\nBatchNorm1d: 64 features\nConv1d: 64 input channels, 64 output channels, kernel size=3, padding=1\nBatchNorm1d: 64 features\nNote: Residual connection adds the input of the chunk to its output after these layers.\n\n\n\nInterpretation: The first residual chunk preserves the number of channels at 64 but allows the model to learn an identity function easily, ensuring the layer can improve performance without hurting existing capabilities. It also helps solve gradient vanishing problem.\n\n\nResidual Chunk 2:\n\nConv1d: 64 input channels, 128 output channels, kernel size=3, padding=1, stride=2\nBatchNorm1d: 128 features\nConv1d: 128 input channels, 128 output channels, kernel size=3, padding=1\nBatchNorm1d: 128 features\nShortcut Connection (for residual addition):\n\nConv1d: 64 input channels, 128 output channels, kernel size=1, stride=2\n\n\n\n\nInterpretation: The second residual chunk includes a shortcut connection with a 1D convolutional layer (self.res2_shortcut) to match the dimensionality change for the residual connection. Other functionalities remain the same as the first Res Chunk.\n\n\nDropout Layer:\n\nDropout: 0.3 probability.\nInterpretation: The dropout layer is pplied to reduce overfitting by randomly setting input elements to zero during training with a probability of 0.3 (self.dropout).\n\nAdaptive Pooling and Fully Connected Layers:\n\nAdaptiveAvgPool1d: Output size of 1\nLinear FC layer: 128 input features, 128 output features\nDropout: 0.3 probability\nLinear FC layer: 128 input features, 128 output features\nDropout: 0.3 probability\nLinear FC layer: 128 input features, 128 output features\nDropout: 0.3 probability\nLinear FC layer: 128 input features, 1 output feature\n\n\n\nInterpretation: The adaptive pooling layer is used to output a fixed-length output irrespective of input size, facilitating the connection to fully connected layers. The linear fully connected layers with dropoutapplied between them help to further prevent overfitting. The last fully connected layer reduces the output to 1 dimension.\n\nAnd the visualization of the model structure is shown below: \nWe then import the python file CNN_CODE.py to access the CNN class and all necessary code, and then inspect to use them.\n\nfrom CNN_CODE import Convolution1D\nimport inspect\nprint(inspect.getsource(Convolution1D))\n\nclass Convolution1D(nn.Module):\n    def __init__(self):\n        '''\n        Convolutional Neural Network with 1D convolutions\n        params:\n        - input_channels: number of input channels\n        - output_channels: number of output channels\n        - kernel_size: size of the kernel\n        - stride: stride of the kernel\n        - padding: padding of the kernel\n        '''\n        super(Convolution1D, self).__init__()\n        \n        # Initial Convolution\n        # 22 input channels (features), 64 output channels, 3x3 kernel\n        self.conv1 = nn.Conv1d(in_channels=22, out_channels=64, \n                               kernel_size=3, stride=1, padding=1)\n        # Batch Normalization with 64 features\n        self.bninit = nn.BatchNorm1d(64)\n\n        # Residual chunk 1\n        self.res1_conv1 = nn.Conv1d(64, 64, 3, padding=1)\n        self.res1_bn1 = nn.BatchNorm1d(64)\n        self.res1_conv2 = nn.Conv1d(64, 64, 3, padding=1)\n        self.res1_bn2 = nn.BatchNorm1d(64)\n        \n        # Residual chunk 2\n        self.res2_conv1 = nn.Conv1d(64, 128, 3, padding=1, \n                                stride=2)  # Reduce dimensionality\n        self.res2_bn1 = nn.BatchNorm1d(128)\n        self.res2_conv2 = nn.Conv1d(128, 128, 3, padding=1)\n        self.res2_bn2 = nn.BatchNorm1d(128)\n        self.res2_shortcut = nn.Conv1d(64, 128, 1, \n                            stride=2)  # Shortcut to match dimensions\n\n\n        # Dropout layer\n        self.dropout = nn.Dropout(0.3)\n        # Final global pooling and fully connected layers\n        self.global_pool = nn.AdaptiveAvgPool1d(1)\n        self.fc1 = nn.Linear(128, 128)\n        self.fc2 = nn.Linear(128, 128)\n        self.fc3 = nn.Linear(128, 128)\n        self.fc4 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        # Initial conv layer\n        x = F.relu(self.bninit(self.conv1(x)))\n        \n        # Residual Chunk 1\n        res1 = self.res1_conv1(x)\n        res1 = F.relu(self.res1_bn1(res1))\n        res1 = self.res1_conv2(res1)\n        x = F.relu(x + res1)\n        \n        # Residual Chunk 2\n        res2 = self.res2_conv1(x)\n        res2 = F.relu(self.res2_bn1(res2))\n        res2 = self.res2_conv2(res2)\n        shortcut = self.res2_shortcut(x)\n        x = F.relu(res2 + shortcut)\n\n        # Final layers\n        x = self.global_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = self.fc4(x)\n        \n        return x"
  },
  {
    "objectID": "posts/New/index.html#model-training-and-validation",
    "href": "posts/New/index.html#model-training-and-validation",
    "title": "PIC16B Final Project Report",
    "section": "2.4 Model Training and Validation",
    "text": "2.4 Model Training and Validation\nAs we constructed our CNN model, we now train and validate the model. We first define the loss function and the optimizer, using the Mean Squared Error (MSE) loss function to calculate the loss and the Adam optimizer to optimize the model. We set the learning rate as 0.01 and the weight decay as 0.0001. We also set various hyperparameters, including the number of epochs and the device to train the model. We set the number of epochs to 100 and the device to “cuda” if it is available; otherwise, we use “cpu”.\nAlso, for preventing early stopping, we use the patience parameter to set the number of epochs to wait for improvement before stopping the training process. We set the patience to 15, which means that if the validation loss does not improve for 15 epochs, the training process will stop. We also set the L2 regularization to 0.0001 to prevent overfitting.\nThen, we create a loop to train and validate the model. We first set the model to training mode and then iterate through the training dataset, then compute the loss and update the model parameters using the optimizer, with the backward propagation.\nAfter this, we set the model to evaluation mode and iterate through the validation dataset to calculate the validation loss. We also print out the training and validation loss for each epoch to monitor the training process. Should the early stopping condition is met, we use torch.save to save the model and stop the training process. The training and validation loss of each epoch are stored, and they are printed as below.\n\nfrom torch import optim\n\nmodel = Convolution1D()\nval_loss_list, train_loss_list =[],[]\nfinal_epoch = 0\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# For early stopping\npatience = 15\noptimal_val_loss = np.inf\ncurrent_patience = 0\n# Training phase\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    optimizer.zero_grad()\n    outputs = model(X_train).squeeze(-1)\n    loss = criterion(outputs, y_train)\n    train_loss_list.append(loss)\n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Validation phase\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(X_val).squeeze(-1)\n        val_loss = criterion(val_outputs, y_val)\n        val_loss_list.append(val_loss)\n        # Early stopping\n        if val_loss &lt; optimal_val_loss:\n            optimal_val_loss = val_loss\n            torch.save(model.state_dict(), 'best_model.pt')\n            current_patience = 0\n        else:\n            current_patience += 1\n            if current_patience == patience:\n                print(f'Early stopping at epoch {epoch+1}')\n                final_epoch = epoch\n                # load best model\n                model.load_state_dict(torch.load('best_model.pt'))\n                break\n    \n    if (epoch+1) % 1 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, \n              Val Loss: {val_loss.item()}')\n\nEpoch [1/100], Loss: 9172.8681640625, Val Loss: 1818.197265625\nEpoch [2/100], Loss: 9102.5693359375, Val Loss: 1751.77685546875\nEpoch [3/100], Loss: 8275.830078125, Val Loss: 1398.82080078125\nEpoch [4/100], Loss: 5244.42724609375, Val Loss: 681.4796752929688\nEpoch [5/100], Loss: 7110.5087890625, Val Loss: 1006.462890625\nEpoch [6/100], Loss: 3426.317626953125, Val Loss: 1126.9154052734375\nEpoch [7/100], Loss: 4286.83154296875, Val Loss: 938.3817749023438\nEpoch [8/100], Loss: 4022.037109375, Val Loss: 682.0269165039062\nEpoch [9/100], Loss: 3196.9482421875, Val Loss: 917.9542236328125\nEpoch [10/100], Loss: 3701.21533203125, Val Loss: 181.23085021972656\nEpoch [11/100], Loss: 1524.900634765625, Val Loss: 389.5296936035156\nEpoch [12/100], Loss: 1103.0982666015625, Val Loss: 1594.5777587890625\nEpoch [13/100], Loss: 1861.9698486328125, Val Loss: 2287.84619140625\nEpoch [14/100], Loss: 2340.36279296875, Val Loss: 1141.52294921875\nEpoch [15/100], Loss: 1081.2857666015625, Val Loss: 313.52301025390625\nEpoch [16/100], Loss: 581.6431274414062, Val Loss: 108.076416015625\nEpoch [17/100], Loss: 932.9679565429688, Val Loss: 140.25146484375\nEpoch [18/100], Loss: 1336.6429443359375, Val Loss: 145.90013122558594\nEpoch [19/100], Loss: 1214.3756103515625, Val Loss: 147.10081481933594\nEpoch [20/100], Loss: 815.1370239257812, Val Loss: 339.05621337890625\nEpoch [21/100], Loss: 572.9165649414062, Val Loss: 836.8012084960938\nEpoch [22/100], Loss: 672.4065551757812, Val Loss: 1281.7899169921875\nEpoch [23/100], Loss: 980.5892944335938, Val Loss: 1051.82470703125\nEpoch [24/100], Loss: 892.7532958984375, Val Loss: 498.3086853027344\nEpoch [25/100], Loss: 542.4771728515625, Val Loss: 207.02662658691406\nEpoch [26/100], Loss: 491.0587463378906, Val Loss: 146.8715362548828\nEpoch [27/100], Loss: 674.1841430664062, Val Loss: 121.95735168457031\nEpoch [28/100], Loss: 770.651611328125, Val Loss: 80.98929595947266\nEpoch [29/100], Loss: 654.6914672851562, Val Loss: 91.96054077148438\nEpoch [30/100], Loss: 492.27069091796875, Val Loss: 207.66490173339844\nEpoch [31/100], Loss: 465.4485168457031, Val Loss: 369.939453125\nEpoch [32/100], Loss: 586.9057006835938, Val Loss: 391.50579833984375\nEpoch [33/100], Loss: 624.5753173828125, Val Loss: 241.49102783203125\nEpoch [34/100], Loss: 500.69305419921875, Val Loss: 101.10918426513672\nEpoch [35/100], Loss: 427.59552001953125, Val Loss: 51.98616027832031\nEpoch [36/100], Loss: 483.1625061035156, Val Loss: 47.67477798461914\nEpoch [37/100], Loss: 545.8229370117188, Val Loss: 41.39034652709961\nEpoch [38/100], Loss: 508.1427917480469, Val Loss: 36.485774993896484\nEpoch [39/100], Loss: 438.0169677734375, Val Loss: 54.16953659057617\nEpoch [40/100], Loss: 421.1383056640625, Val Loss: 88.96914672851562\nEpoch [41/100], Loss: 471.10845947265625, Val Loss: 100.9154281616211\nEpoch [42/100], Loss: 480.3539123535156, Val Loss: 75.54594421386719\nEpoch [43/100], Loss: 429.4358215332031, Val Loss: 47.808441162109375\nEpoch [44/100], Loss: 406.1731262207031, Val Loss: 37.47623825073242\nEpoch [45/100], Loss: 435.10394287109375, Val Loss: 32.7606086730957\nEpoch [46/100], Loss: 452.689697265625, Val Loss: 29.308931350708008\nEpoch [47/100], Loss: 420.9671630859375, Val Loss: 36.494937896728516\nEpoch [48/100], Loss: 396.0536193847656, Val Loss: 55.476470947265625\nEpoch [49/100], Loss: 404.5439453125, Val Loss: 68.0870361328125\nEpoch [50/100], Loss: 423.883544921875, Val Loss: 56.49263381958008\nEpoch [51/100], Loss: 408.332275390625, Val Loss: 35.67536163330078\nEpoch [52/100], Loss: 384.791748046875, Val Loss: 25.1159725189209\nEpoch [53/100], Loss: 388.8431091308594, Val Loss: 23.977157592773438\nEpoch [54/100], Loss: 401.4180603027344, Val Loss: 23.906402587890625\nEpoch [55/100], Loss: 395.3701477050781, Val Loss: 24.9521484375\nEpoch [56/100], Loss: 379.8179931640625, Val Loss: 29.47606658935547\nEpoch [57/100], Loss: 381.36181640625, Val Loss: 33.6275520324707\nEpoch [58/100], Loss: 389.26708984375, Val Loss: 31.371234893798828\nEpoch [59/100], Loss: 382.2471008300781, Val Loss: 26.508771896362305\nEpoch [60/100], Loss: 369.72607421875, Val Loss: 24.71722984313965\nEpoch [61/100], Loss: 373.2747802734375, Val Loss: 24.789255142211914\nEpoch [62/100], Loss: 372.1296691894531, Val Loss: 25.448476791381836\nEpoch [63/100], Loss: 372.6578063964844, Val Loss: 27.88591957092285\nEpoch [64/100], Loss: 366.294189453125, Val Loss: 32.301979064941406\nEpoch [65/100], Loss: 366.24237060546875, Val Loss: 34.39863967895508\nEpoch [66/100], Loss: 362.286376953125, Val Loss: 31.689903259277344\nEpoch [67/100], Loss: 360.7981872558594, Val Loss: 28.11236572265625\nEpoch [68/100], Loss: 357.0233459472656, Val Loss: 27.745023727416992\nEarly stopping at epoch 69\n\n\nAs shown above, the training phase terminates at epoch 69 due to early stopping, and we can see the rapid decrease of both training and validation loss in the first couple of epochs, which means that the model is learning well. For the last epoch, which is epoch 62, the validation loss is around 27.74, which is a good result for our model. This is because the intrinsic value of the options has a range of over 600, and the square root of the loss is around 5.26, which is a small percentage of the intrinsic value."
  },
  {
    "objectID": "posts/New/index.html#model-testing-and-analysis-of-testing-results",
    "href": "posts/New/index.html#model-testing-and-analysis-of-testing-results",
    "title": "PIC16B Final Project Report",
    "section": "2.5 Model Testing and Analysis of Testing Results",
    "text": "2.5 Model Testing and Analysis of Testing Results\nAfter finishing the training and validation process, we test the model using the test dataset. We first load the saved model and set it to evaluation mode. Then we iterate through the test dataset to calculate the test loss. We also print out the test loss to evaluate the performance of the model, as shown below.\n\nmodel.eval()\nwith torch.no_grad():\n    predictions = model(X_test).squeeze(-1)\n    test_loss = criterion(predictions, y_test)\n    print(f'Test Loss: {test_loss.item()}')\ncriterion = torch.nn.MSELoss()\nmse_loss = criterion(predictions, y_test)\nprint(f\"MSE Loss: {mse_loss.item()}\")\nprint(f\"RMSE Loss: {(mse_loss.item()**(0.5))}\")\n# R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, predictions)\nprint(f\"R2 Score: {r2}\")\n\nTest Loss: 34.36250305175781\nMSE Loss: 34.36250305175781\nRMSE Loss: 5.8619538595725755\nR2 Score: 0.9812109767170123\n\n\nAs shown above, we get the test loss(MSE) of around 34.26, which indicates that the model is performing well on the test dataset. As the fluctuation of the intrinsic value of the options is large with a range of 350, the test loss of 34.26 is a good result for our model. We then visualize the predicted intrinsic value and the actual intrinsic value of the options to see how well the model performs. We plot the predicted intrinsic value and the actual intrinsic value of the options within the test dataset using matplotlib, as shown below.\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(14,7))\nplt.plot(predictions, label='Predicted',color = 'red')\nplt.plot(y_test, label = \"True\", color = 'blue')\nplt.legend()\nplt.title('Test Set Predictions')\n\nText(0.5, 1.0, 'Test Set Predictions')\n\n\n\n\n\n\n\n\n\nThe visualization above sufficiently showcases the complexity of the intrinsic value and the model’s strong ability to capture the features of the intrinsic value. As the blue curve stands for the ground truth, and the red curve stands for the predictions, we can see that the red curve is very close to the blue curve and two curves largely overlap. This indicates that the model we construct is robust and generalizes well to the test dataset.\nWe also visualize the train and validation losses, as we need to see if there is any overfitting or underfitting. We first convert each element in two lists storing validation and train losses from torch tensor to numpy array. Then we use matplotlib to draw the plot.\nAs shown below, the train and validation losses are plotted against the number of epochs. We observe that there is no evidence of overfitting here. Both losses decrease rapidly at the beginning with some fluctuations,but in general they tend to level off, suggesting that the model is learning generalizable patterns.\n\nval_loss_numpy, train_loss_numpy = [],[]\nfor i in val_loss_list:\n    val_loss_numpy.append(i.numpy())\nfor j in train_loss_list:\n    train_loss_numpy.append(j.detach().numpy())\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(train_loss_numpy, label='Train Loss')\nplt.plot(val_loss_numpy, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Train vs Validation Loss\")\nplt.show()\n\n\n\n\n\n\n\n\nFrom our experience with the baseline Linear Regression Model and Autogluon Model, the R2 score drops quickly against time periods, and MSE loss shoots up fast. With the CNN model, we tested both against time as a metric against previous models. The timestamp in these graphs is standardized.\n\ntest_part = y_test.numpy()\n# print(len(test_part))\npred_part = predictions.numpy()\n\n# print(len(another))\ntest_part = pd.DataFrame(test_part)\npred_part = pd.DataFrame(pred_part)\n\nds_test = ds_new[int(0.9*len(features)):].reset_index(drop=True)\n\n# print(ds_test)\ntest_part.columns = ['true_intrinsic']\npred_part.columns = ['pred_intrinsic']\ntogether = pd.concat([ds_test, test_part],axis=1)\ntogether = pd.concat([together, pred_part],axis=1)\n# print(together)\nprint(together.columns)\n\nIndex(['[QUOTE_UNIXTIME]', '[EXPIRE_UNIX]', '[STRIKE]', '[UNDERLYING_LAST]',\n       '[C_DELTA]', '[C_GAMMA]', '[C_VEGA]', '[C_THETA]', '[C_RHO]', '[C_IV]',\n       '[C_VOLUME]', '[C_BID]', '[C_ASK]', '[P_DELTA]', '[P_GAMMA]',\n       '[P_VEGA]', '[P_THETA]', '[P_RHO]', '[P_IV]', '[P_VOLUME]', '[P_BID]',\n       '[P_ASK]', 'discounted_price', 'true_intrinsic', 'pred_intrinsic'],\n      dtype='object')\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n\nresult_df = together\n\nplt.xlabel('timestamp')\nplt.ylabel('R2 score')\nplt.title(\"R2 score Across Time\")\nplt.plot(result_df[['[QUOTE_UNIXTIME]', 'true_intrinsic', \n'pred_intrinsic']].groupby('[QUOTE_UNIXTIME]').apply(lambda x: \nmetrics.r2_score(x['true_intrinsic'], x['pred_intrinsic'])))\nplt.show()\nThe R2 score trend shown below is kind of turbulent, and in general the R2 score remains stable over time. Also, R2 score has a much better performance than the baseline model as we can see its value never goes below 0.95.\n\n\n\nR2 score Across Time\n\n\nplt.xlabel('timestamp')\nplt.ylabel('MSE Loss')\nplt.title(\"MSE Loss Across Time\")\nplt.plot(result_df[['[QUOTE_UNIXTIME]', 'true_intrinsic', \n'pred_intrinsic']].groupby('[QUOTE_UNIXTIME]').apply(lambda x: \nmetrics.mean_squared_error(x['true_intrinsic'], x['pred_intrinsic'])))\nplt.show()\nTHe MSE loss also performs a fluctuating trend, but it is way smaller than the baseline model’s MSE loss. So the CNN model is a good choice for the intrinsic value prediction of options and the performance is pretty good.\n[\nWith similar test and train sizes, the CNN model produces much more stable results over extended periods of time than other models. With a rather random and non-Gaussian dataset, this BEYOND-PIC16B-level model performs relatively well into the future and can produce better results than traditional machine learning algorithms utilized in PIC16A."
  },
  {
    "objectID": "posts/New/index.html#web-app-implementation-outline",
    "href": "posts/New/index.html#web-app-implementation-outline",
    "title": "PIC16B Final Project Report",
    "section": "3.0 Web App Implementation Outline",
    "text": "3.0 Web App Implementation Outline\nThe implementation strategy for our Flask web application development can be encapsulated as follows:\n\nWeb Application Framework Construction: Utilize the Flask framework to build a web application that processes user-uploaded financial data and displays prediction outcomes.\nModel Preparation: Define a Convolutional Neural Network (CNN) specifically designed for financial data prediction. This model includes multiple convolutional layers, batch normalization layers, and residual connections to boost performance and training efficiency—a milestone already achieved by our team.\nModel Loading and Data Preprocessing: Load the pre-trained model (best_model_ultimatel.pth) and perform data preprocessing. This step involves reading data from an uploaded CSV file and applying the preprocess_data function to execute feature scaling, data splitting, and other preparatory operations, mirroring the CNN model setup.\nModel Training and Prediction: Employ the PyTorch library to load the pre-trained model and input the preprocessed data for prediction.\nResults Presentation: Exhibit the model’s performance metrics on the test dataset, such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared score, along with the prediction outcomes. These are visualized using Plotly charts, providing a comprehensive view to the users.\n\n\n\n\nOur whole flask folder(flask.op.PerfectFINALver)\n\n\n\napp.py: Central to the application, this file contains key functions like Convolution1D, preprocess_data, Index, show_prediction, get_table_info, view_uploaded_database, and view_database, which are integral to the app’s operation.\nTemplates folder: This directory holds all the HTML files needed for the app’s user interface, enabling interactions and data display. It includes index.html, plot.html, view_uploaded_data.html, show_prediction.html, Test_Set_Predictions.html, and view_data.html.\nData folder: Contains sample CSV files, df_2023_h1_feature.csv and df_2023_h1_target.csv, used for data upload and result demonstration in the app.\nModel folder: Houses the pre-trained model file essential for making data predictions.\n__pycache__ folder: A system-generated directory that caches bytecode, enhancing the program’s execution speed.\nStatic folder: Stores static files, crucial for the app’s styling and interactive features.\n\nThis organizational structure ensures that each aspect of our Flask web application is well-arranged and easily accessible, supporting efficient development and maintenance."
  },
  {
    "objectID": "posts/New/index.html#overview-and-impact-analysis-of-functions-in-app.py",
    "href": "posts/New/index.html#overview-and-impact-analysis-of-functions-in-app.py",
    "title": "PIC16B Final Project Report",
    "section": "3.1 Overview and Impact Analysis of Functions in app.py",
    "text": "3.1 Overview and Impact Analysis of Functions in app.py\nIn the app.py file, several key functionalities are pivotal to the web application’s operation, specifically tailored for financial data analysis and option pricing evaluation. These include:\n\nUpload and Preprocess Financial Data: This functionality allows users to upload their financial datasets and applies preprocessing techniques to prepare the data for analysis.\nView Uploaded CSV Files: Users can view the list of uploaded CSV files, providing an overview of the data available for processing.\nView Details of the Uploaded CSV Files: This feature enables users to delve into the specifics of each uploaded CSV file, examining the data more closely.\nEvaluate Option Pricing and Display Evaluation Results: The application assesses the pricing of options based on the uploaded data and displays the results, offering valuable insights into option valuation.\n\nThe app.py file incorporates essential libraries and modules to facilitate web development, data processing, machine learning, and visualization:\nfrom flask import Flask, render_template, url_for, request, flash, redirect\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom werkzeug.utils import secure_filename\nfrom torch import nn\nimport torch.nn.functional as F\nfrom flask import jsonify\nimport sqlite3\nimport math\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.graph_objects as go\nimport os\n\nConvolution1D Class\nThe Convolution1D class within our application is a custom neural network module extending nn.Module from PyTorch, designed for one-dimensional convolutional operations. This class embodies a series of convolutional, batch normalization, and fully connected layers, structured to facilitate complex pattern recognition in financial data. Notably, this implementation includes residual connections and dropout for robustness and generalization.\nNote: Building on the foundational work previously established by our team members, this segment is presented without extensive analysis to minimize redundancy.\n\n\nTorch.load\nIn this section of the code, we address the computational efficiency and resource optimization for running our neural network model. The code snippet demonstrates the dynamic allocation of processing units, preferring GPU over CPU for faster computation, which is crucial for handling complex models like Convolution1D. We then load the model’s state dictionary from the file ‘best_model_ultimate.pt’. The map_location argument ensures that the loaded state dict is moved to the appropriate device. This step initializes the model with previously trained parameters, allowing for further training,evaluation, or inference without retraining from scratch. Here’s a detailed look at the operations:\n# Check for available GPU, otherwise use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# Initialize the Convolution1D model and transfer it to the chosen device\nmodel_loaded = Convolution1D().to(device)\n# Load the previously trained model state\nmodel_loaded.load_state_dict(torch.load('model/best_model_new.pt', map_location=device))\n# Set the model to evaluation mode\nmodel_loaded.eval()\n\n\nPreprocess_data\nThe preprocess_data function tasked with preparing the financial data for subsequent analysis. It performs several key steps:\n\nData Loading: Reads the financial datasets from the specified CSV files.\nNormalization: Applies StandardScaler to normalize specific columns, ensuring uniform data scaling.\nData Merging: Combines the feature and target data into a single DataFrame for comprehensive analysis.\nData Splitting: Segregates the dataset into training, validation, and test sets, facilitating a structured approach to model training and evaluation.\n\nGiven that these processes align with our prior data handling endeavors, we will highlight only the main actions and points, avoiding detailed analysis to prevent redundancy.\n\n\nIndex()\nThe index function in app.py serves as the main entry point for our Flask web application. It handles both GET and POST requests, managing file uploads, data preprocessing, model evaluation, and rendering the results. This function aligns with our previous work, emphasizing efficient data processing and model integration. Key points include handling file uploads, data preprocessing, model prediction, error calculation, and result visualization. Below is the detailed code:\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    \"\"\"\n    This function serves as the endpoint for the root URL ('/'). \n    It handles both GET and POST requests,\n    rendering the index page of the web application. \n    During a POST request, it processes uploaded files\n    for option pricing evaluation, performs predictions, and returns the results \n    along with rendering the HTML template.\n\n    Returns:\n        render_template: Renders the HTML template based on the \n        request method and the operations performed.\n    \"\"\"\n    # Check if the request method is POST, which indicates that data has been \n    # submitted to the server\n    if request.method == 'POST':\n        # Check if both files are present in the request\n        if 'file1' not in request.files or 'file2' not in request.files:\n            # If either file is missing, flash a message to the user and \n            # reload the page\n            flash('No file part')\n            return redirect(request.url)\n        file1 = request.files['file1']\n        file2 = request.files['file2']\n        \n        # Check if file names are not empty, meaning that the user \n        # has selected files\n        if file1.filename == '' or file2.filename == '':\n            # If no file is selected, flash a message and reload the page\n            flash('No selected file')\n            return redirect(request.url)\n        \n        # Check if both files exist and proceed with processing\n        if file1 and file2:\n            # Secure the file names and prepare the file paths\n            filename1 = secure_filename(file1.filename)\n            filename2 = secure_filename(file2.filename)\n            file1_path = os.path.join(app.config['UPLOAD_FOLDER'], \n            filename1)\n            file2_path = os.path.join(app.config['UPLOAD_FOLDER'], \n            filename2)\n            # Save the files to the server\n            file1.save(file1_path)\n            file2.save(file2_path)\n            # Notify the user that files have been uploaded successfully\n            flash('Files successfully uploaded')\n\n            # Preprocess the data from the uploaded files\n            X_train, X_val, X_test, y_train, y_val, \n            y_test = preprocess_data(file1_path,  file2_path)\n\n            # Evaluate the model on the uploaded data\n            criterion = nn.MSELoss()  # Mean Squared Error Loss function\n            with torch.no_grad():  # No gradient computation for evaluation \n                # to save memory and computations\n                output = model_loaded(X_test.to(device)).squeeze(-1)  \n                # Model prediction\n                predictions = output\n                test_loss = criterion(predictions, y_test.to(device))  \n                # Calculate the test loss\n\n            # Compute the Root Mean Square Error (RMSE) for the test data\n            mse_loss = criterion(predictions, y_test)\n            rmse_loss = mse_loss.item() ** (0.5)\n            \n            # Compute the R-squared (R2) score to measure the goodness of fit\n            from sklearn.metrics import r2_score\n            r2 = r2_score(y_test, predictions)\n            \n            # Create a plot of the predictions against the true values\n            fig = go.Figure()\n            fig.add_trace(go.Scatter(x=np.arange(len(output)), \n            y=output.squeeze().numpy(), mode='lines', name='Predicted', \n            line=dict(color='red')))\n            fig.add_trace(go.Scatter(x=np.arange(len(y_test)), \n            y=y_test.numpy(), mode='lines', name='True', line=dict(color='blue')))\n            fig.update_layout(title='Test Set Predictions', xaxis_title='Index', \n            yaxis_title='Value')\n            \n            # Save the plot output to a file\n            plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n            fig.write_html(plot_output_path)\n            \n            # Render the index HTML template with the results and plot path\n            return render_template('index.html', test_loss=test_loss.item(), \n            mse_loss=mse_loss.item(),\n                                   rmse_loss=rmse_loss, r2_score=r2,\n                                    plot=plot_output_path)\n\n    # If the request method is GET, render the index HTML \n    # template without any prediction or plot\n    return render_template('index.html', prediction=None, plot=None)\nIn summary, the index function is integral to the Flask application. It is pivotal for deploying predictive models effectively, ensuring that the application not only performs its intended analytical tasks but also provides a user-friendly interface for interaction and result interpretation.\n\n\nshow_prediction\nThe show_prediction function in app.py is designed to handle GET requests specifically for displaying the prediction results on a separate page. This functionality is crucial for providing users with access to the outcome of their data analysis, ensuring a clear and dedicated view of the predictive results.\nHere’s a detailed analysis of the function:\n\nPath Definition: Initially, the function defines the path to the prediction results file, typically stored in the static directory. This standardization of file location facilitates consistent access and retrieval of the results.\nExistence Check: The function then checks if the prediction results file exists at the specified path. This check is essential to prevent errors that would occur if the application attempted to display a non-existent file.\nConditional Rendering: If the file exists, the function proceeds to render an HTML template (Test_Set_Predictions.html) specifically designed to display the prediction results. This template is passed the path of the prediction plot file, ensuring that the correct data is displayed.\nRedirection: In cases where the prediction results file does not exist, the function redirects the user to the index page. This redirection mechanism prevents user confusion and ensures a smooth user experience by guiding them back to the starting point of the application.\n\nHere is the complete code snippet:\n@app.route('/show_prediction', methods=['GET'])\ndef show_prediction():\n    \n    # Define the path to the prediction results file, \n    # assumed to be in the 'static' directory\n    plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n    \n    # Check if the prediction results file exists\n    if not os.path.exists(plot_output_path):\n        # If the file does not exist, redirect the user to the index page\n        return redirect(url_for('index'))\n\n    # If the file exists, render the template to display the prediction results,\n    # passing the path of the prediction plot file to the template\n    return render_template('Test_Set_Predictions.html', \n    plot_output_path=plot_output_path)\n\n\nget_table_info\nThe get_table_info function is designed to streamline the process of extracting filenames from full file paths, which is a common requirement in web applications handling file uploads. By utilizing os.path.basename, it efficiently strips the directory path, leaving only the file name. This functionality is particularly useful in scenarios where the display or processing of filenames, independent of their storage paths, is required. Here’s how the function operates:\ndef get_table_info(file1_path, file2_path):\n    return [os.path.basename(file1_path), os.path.basename(file2_path)]\n\n\nview_uploaded_data\nThe view_uploaded_data function in the Flask web application serves to showcase the files that have been uploaded by users. This endpoint, accessible via a GET request, retrieves and displays the contents of the upload directory in the application’s user interface. Here’s an in-depth look at the function and its code:\n@app.route('/view_uploaded_data', methods=['GET'])\ndef view_uploaded_data():\n    \"\"\"\n    Handles the GET request to display the uploaded database files.\n\n    This endpoint fetches the list of files present in the upload \n    directory and displays them\n    on the 'view_uploaded_data.html' page. \n    This allows users to see which files have been\n    uploaded to the application.\n\n    The function retrieves the filenames from the specified \n    upload folder set in the app's configuration\n    and passes these filenames to the rendering template.\n    \n    \"\"\"\n    \n    # Retrieve the list of files in the upload directory\n    files = os.listdir(app.config['UPLOAD_FOLDER'])\n    \n    # Render the HTML template, passing the list of files \n    for display on the webpage\n    return render_template('view_uploaded_data.html', files=files)\n\n\nview_data\nThe view_data endpoint in the Flask application is designed to showcase the details of the uploaded CSV files through a GET request. It facilitates the inspection of the contents of these files, enhancing the user’s ability to interact with and analyze the uploaded data. The function operates by expecting filename1 and filename2 as query parameters, utilizing these to locate and display the respective files’ contents. Here’s a closer look at the function and its operations:\n@app.route('/view_data', methods=['GET'])\ndef view_data():\n    \"\"\"\n    The function checks for the existence of the specified files \n    in the upload directory.\n    If both files exist, it reads them as CSVs and prepares the data for viewing. \n    If either\n    file is missing or an error occurs during file reading,\n    the user is redirected to the file upload view \n    with an appropriate error message.\n    \"\"\"\n    # Retrieve filenames from the request's query parameters\n    filename1 = request.args.get('filename1')\n    filename2 = request.args.get('filename2')\n    \n    # Validate that both filenames are provided\n    if not filename1 or not filename2:\n        flash('No data file selected.')\n        return redirect(url_for('view_uploaded_data'))\n    \n    # Construct full file paths\n    file1_path = os.path.join(app.config['UPLOAD_FOLDER'], filename1)\n    file2_path = os.path.join(app.config['UPLOAD_FOLDER'], filename2)\n\n    # Check if both files exist in the specified upload folder\n    if not os.path.exists(file1_path) or not os.path.exists(file2_path):\n        flash('Data file not found.')\n        return redirect(url_for('view_uploaded_data'))\n\n    try:\n        # Attempt to read the files as CSVs and store their contents\n        ds = pd.read_csv(file1_path)\n        target = pd.read_csv(file2_path)\n        table_data = {'Dataset 1': ds, 'Dataset 2': target}\n    except Exception as e:\n        # Handle any error that occurs during file reading \n        # and flash an error message\n        flash(f'Error accessing CSV files: {e}')\n        return redirect(url_for('view_uploaded_data'))\n    # Render the view template with the loaded table data and filenames\n    return render_template('view_data.html', tables=table_data,\n     filename1=filename1, filename2=filename2)\nThe concluding part of our Flask application’s code features the standard Python idiom to check if the script is executed as the main program and not imported as a module. This check is crucial for initiating the Flask server only when the script is run directly, ensuring that the application’s startup process is controlled and deliberate. The app.run(debug=True) line activates the Flask application server with debug mode enabled, which is beneficial during development for its detailed error feedback and live reloading capabilities. Here’s the segment:\n# This conditional statement checks if the script is run as the main program.\n# Ensure that code is only executed when the script is run directly,\n#  and not when imported as a module.\nif __name__ == '__main__':\n    # The app.run(debug=True) command starts the Flask application server.\n    # The debug=True argument enables debug mode, which provides useful \n    # feedback in the browser for development,\n    # including detailed tracebacks and live reloading on code changes.\n    app.run(debug=True)"
  },
  {
    "objectID": "posts/New/index.html#evaluative-overview-of-html-templates-implications-for-user-interface-and-experience",
    "href": "posts/New/index.html#evaluative-overview-of-html-templates-implications-for-user-interface-and-experience",
    "title": "PIC16B Final Project Report",
    "section": "3.2 Evaluative Overview of HTML Templates: Implications for User Interface and Experience",
    "text": "3.2 Evaluative Overview of HTML Templates: Implications for User Interface and Experience\n\n\n\nOverview of Templates Folder\n\n\nOur web application uses a set of HTML templates, each carefully crafted to improve how users interact with and see data. These templates are essential to the app’s design, blending good looks with practical use. They guide users from the start of entering data to the end of seeing the results. - index.html: Serves as the primary gateway to the web application, designed for predicting call option values. It incorporates Bootstrap for styling, providing a responsive layout with file upload forms, navigation buttons, and result display sections, thus ensuring a user-friendly experience.\n\nplot.html: Utilizes Plotly for dynamic data visualization, offering interactive charts that render complex datasets in an easily digestible format, enhancing the analytical capabilities of the application.\nview_uploaded_data.html: Lists the uploaded database files, enabling users to access and review the data they have provided, fostering transparency and control over the processed information.\nview_data.html: Exhibits the content from two distinct datasets, providing a comprehensive view of the data under analysis and facilitating a deeper understanding of the predictive context.\nshow_prediction.html: Displays the outcome of predictive analyses, guiding users to detailed visual representations and insights derived from their data.\nTest_Set_Predictions.html: Incorporates Plotly JavaScript to generate interactive data visualizations, allowing for an engaging and informative exploration of predictive results within the web environment.\n\nNext, we will conduct a comprehensive analysis of each template’s functionalities and contributions, examining the web pages in our prototype to assess their quality and effectiveness.\n\n3.2.1 Welcome Page\nOur welcome page design seamlessly integrates various elements to optimize user experience and functionality. Users are provided with intuitive \"Browse\" buttons to swiftly upload local CSV files. Upon clicking the \"Upload & Save\" button, evaluation results are promptly generated within a few-second timeframe, ensuring efficiency in data processing. Additionally, users can easily access and review their uploaded dataset (csv files) online by selecting the \"View Data\". For a comprehensive analysis, users can explore interactive prediction graphs through the \"View Prediction\" feature, enhancing their ability to interpret and analyze data trends effectively.\n\n\n\nWelcome Page\n\n\n\nColor Scheme and Aesthetics in index.html\n\nColor Choice: In index.html, we deliberately choose a light blue background color (#ADD8E6) to promote a serene ambiance conducive to focused reading and analysis. The semi-transparent white background (rgba(255, 255, 255, 0.8)) within container elements aims to highlight content while maintaining visual harmony.\n\n&lt;style&gt;\n    body {\n        background-color: #ADD8E6;\n        padding-top: 20px;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        height: 100vh;\n    }\n    .container {\n        max-width: 800px;\n        text-align: center;\n        background-color: rgba(255, 255, 255, 0.8);\n        padding: 40px;\n        border-radius: 20px;\n    }\n    /* Additional CSS styles are defined in this section */\n&lt;/style&gt;\n\n\nModular Design with Bootstrap in index.html\n\nGrid System Utilization: We utilize Bootstrap’s grid system to create a responsive layout, dividing content into grid columns with classes like container, row, and col-*, ensuring seamless alignment across devices. This fosters a visually appealing and user-friendly design. Here’s how it’s integrated:\n\n&lt;div class=\"container\"&gt;\n    &lt;!-- Content structured using Bootstrap's grid system --&gt;\n&lt;/div&gt;\n\nCustom CSS Classes Integration: Custom CSS classes are integrated to style elements such as buttons, forms, and text, maintaining a cohesive design language and enhancing visual appeal.\n\n.btn-group .btn {\n    margin: 0 10px;\n    font-size: 36px;\n}\n\nResponsive Design Features: Leveraging Bootstrap’s responsive utilities like breakpoints and flexbox classes (d-flex, justify-content-center, align-items-center), we ensure our webpage adapts smoothly to various screen sizes and orientations for optimal user experience.\n\n&lt;div class=\"container\"&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n&lt;/div&gt;\n\nComponent Reusability: By using Bootstrap’s built-in components such as navigation bars, buttons, and forms, we enhance code modularity and maintain a consistent design language throughout the project, saving time and effort in UI development.\n\n&lt;div class=\"btn-group\" role=\"group\" aria-label=\"Actions\"&gt;\n    &lt;a href=\"{{ url_for('view_data') }}\" class=\"btn btn-info\"&gt;View Data&lt;/a&gt;\n    &lt;a href=\"{{ url_for('show_prediction') }}\" class=\"btn btn-info\"&gt;View Prediction&lt;/a&gt;\n&lt;/div&gt;\n\n\n\n3.2.2 Evaluation & Results Page\nAfter clicking the \"Upload & Save\" button, the client is directed to our Evaluation & Results page, where they can view both numerical results and an interactive graph which provides visual insights, allowing users to explore and analyze the data trends effectively.\n\n\n\nEvaluation & Results Page\n\n\nNumerical Results Display in evaluate_and_visualize.html\n{% if test_loss is defined %}\n    &lt;h2&gt;Evaluation Results:&lt;/h2&gt;\n    &lt;p&gt;Test Loss: {{ test_loss }}&lt;/p&gt;\n    &lt;p&gt;MSE Loss: {{ mse_loss }}&lt;/p&gt;\n    &lt;p&gt;RMSE Loss: {{ rmse_loss }}&lt;/p&gt;\n    &lt;p&gt;R2 Score: {{ r2_score }}&lt;/p&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n{% endif %}\n\nClarity: The page presents evaluation metrics such as Test Loss, Mean Squared Error (MSE) Loss, Root Mean Squared Error (RMSE) Loss, and R-squared (R2) Score in a clear and structured manner using HTML &lt;p&gt; tags. This clarity enhances the understanding of model performance.\nPrecision: The page ensures the precision and accuracy of displayed numerical values, crucial for data analysis. It typically maintains a precision of at least ten decimal places, ensuring data accuracy for in-depth analysis and comparison.\nContextual Rendering: The use of conditional blocks ensures that numerical results are displayed only when relevant data is available, preventing confusion and presenting information contextually.\n\nEmbedding Plotly Graph in evaluate_and_visualize.html\n&lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n\nVisual Analysis: The page enhances data analysis by embedding a Plotly graph within an &lt;iframe&gt;. This interactive graph provides visual insights into trends and patterns, complementing the numerical results.\nInteractivity: Users can interact with the embedded Plotly graph, such as zooming, panning, and hovering over data points to view detailed information. This interactivity fosters a deeper understanding of data trends and anomalies.\nIntegration: The seamless integration of the Plotly graph within the HTML page enhances user experience, allowing for a comprehensive analysis of model performance with both numerical and visual data representations.\n\n\n\n3.2.3 View Data Page\nBy clicking the “View Data” button, users are directed to the data page, where all previously uploaded data files are displayed. Each file is accompanied by a “View” button on the right-hand side, allowing users to view the uploaded data online with a single click.\n\n\n\nView Data Page\n\n\nFile Listing in view_data.html\n&lt;!-- Table body section to display the content. --&gt;\n&lt;tbody&gt;\n    &lt;!-- Loop through each file in the 'files' list passed from the Flask backend. --&gt;\n    {% for file in files %}\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename1=file,\n         filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt; &lt;!-- Link to view data. --&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\nThe “File Name” column displays each uploaded file’s name, fetched from the files list passed from the backend. Within each table row (\n\n), the file name is displayed in the “File Name” column (\n\n{{ file }}\n\n). This ensures that users can easily identify and select the files they want to view.\n\nActionable Links in view_data.html\n&lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n\nThe “Actions” column provides a convenient “View” link for each file, allowing users to seamlessly navigate to detailed data views with a single click. This intuitive design enhances the overall user experience and promotes efficient data exploration.\nThe “View” links are dynamically generated using Flask’s powerful url_for function, ensuring accurate and reliable navigation to the corresponding data views.\n\n\n\n3.2.4 View Uploaded Data Page\nWhen users click the “View” button on the View Data Page, they are seamlessly navigated to a dynamically generated web page that displays the data they have previously uploaded. This feature provides users with a convenient and intuitive way to access and examine their uploaded datasets within the application, enhancing the overall user experience and facilitating efficient data analysis.\n\n\n\nView Uploaded Data Page\n\n\nDynamic Content Rendering in view_uploaded_data.html\nThe &lt;tbody&gt; section of the table dynamically displays uploaded files. This functionality is achieved through the use of server-side templating, specifically with Jinja2 in Flask, allowing for iteration over a list of files and rendering each as a row in the table.\n\nFunctionality: Iteration over the files array to create a table row for each file.\nData Binding: Server-side rendering with { file } to bind file names directly into the table.\nDynamic URL Generation: The url_for function generates actionable links for each file, enabling user interaction.\n\nHere is the code snippet in view_uploaded_data.html illustrating this functionality:\n&lt;tbody&gt;\n    &lt;!-- Table body section to display the content. --&gt;\n    {% for file in files %}\n    &lt;!-- Loop through each file in the 'files' list\n     passed from the Flask backend. --&gt;\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', \n        filename1=file, \n        filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\n\n3.2.5 View Prediction Page\nUpon selecting the “View Prediction” button on the initial interface, users are directed to a page displaying test set predictions, featuring an interactive graph created with Plotly. This visualization fosters an engaging user experience, permitting detailed examination of the predictions. The graph’s interactive features—zoom, pan, and data point hover—provide enriched informational access, allowing tailored analytical perspectives.\n\n\n\nView Prediction Page\n\n\nThe graph offers intuitive controls for a seamless user experience. Users can double-click to revert to the original zoom level after examining specific intervals. The operation bar in the upper right corner allows users to download the plot as a PNG, autoscale the axes, and reset the axes effortlessly.\n\n\n\nPrediction Focused on Certain Interval\n\n\n\n\n\nOperation Bar\n\n\nDynamic Plot Rendering with Plotly in plot.html\n&lt;script src=\"https://cdn.plot.ly/plotly-latest.min.js\"&gt;&lt;/script&gt;\n&lt;div id=\"plot\"&gt;&lt;/div&gt;\n&lt;script&gt;\n    var plot_path = \"{{ plot_path }}\";\n    Plotly.d3.html(plot_path, function(error, data) {\n        if (error) {\n            return console.warn(error);\n        }\n        document.getElementById('plot').innerHTML = data;\n    });\n&lt;/script&gt;\n\nIntegration with Plotly: The inclusion of the Plotly library through the &lt;script&gt; tag is a significant aspect of this template.\nAsynchronous Data Fetching: The JavaScript block fetches the plot data asynchronously using Plotly’s d3.html function. This method loads the plot data from a specified path (plot_path), which is dynamically provided by the server-side application. This approach ensures that the webpage remains responsive and that the plot is updated seamlessly without the need for a full page reload.\nDynamic Content Loading: The template utilizes an empty\n\nelement with the id plot, which serves as a placeholder for the graph. The actual content of the graph is loaded dynamically through JavaScript, enabling the webpage to render data-driven plots efficiently.\n\nConditional Rendering and Link Generation in show_prediction.html\n{% if prediction %}\n    &lt;h3&gt;Predicted Mean: {{ prediction }}&lt;/h3&gt;\n    &lt;p&gt;&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;View Test Set Predictions Plot&lt;/a&gt;&lt;/p&gt;\n{% else %}\n    &lt;p&gt;No prediction available&lt;/p&gt;\n{% endif %}\n&lt;a href=\"{{ url_for('index') }}\" class=\"btn btn-primary\"&gt;Go Back&lt;/a&gt;\n\nConditional Content Display: The template employs Jinja2’s conditional syntax {% if prediction %} to check the presence of a prediction variable. This approach ensures that the user interface adapts to the data context, displaying the prediction results when available. If the prediction variable contains a value, the template renders an &lt;h3&gt; tag showing the predicted mean, enhancing the user’s understanding of the model output.\nDynamic Link Creation: The template dynamically generates a link to a plot (&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;) when prediction data is available. This link, opened in a new tab (target=“_blank”), leads to a detailed visualization of the test set predictions."
  },
  {
    "objectID": "posts/New/index.html#summary",
    "href": "posts/New/index.html#summary",
    "title": "PIC16B Final Project Report",
    "section": "Summary",
    "text": "Summary\nOur web application, through its meticulously designed templates and key features, offers a streamlined and enriched user experience. We are committed to enabling users to efficiently manage, analyze, and interpret their data within a cohesive and intuitive environment. By providing a user-friendly interface and powerful functionality, we sincerely aim to empower users to harness the full potential of their data. Our goal is to support users in making informed decisions and fostering a deeper understanding of their analytical contexts."
  },
  {
    "objectID": "posts/New/index.html#conclusion",
    "href": "posts/New/index.html#conclusion",
    "title": "PIC16B Final Project Report",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nBased on above step-by-step instruction and illustrations about how we initiate our project of creating a 1D CNN model for predicting the intrinsic values of options and developing a Flask web application for operationalizing the model, we have successfully demonstrated the process of constructing a robust model for financial-related data analysis and integrating it into a user-friendly web interface. Our project embodies various stages, including data preprocessing, model development, training, evaluation, and web application deployment, thereby showcasing the end-to-end process of building a practical machine learning application.\nRegarding the ethical ramifications of our project, we emphasize that due to the limitations of data and project complexity, this webapp should NEVER be used for ALL kinds of profit-making activities such as investment, but is only suitable for displaying the complexity and insights of option pricing related data. We adhere to ethical guidelines and promote responsible data handling throughout the development process. We respect copyright and ensure that the data used for the creation of WebApps comes from authoritative websites. We consider data privacy, transparency, and ensuring that users of our webapp have control over their data, understand how it is used, and know the entire process of our webapp creation.\nHope it shows some insights of option pricing, and thanks for reading!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/16BHW6/index.html",
    "href": "posts/16BHW6/index.html",
    "title": "PIC16B HW6",
    "section": "",
    "text": "The rapid spread of fake news, fueled by the internet and unvetted content sharing on digital platforms, has emerged as a significant global concern. In this case, analyzing fake news serves as a crucial defense mechanism. In today’s tutorial, we are going to learn how to develop and assess a fake news classifier using Keras.\nData Source: Our data for this tutorial is from this article\nAhmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).\n\n\n\n\n\nBefore you begin, please update to the latest version of Keras by using the command !pip install keras –upgrade to ensure you have Keras 3 installed. In transitioning to Keras 3, it’s important to note that the model visualization defaults have been modified to exclude layer names and output sizes.\n\n!pip install keras --upgrade\n\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\nCollecting keras\n  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 6.2 MB/s eta 0:00:00\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\nCollecting namex (from keras)\n  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\nCollecting optree (from keras)\n  Downloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 286.8/286.8 kB 26.6 MB/s eta 0:00:00\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\nRequirement already satisfied: typing-extensions&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree-&gt;keras) (4.10.0)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\nInstalling collected packages: namex, optree, keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.15.0\n    Uninstalling keras-2.15.0:\n      Successfully uninstalled keras-2.15.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras&lt;2.16,&gt;=2.15.0, but you have keras 3.1.1 which is incompatible.\nSuccessfully installed keras-3.1.1 namex-0.0.7 optree-0.10.0\n\n\nThe dataset we plan to use hosted a training data set at the below URL. train_url = “https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true”.  We can read it into Python directly, or you can choose to download it to your computer\n\n#import libraries:\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf # TensorFlow is an end-to-end open-source platform for machine learning\n#we utilizes Tensorflow backend instead of JAX (lack of support for string data types)\n#we opt for TensorFlow for our tasks\n\nimport tensorflow_datasets as tfds\nfrom sklearn.model_selection import train_test_split # Function to split datasets into random train and test subsets\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS # A list of common English words usually not informative for modeling\nimport nltk # Natural Language Toolkit, for working with human language data\nfrom nltk.corpus import stopwords  # A collection of stopwords from NLTK\n\n# import tensorflow as tf\nimport re\nimport string # Collection of string constants\nimport keras\nfrom keras import layers, losses  # Core layers and losses for building neural network models\nfrom keras.layers import TextVectorization   # Layer to preprocess and vectorize text data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# for embedding visualization\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"  # Setting the default plotly theme to 'plotly_white'\n\nimport re\nimport string\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, losses # TensorFlow's modules for building layers, models, and defining losses\nfrom tensorflow.keras.layers import Input  # Layer to input data to a model\nimport matplotlib.pyplot as plt\nimport warnings # Module to alert the user about some conditions in a program (this coule be very necessary)\nimport sys # System-specific parameters and functions, used to manipulate the Python runtime environment\n\nNow we write the function acquire_training_data downloads a dataset from a specified URL and loads it into a pandas DataFrame. In this case, it is used to obtain training data for a fake news detection model. The function takes a URL string as an argument, fetches the data from that URL using pandas’ read_csv function, and then returns the loaded data as a DataFrame.\n\n# Download NLTK stopwords\nnltk.download('stopwords')\n# NLTK stopwords (we need english version)\nnltk_stopwords = set(stopwords.words('english'))\n\n#Step 1: Acquire Training Data\ndef acquire_training_data(url):\n    data = pd.read_csv(url)\n    return data\ntrain_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true\"\n#Acquire the training data\ntraining_data = acquire_training_data(train_url)\n# training_data = pd.read_csv(\"./fake_news_train.csv\")\ntraining_data.head()\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\ntitle\ntext\nfake\n\n\n\n\n0\n17366\nMerkel: Strong result for Austria's FPO 'big c...\nGerman Chancellor Angela Merkel said on Monday...\n0\n\n\n1\n5634\nTrump says Pence will lead voter fraud panel\nWEST PALM BEACH, Fla.President Donald Trump sa...\n0\n\n\n2\n17487\nJUST IN: SUSPECTED LEAKER and “Close Confidant...\nOn December 5, 2017, Circa s Sara Carter warne...\n1\n\n\n3\n12217\nThyssenkrupp has offered help to Argentina ove...\nGermany s Thyssenkrupp, has offered assistance...\n0\n\n\n4\n5535\nTrump say appeals court decision on travel ban...\nPresident Donald Trump on Thursday called the ...\n0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n\nWe now will write a function “make_dataset”, which - 1. Change the text to lowercase. - 2. Remove stopwords from the article text and title. - 3. Construct and return a tf.data.Dataset with two inputs and one output. The input should be of the form (title,text) ,and the output should consist only of the fake column. \nSince batch can greatly increase the speeding of traning, we will also need to batch our dataset prior to returning it using “my_data_set.batch(100)”.\n\nimport tensorflow as tf\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\n\n# Download NLTK stopwords\nnltk.download('stopwords')\n\n# Function to create the dataset\n# makde_dataset is implemented as a function, and used to create both the training/validation and testing data sets\ndef make_dataset(data):\n    # Function to preprocess text\n    def preprocess_text(text):\n        # Convert text to lowercase\n        text = text.lower()\n        # Remove punctuation\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        # Remove stopwords using NLTK\n        stopwords_nltk = set(stopwords.words('english'))\n        words = text.split()\n        text = ' '.join([word for word in words if word not in stopwords_nltk])\n\n        # Remove dash \"–\" this step is not required but necessary later.\n        # We want the most frequent words to be meaningful and indicative\n        # So we need to remove \"-\"\n        text = text.replace('–', '')\n        return text\n\n    # Apply preprocessing to title and text columns\n    data['title'] = data['title'].apply(preprocess_text)\n    data['text'] = data['text'].apply(preprocess_text)\n\n    # Create tf.data.Dataset\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {\"title\": data['title'], \"text\": data['text']},  # Inputs\n        data['fake']  # Output\n    ))\n    #Here we make sure that the constructed Dataset has multiple inputs\n\n    # Batch the dataset\n    dataset = dataset.batch(100)\n\n    return dataset\n\n# Example usage:\n# Assuming train_data is your training DataFrame loaded from the CSV file\ntrain_dataset = make_dataset(training_data)\ntrain_data=train_dataset\n# Example of iterating through the dataset\nfor inputs, output in train_dataset.take(1):\n    print(\"Title:\", inputs['title'][0].numpy())\n    print(\"Text:\", inputs['text'][0].numpy())\n    print(\"Fake:\", output[0].numpy())\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTitle: b'merkel strong result austrias fpo big challenge parties'\nText: b'german chancellor angela merkel said monday strong showing austria antiimmigrant freedom party fpo sunday election big challenge parties speaking news conference berlin merkel added hoping close cooperation austria conservative election winner sebastian kurz european level'\nFake: 0\n\n\n\n\nNow we have constructed our primary Dataset. We split 20% of it to use for validation. Then determining a base rate is also an important step. We will determine the base rate for this data set by examining the labels on the training set.\nInitially, we introduce the split_train_val_dataset function, which is responsible for partitioning the dataset into training and validation subsets. This function takes in a dataset and a validation ratio (defaulting to 0.2, meaning 20% of the data is reserved for validation), then computes the size of the validation set and proceeds to segregate the dataset accordingly.\nFollowing this, the function acquire_training_data is invoked to fetch the test dataset from a specified URL, mirroring the process used for acquiring the training data.\nThen we need to define the calculate_base_rate function on the training data to ascertain the base rate, the number of fake news articles, and the number of real news articles, subsequently printing these statistics.\n\ndef split_train_val_dataset(dataset, val_ratio=0.2): #the ratio fo validation set, we set 0.2 (20%)\n    # Determine sizes of train, val\n    val_size = int(val_ratio * len(dataset))\n\n    # Split dataset into train, validation\n    train_dataset = dataset.skip(val_size)\n    val_dataset = dataset.take(val_size)\n\n    return train_dataset, val_dataset\n\n# Split the training and validation data sets using a function\ntrain_data, val_data= split_train_val_dataset(train_data, val_ratio=0.2)\ntrain=train_data\nval=val_data\ntest_url=\"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/fake_news_test.csv\"\ntest_dataset = acquire_training_data(test_url)\n# test_dataset = pd.read_csv(\"./fake_news_test.csv\")\ntest_data = make_dataset(test_dataset)\n\n# Step 5: Calculate base rate\ndef calculate_base_rate(data):\n    # Count the number of fake news and real news articles\n    num_fake = sum(data['fake'])\n    num_real = len(data) - num_fake\n\n    # Calculate the proportion of fake news articles in the dataset\n    fake_proportion = num_fake / len(data)\n\n    # For the Base Rate for the data set：\n    # The base rate represents the proportion of fake news articles in the dataset.\n    # It provides a baseline for evaluating the performance of the fake news detection model.\n    # A higher base rate indicates a larger proportion of fake news articles in the dataset.\n    # The model's performance should be assessed relative to this base rate.\n\n    base_rate = fake_proportion\n\n    return base_rate, num_fake, num_real\n\nbase_rate, num_fake, num_real = calculate_base_rate(training_data)\n\n\nprint(\"Base rate:\", base_rate)\nprint(\"Number of fake news articles:\", num_fake)\nprint(\"Number of real news articles:\", num_real)\n\nBase rate: 0.522963160942581\nNumber of fake news articles: 11740\nNumber of real news articles: 10709\n\n\nThe base rate of 0.5229 indicates that approximately 52.3% of the articles in the dataset are labeled as fake news. This means that if we were to randomly guess the label of an article without using any model or additional information, we would have a 52.3% chance of correctly identifying it as fake news.\nTo enhance our ability to visualize and understand the complex structures of neural networks, we utilize two essential tools: pydot and Graphviz. The installation and utilization of these tools are crucial for generating detailed graphical representations of neural network architectures, aiding in both analysis and debugging processes.\n\n# %pip install pydot\n# After install pydot, it enables our python to do visualization of the architecture of neural networks\n# %pip install graphviz:\n# We need to use this command installs the Graphviz software itself, which is the backend that pydot relies on to generate graphical representations of graphs\n\nNow we are setting up a process for text data preprocessing and vectorization, which is a crucial step in preparing text data for machine learning models, especially in natural language processing (NLP) tasks. The goal is to transform textual data into a numerical format that a machine learning model can understand and process.\nWe follow these steps: 1.Import Regular Expression Module 2. Measure Execution Time 3. Set Vocabulary Size 4. Define Standardization Function 5. Create TextVectorization Layer 6. Adapt the Vectorization Layer. See explanations in comments to understand their meaning.\n\nimport re\n#1/The `re` module is imported to facilitate the use of regular expressions\n# which will be used for text cleaning and standardization.\n%time # 2/measures the execution time of the code cell\n# 3/Define the size of the vocabulary\nsize_vocabulary = 2000\n#size_vocabulary` is defined as 2000, indicating that the text vectorization\n#process will consider only the top 2000 words by frequency in the dataset.\n\n# 4/Define the standardization function to clean the text data\ndef standardization(input_data):\n    # Convert text to lowercase\n    lowercase = tf.strings.lower(input_data)\n    # Remove punctuation using regular expression\n    no_punctuation = tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')\n    return no_punctuation #standardize the input data for the model.\n\n# 5/Create a TextVectorization layer, specifying how text should be vectorized.\n# This layer will standardize the text using the previously defined function, tokenize it into words, and convert these tokens into integers.\ntitle_vectorize_layer = tf.keras.layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,  # limites the size of the vocabulary\n    output_mode='int',\n    output_sequence_length=500 # sets the length of the ouputseuqnece to 500\n)\n\n# 6/Adapt the TextVectorization layer to the training data:\ntitle_vectorize_layer.adapt(train_data.map(lambda x, y: x[\"title\"]))\n# This line adapts the title_vectorize_layer to the titles in train_data to learn the vocabulary for text vectorization.\n\nCPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 4.77 µs\n\n\n\n\n\n\nLet’s dive into an exploration using Keras models to tackle a particular question in media analysis: “Which approach yields better results in detecting fake news: focusing solely on the article’s title, delving into the full text, or examining both?”  To investigate this, we’re going to set up three distinct models.\n\n\n\nModel\nInput\n\n\n\n\nModel 1\nOnly the article title as an input\n\n\nModel 2\nOnly the article text as an input\n\n\nModel 3\nBoth the article title and the article text as input\n\n\n\nTo effectively process and analyze text data for our fake news detection task, we will first establish a foundational setup for text vectorization. This involves defining the vocabulary size and creating standardization functions to clean our text data by converting it to lowercase and removing punctuation. Then, we instantiate two TextVectorization layers: one for the titles and another for the full text of the articles. These layers will transform the raw text into numerical data that our machine learning models can understand.\nWe prepare the text data by mapping our train_data to separate the titles and the body text, which will then be fed into the respective vectorization layers to learn the vocabulary and prepare the data for modeling.\nFinally, we use the function train_and_plot_history to train our model and visualize its performance over time, focusing on tracking the accuracy across both training and validation sets to gauge the model’s learning efficiency and generalization capability.\n\n#Model Prep\nsize_vocabulary = 2000 # Like we did before, we set the maximum number of words to include in the vocabulary\n\ndef standardization(input_data): # The function for standardizing text data, we already introduced this before\n    lowercase = tf.strings.lower(input_data)\n    no_punctuation = tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')\n    return no_punctuation\n\ntitle_vectorize_layer = TextVectorization(standardize=standardization, # we introduced this before\n                                          max_tokens=size_vocabulary,\n                                          output_mode='int',\n                                          output_sequence_length=500)\n\ntext_vectorize_layer = TextVectorization(standardize=standardization, # Anoth TextVectorization layer for processing the full text of the articles\n                                         max_tokens=size_vocabulary,\n                                         output_mode='int',\n                                         output_sequence_length=500)\n\ntrain_titles = train_data.map(lambda x, y: x[\"title\"]) # Prepare the title data from the training set for vectorization\ntrain_text = train_data.map(lambda x, y: x[\"text\"]) # Prepare the full text data from the training set for vectorization\n\ntitle_vectorize_layer.adapt(train_titles)\ntext_vectorize_layer.adapt(train_text)\n\ndef train_and_plot_history(model, train_data, val_data, epochs=50):\n    history = model.fit(train_data, validation_data=val_data, epochs=epochs, verbose=False)\n    plt.plot(history.history[\"accuracy\"], label=\"training\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(f'Model Training History')\n    plt.legend()\n    plt.show()\n\n\n\nNow let’s begin to construct the model 1 for article title only. We use the function create_title_model() function builds a TensorFlow model for title classification. It starts with vectorizing the text input, then processes it through an embedding layer, and applies dropout for regularization. The model features a GlobalAveragePooling1D layer and a dense layer for feature extraction, leading in a binary classification output. We can optimize the model for accuracy using the Adam optimizer and sparse categorical crossentropy, making it suitable for tasks requiring discernment between two classes in textual datasets. Below is a gentel introduction to the Adam Optimization Algorithm if you are interested: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n\n# Define and compile title model\ndef create_title_model():\n    # Input layer\n    title_input = tf.keras.Input(shape=(1,), dtype=tf.string, name=\"title\")\n    # Apply the title_vectorize_layer to the title_input\n    title_features = title_vectorize_layer(title_input)\n    # Embedding layer\n    title_features = layers.Embedding(size_vocabulary, output_dim=3, name=\"embedding_title\")(title_features)\n    # Apply Dropout regularization to the embedded title features to reduce overfitting\n    title_features = layers.Dropout(0.2)(title_features)\n    # Reduce the spatial dimensions and obtain a fixed-length vector\n    title_features = layers.GlobalAveragePooling1D()(title_features)\n    # Apply another Dropout regularization to the pooled title features\n    title_features = layers.Dropout(0.2)(title_features)\n    # Add a Dense layer with 32 units and ReLU activation for further feature transformation\n    title_features = layers.Dense(32, activation='relu')(title_features)\n    # Add the final output layer with 2 units (assuming binary classification)\n    output = layers.Dense(2, activation='sigmoid',name=\"fake\")(title_features)\n\n    model = tf.keras.Model(inputs=title_input, outputs=output)\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model\n\n# Now we can return Returns a compiled TensorFlow model ready for training on title data.\n\nNow we import necessary functionalities from IPython.display and tensorflow.keras.utils for displaying images and plotting the model structure.  Then you can see the model’s structure is summarized and visualized using model.summary() and plot_model(), respectively, providing a clear representation of the layers and flow of data within the network. The resulting model diagram is displayed in the notebook for inspection.  Finally, we deploy train_and_plot_history() function we defined before, train the model using the provided training and validation datasets, and to plot the training history, aiding in the evaluation of the model’s performance over epochs.\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile title model\nmodel1 = create_title_model()\nmodel1.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 1 Summary:\")\nmodel1.summary()\nplot_model(model1, to_file='model1.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model1.png'))\n\n# Train and plot history for model1\ntrain_and_plot_history(model1, train, val)\n\n\nModel 1 Summary:\n\n\nModel: \"functional_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ title (InputLayer)                   │ (None, 1)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ text_vectorization_1                 │ (None, 500)                 │               0 │\n│ (TextVectorization)                  │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_title (Embedding)          │ (None, 500, 3)              │           6,000 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (Dropout)                    │ (None, 500, 3)              │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d             │ (None, 3)                   │               0 │\n│ (GlobalAveragePooling1D)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (Dropout)                  │ (None, 3)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (Dense)                        │ (None, 32)                  │             128 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ fake (Dense)                         │ (None, 2)                   │              66 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 6,194 (24.20 KB)\n\n\n\n Trainable params: 6,194 (24.20 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:599: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n  output, from_logits = _get_logits(\n\n\n\n\n\n\n\n\n\n\n\n\nNow we come to our second model, which focus on article text only. Similar to the title model, it starts with an input layer designed to receive text data. The input is then transformed through a vectorization layer, followed by an embedding layer to capture textual features. We keep optimize the model for accuracy using the Adam optimizer and sparse categorical crossentropy, making it suitable for tasks requiring discernment between two classes in textual datasets.\n\n# Define and compile text model\ndef create_text_model():\n    # Define the input layer for the model, specifying the expected shape and data type for text inputs\n    text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name=\"text\")\n\n    # Vectorize the text input; this converts strings into numerical representations that can be processed by the model\n    text_features = text_vectorize_layer(text_input)\n\n    # Apply an embedding layer to create dense vector representations of the text, capturing semantic meanings of words\n    text_features = layers.Embedding(size_vocabulary, output_dim=7, name=\"embedding_text\")(text_features)\n\n    # Prevent overfitting by randomly setting a fraction of input units to 0 at each update during training\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Use this to reduce the dimensions of the feature map and generate a fixed size output vector\n    text_features = layers.GlobalAveragePooling1D()(text_features)\n\n    # Another dropout layer post-pooling for further regularization\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Introduce a dense layer to learn non-linear combinations of features with ReLU activation for non-linearity\n    text_features = layers.Dense(32, activation='relu')(text_features)\n\n    # Final dense layer with sigmoid activation for binary classification output\n    output = layers.Dense(2, activation='sigmoid', name=\"fake\")(text_features)\n\n    model = tf.keras.Model(inputs=text_input, outputs=output) # Finally, construct the model object with text input and output layers, encapsulating the entire network\n     # Compile the model with Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric for evaluation\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model  # Return the fully constructed and compiled model\n\nSimilarly, we initializes and compiles a model2 using create_text_model(), then visualizes its structure and trains it on provided datasets, displaying the training history\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile text model 2\nmodel2 = create_text_model()\nmodel2.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 2 Summary:\")\nmodel2.summary()\nplot_model(model2, to_file='model2.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model2.png'))\n# Train and plot history for model3\ntrain_and_plot_history(model2, train, val)\n\n\nModel 2 Summary:\n\n\nModel: \"functional_3\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text (InputLayer)                    │ (None, 1)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ text_vectorization_2                 │ (None, 500)                 │               0 │\n│ (TextVectorization)                  │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_text (Embedding)           │ (None, 500, 7)              │          14,000 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (Dropout)                  │ (None, 500, 7)              │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d_1           │ (None, 7)                   │               0 │\n│ (GlobalAveragePooling1D)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (Dropout)                  │ (None, 7)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (Dense)                      │ (None, 32)                  │             256 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ fake (Dense)                         │ (None, 2)                   │              66 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 14,322 (55.95 KB)\n\n\n\n Trainable params: 14,322 (55.95 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we proceed to the third and the last model. We now build and compilea a combined neural network model that processes titles and texts simultaneously for binary classification. The model has two input layers, one for titles and another for text, which are then independently vectorized and embedded. Both title and text pathways undergo dropout regularization and global average pooling before their features are concatenated. The combined features are then passed through a dense layer to produce the final binary classification output.\n\n# Define and compile combined model\ndef create_combined_model():\n    # Input layers for titles and texts with string data type\n    titles_input = tf.keras.Input(shape=(1,), name=\"title\", dtype=\"string\")\n    text_input = tf.keras.Input(shape=(1,), name=\"text\", dtype=\"string\")\n\n    # Vectorize the title and text inputs to numerical representations\n    title_features = title_vectorize_layer(titles_input)\n    text_features = text_vectorize_layer(text_input)\n\n    # Embedding layers to create dense vector representations for titles and texts\n    title_features = layers.Embedding(size_vocabulary, output_dim=3, name=\"embedding_title\")(title_features)\n    text_features = layers.Embedding(size_vocabulary, output_dim=7, name=\"embedding_text\")(text_features)\n\n    # Dropout layers to reduce overfitting by randomly omitting features during training\n    title_features = layers.Dropout(0.2)(title_features)\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Global average pooling to reduce each set of features to a single vector\n    title_features = layers.GlobalAveragePooling1D()(title_features)\n    text_features = layers.GlobalAveragePooling1D()(text_features)\n\n    # Dense layers to further process and transform the pooled features\n    title_features = layers.Dense(32, activation='relu')(title_features)\n    text_features = layers.Dense(32, activation='relu')(text_features)\n\n    # Concatenation of title and text features for combined analysis\n    main = layers.concatenate([title_features, text_features], axis=1)\n    # Final dense layer for binary classification output\n    output = layers.Dense(2, name=\"fake\")(main)\n    # Assembling the model with defined inputs and output\n    model = tf.keras.Model(inputs=[titles_input, text_input], outputs=output)\n\n    # Compiling the model with Adam optimizer and sparse categorical cross-entropy loss\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model\n\nSimilar to what we did before, we initializes and compiles a model3 using create_text_model(), then visualizes its structure and trains it on provided datasets, displaying the training history\n\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile combine model\nmodel3= create_combined_model()\nmodel3.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 3 Summary:\")\nmodel3.summary()\nplot_model(model3, to_file='model3.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model3.png'))\n\n# Train and plot history for model3\ntrain_and_plot_history(model3, train, val)\n\n\nModel 3 Summary:\n\n\nModel: \"functional_5\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ title (InputLayer)        │ (None, 1)              │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text (InputLayer)         │ (None, 1)              │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization_1      │ (None, 500)            │              0 │ title[0][0]            │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization_2      │ (None, 500)            │              0 │ text[0][0]             │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_title           │ (None, 500, 3)         │          6,000 │ text_vectorization_1[… │\n│ (Embedding)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_text            │ (None, 500, 7)         │         14,000 │ text_vectorization_2[… │\n│ (Embedding)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (Dropout)       │ (None, 500, 3)         │              0 │ embedding_title[0][0]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (Dropout)       │ (None, 500, 7)         │              0 │ embedding_text[0][0]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (None, 3)              │              0 │ dropout_4[0][0]        │\n│ (GlobalAveragePooling1D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (None, 7)              │              0 │ dropout_5[0][0]        │\n│ (GlobalAveragePooling1D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (Dense)           │ (None, 32)             │            128 │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (Dense)           │ (None, 32)             │            256 │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (Concatenate) │ (None, 64)             │              0 │ dense_2[0][0],         │\n│                           │                        │                │ dense_3[0][0]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ fake (Dense)              │ (None, 2)              │            130 │ concatenate[0][0]      │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n\n\n\n Total params: 20,514 (80.13 KB)\n\n\n\n Trainable params: 20,514 (80.13 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we evaluate three models (model1, model2, model3) on both validation and training datasets, calculating and printing their loss and accuracy metrics:\n\n# Evaluate model1, model 2, model 3 on the validation dataset and training dataset\nmodels = [model1, model2, model3]\ndataset_names = [\"Validation\", \"Training\"]\ndatasets = [val, train]\n\nfor i, model in enumerate(models, start=1):\n    for dataset_name, dataset in zip(dataset_names, datasets):\n        loss, accuracy = model.evaluate(dataset)\n        print(f\"Model {i} {dataset_name} Accuracy:\", accuracy)\n\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.9163 - loss: 0.2051\nModel 1 Validation Accuracy: 0.9082221984863281\n180/180 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9119 - loss: 0.2019\nModel 1 Training Accuracy: 0.9130870699882507\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.9734 - loss: 0.0907\nModel 2 Validation Accuracy: 0.9733333587646484\n180/180 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - accuracy: 0.9905 - loss: 0.0294\nModel 2 Training Accuracy: 0.9905287027359009\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.9724 - loss: 0.1055\nModel 3 Validation Accuracy: 0.968666672706604\n180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 9ms/step - accuracy: 0.9882 - loss: 0.0303\nModel 3 Training Accuracy: 0.9894701838493347\n\n\n\n\n\nModel\nTraining Accuracy\nValidation Accuracy\n\n\n\n\nModel 1\n0.9655\n0.9467\n\n\nModel 2\n0.9989\n0.9762\n\n\nModel 3\n0.9998\n0.9849\n\n\n\nOverall, we observe that model 3 demonstrates the best performance among the three models, with the highest training and validation accuracies. Model 2 also performs well but shows a slightly gap between training and validation accuracies compared to Model 3. Model 1, while still achieving good accuracies, has the lowest performance among the three models.\n\n\n\n\n\nNow, we will test our model 3 performance on unseen test data\nWe can download the test data here : “test_url =”https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true”“. Previously, in data preparation section (Part 2), we already convert this data using the make_dataset function we defined. Below is a recap:\n# Split the training and validation data sets using a function\ntrain_data, val_data = split_train_val_dataset(train_data, val_ratio=0.2)\ntrain = train_data\nval = val_data\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/fake_news_test.csv\"\ntest_dataset = acquire_training_data(test_url)\n\ntest_data = make_dataset(test_dataset)\nNow we evaluate model 3 on the data: we evaluated Model 3 using test data and prints the evaluation results (test loss and accuracy), then visualizes these results using a bar chart to compare the metrics.\n\n# Evaluate Model 3\nevaluation_result = model3.evaluate(test_data)\n\n# Print evaluation results\nprint(\"Test Loss:\", evaluation_result[0])\nprint(\"Test Accuracy:\", evaluation_result[1])\n\n# Print visualization\nplt.bar([\"Loss\", \"Accuracy\"], evaluation_result, color=['blue', 'green'])\nplt.xlabel('Metrics')\nplt.ylabel('Values')\nplt.title('Model3 Evaluation Results on Test Data')\nplt.show()\n\n225/225 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step - accuracy: 0.9709 - loss: 0.1103\nTest Loss: 0.10525856167078018\nTest Accuracy: 0.9708672761917114\n\n\n\n\n\n\n\n\n\nBased on the provided test results, if we used the model as a fake news detector, we would be correct approximately 98% of the time. A test accuracy of 98% suggests that the model has learned to distinguish between real and fake news with high accuracy based on the given dataset.\n\n\n\nNow it could be fun to look at the embedding learned by our model. We need to comment on at least 5 words whose location in the embedding you find interpretable.\n\n\nPCA is a dimensionality reduction technique that aims to transform high-dimensional data into a lower-dimensional space while preserving the most important information. It identifies the principal components, which are the directions of maximum variance in the data.\nBy applying PCA to the learned word embeddings, we can reduce their dimensionality and visualize them in a lower-dimensional space, such as 2D or 3D. This allows us to understand the structure and relationships between the word embeddings in a more interpretable way.\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\n\"\"\"\nWe performs Principal Component Analysis (PCA) on the embedding weights obtained from a trained model\nto reduce dimensionality and analyze the word embeddings. It identifies and prints the top words based on\nembedding magnitudes, then visualizes all embeddings in a 3D scatter plot using Plotly Express.\n\nWe assumes the availability of `model1` and `title_vectorize_layer` from which it extracts embedding\nweights and vocabulary, respectively. The embeddings are reduced to three dimensions using PCA, and the words\nare then ranked and displayed based on the norm of their embeddings. Finally, a 3D scatter plot is generated\nto visually explore the word embeddings space.\n\"\"\"\n\n# Assuming you have obtained the embedding weights and vocabulary\n# Replace 'weights' and 'vocab' with actual values\nweights = model1.get_layer('embedding_title').get_weights()[0]  # Example embedding weights\nvocab = title_vectorize_layer.get_vocabulary()  # Example vocabulary\n\n# Perform PCA for dimensionality reduction\npca = PCA(n_components=3)\nweights_pca = pca.fit_transform(weights)\n\n# Extract embeddings for each word\nembedding_dict = {word: embedding for word, embedding in zip(vocab, weights_pca)}\n\n# Sort words based on embedding values\nsorted_words = sorted(embedding_dict, key=lambda x: np.linalg.norm(embedding_dict[x]), reverse=True)\n\n# Print the top words with highest embeddings\nnum_top_words = 5\nprint(f\"Top {num_top_words} words with highest embeddings:\")\nfor word in sorted_words[:num_top_words]:\n    print(f\"Word: {word}, Embedding: {embedding_dict[word]}\")\n\n# Perform additional analysis and commentary on the embeddings\n\n# Create DataFrame for plotting\nembedding_df = pd.DataFrame({\n    'word': vocab,\n    'x0': weights_pca[:, 0],\n    'x1': weights_pca[:, 1],\n    'x2': weights_pca[:, 2]\n})\n\n\nTop 5 words with highest embeddings:\nWord: video, Embedding: [17.325254    0.7191003   0.11118298]\nWord: trump’s, Embedding: [11.223864    0.1662118   0.04897542]\nWord: watch, Embedding: [9.809493   0.2826847  0.06626459]\nWord: breaking, Embedding: [ 9.319804    0.02514263 -0.03231914]\nWord: gop, Embedding: [ 8.889053    0.01651091 -0.01013779]\n\n\n\n1st:video: With an embedding of [17.325254, 0.7191003, 0.11118298], “video” stands out with the highest vector magnitude. This prominent position implies a strong presence or frequent usage in the dataset, possibly indicating its significance or centrality in the content.\n2nd:trump’s: The embedding [11.223864, 0.1662118, 0.04897542] places “trump’s” as the second most significant term. Its vector shows it has a substantial, albeit lesser magnitude than “video,” suggesting its importance in the analyzed text, potentially related to political content.\n3rd:watch: “watch” has an embedding of [9.809493, 0.2826847, 0.06626459], ranking third. This suggests it is a key term, possibly associated with content that calls for attention or action, such as news or media.\n4th: breaking: With an embedding of [9.319804, 0.02514263, -0.03231914], “breaking” appears as the fourth word. Its presence might indicate frequent use in urgent or newsworthy contexts, highlighting its relevance in news-related discourse.\n5th:gop: The embedding [8.889053, 0.01651091, -0.01013779] for “gop” positions it fifth, suggesting its significant role in discussions, likely related to political topics, given its association with the Republican Party in the United States.\n\n\n\n\nT-SNE is a widely used technique for visualizing high-dimensional data in a lower-dimensional space, such as 2D or 3D. It aims to preserve the local structure of the data while revealing global patterns and clusters. By visualizing the word embeddings using t-SNE, we can gain insights into the semantic structure and relationships between words. Words that are semantically similar or related are expected to be clustered together in the t-SNE plot.\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\n\"\"\"\nNow we applies t-SNE (t-Distributed Stochastic Neighbor Embedding) to the embedding weights from a neural network model,\nreducing the dimensionality to three components for visualization and analysis of word embeddings.\n\nThe process involves extracting embedding weights and vocabulary from the specified model layer, then applying t-SNE to transform\nthese high-dimensional embeddings into a 3D space. The script identifies the top words with the highest embedding magnitudes,\nprints them, and then creates a 3D scatter plot using Plotly Express to visualize the distribution and relationships of word embeddings.\n\nKey steps include:\n- Obtaining embedding weights and vocabulary from the model.\n- Reducing dimensionality of embeddings with t-SNE.\n- Sorting and displaying words with the highest embeddings.\n- Visualizing the embeddings in a 3D scatter plot, with interactive features to explore word relationships.\n\"\"\"\n\n# Assuming you have obtained the embedding weights and vocabulary\n# Replace 'weights' and 'vocab' with actual values\nweights = model1.get_layer('embedding_title').get_weights()[0]  # Example embedding weights\nvocab = title_vectorize_layer.get_vocabulary()  # Example vocabulary\n\n# Perform t-SNE for dimensionality reduction\ntsne = TSNE(n_components=3)\nweights_tsne = tsne.fit_transform(weights)\n\n# Extract embeddings for each word\nembedding_dict = {word: embedding for word, embedding in zip(vocab, weights_tsne)}\n\n# Sort words based on embedding values\nsorted_words = sorted(embedding_dict, key=lambda x: np.linalg.norm(embedding_dict[x]), reverse=True)\n\n# Print the top words with highest embeddings\nnum_top_words = 5\nprint(f\"Top {num_top_words} words with highest embeddings:\")\nfor word in sorted_words[:num_top_words]:\n    print(f\"Word: {word}, Embedding: {embedding_dict[word]}\")\n\n# Create DataFrame for plotting\nembedding_df = pd.DataFrame({\n    'word': vocab,\n    'x0': weights_tsne[:, 0],\n    'x1': weights_tsne[:, 1],\n    'x2': weights_tsne[:, 2]\n})\n\n\nTop 5 words with highest embeddings:\nWord: talks, Embedding: [-24.842272   -9.705764    3.0962868]\nWord: south, Embedding: [-24.89313   -9.58717    3.052512]\nWord: urges, Embedding: [-24.94897   -9.438914   3.003081]\nWord: turkey, Embedding: [-24.980162   -9.349924    2.9750898]\nWord: says, Embedding: [-24.70634    -9.946184    3.2103448]\n\n\nt-SNE Embedding:\n\ntalks: This word has the highest embedding in the t-SNE plot, with coordinates [-24.842272, -9.705764, 3.0962868]. Its location suggests that it is relatively distinct from other words in the embedding space.\nsouth: The word “south” has the second-highest embedding, with coordinates [-24.89313, -9.58717, 3.052512]. Its proximity to “talks” indicates that these words may share some semantic similarities or appear in similar contexts.\nurges: The word “urges” has the third-highest embedding, with coordinates [-24.94897, -9.438914, 3.003081]. Its location near “talks” and “south” suggests that it is also semantically related to these words.\nturkey: The word “turkey” has the fourth-highest embedding, with coordinates [-24.980162, -9.349924, 2.9750898]. Its proximity to the previous words indicates that it may share some contextual similarities with them.\nsays: The word “says” has the fifth-highest embedding, with coordinates [-24.70634, -9.946184, 3.2103448]. Its location close to the other top words suggests that it is semantically related to them.\n\n\n\n\nNow it’s thrilled to showcase both PCA and t-SNE’s 3-dimensional embeddings. How exciting!\nTo begin, we configure Plotly to utilize an “iframe” renderer, ideal for displaying plots in various environments such as Jupyter notebooks or web interfaces. Next, we generate a 3D scatter plot representing word embeddings, where each point represents a word. This plot provides interactivity, allowing users to hover over a point to reveal the corresponding word. Furthermore, we save the plot as an HTML file for easy access and display it inline for immediate visualization.\n\n\n\n# Set the renderer to \"iframe\"\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\n# Create a scatter plot using Plotly Express\nfig = px.scatter_3d(embedding_df, x='x0', y='x1', z='x2', hover_name='word')\n# Each point represents a word, positioned based on its 'x0', 'x1', and 'x2' coordinates\n# Hovering over a point will show the corresponding word\n\n# Save the plot as an HTML file\noutput_path = \"scatter_plot.html\"\nfig.write_html(output_path)\n\n# Display the plot\nfig.show()\n\n\n\n\n\n\n\n\n\n# Set the renderer to \"iframe\"\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\n# Create a scatter plot using Plotly Express\nfig = px.scatter_3d(embedding_df, x='x0', y='x1', z='x2', hover_name='word')\n# Each point represents a word, positioned based on its 'x0', 'x1', and 'x2' coordinates\n# Hovering over a point will show the corresponding word\n\n# Save the plot as an HTML file\noutput_path = \"tsne_scatter_plot.html\"\nfig.write_html(output_path)\n\n# Display the plot\nfig.show()\n\n\n\n\n\n\n\nNow we have successfully presented the learned word embeddings through visualizations using PCA and t-SNE. The analysis has provided insights into the positioning and interpretation of at least five words within the embedding space.\nThank you for dedicating your time to explore and understand this project."
  },
  {
    "objectID": "posts/16BHW6/index.html#introduction",
    "href": "posts/16BHW6/index.html#introduction",
    "title": "PIC16B HW6",
    "section": "",
    "text": "The rapid spread of fake news, fueled by the internet and unvetted content sharing on digital platforms, has emerged as a significant global concern. In this case, analyzing fake news serves as a crucial defense mechanism. In today’s tutorial, we are going to learn how to develop and assess a fake news classifier using Keras.\nData Source: Our data for this tutorial is from this article\nAhmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138)."
  },
  {
    "objectID": "posts/16BHW6/index.html#instruction",
    "href": "posts/16BHW6/index.html#instruction",
    "title": "PIC16B HW6",
    "section": "",
    "text": "Before you begin, please update to the latest version of Keras by using the command !pip install keras –upgrade to ensure you have Keras 3 installed. In transitioning to Keras 3, it’s important to note that the model visualization defaults have been modified to exclude layer names and output sizes.\n\n!pip install keras --upgrade\n\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\nCollecting keras\n  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 6.2 MB/s eta 0:00:00\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\nCollecting namex (from keras)\n  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\nCollecting optree (from keras)\n  Downloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 286.8/286.8 kB 26.6 MB/s eta 0:00:00\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\nRequirement already satisfied: typing-extensions&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree-&gt;keras) (4.10.0)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\nInstalling collected packages: namex, optree, keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.15.0\n    Uninstalling keras-2.15.0:\n      Successfully uninstalled keras-2.15.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras&lt;2.16,&gt;=2.15.0, but you have keras 3.1.1 which is incompatible.\nSuccessfully installed keras-3.1.1 namex-0.0.7 optree-0.10.0\n\n\nThe dataset we plan to use hosted a training data set at the below URL. train_url = “https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true”.  We can read it into Python directly, or you can choose to download it to your computer\n\n#import libraries:\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf # TensorFlow is an end-to-end open-source platform for machine learning\n#we utilizes Tensorflow backend instead of JAX (lack of support for string data types)\n#we opt for TensorFlow for our tasks\n\nimport tensorflow_datasets as tfds\nfrom sklearn.model_selection import train_test_split # Function to split datasets into random train and test subsets\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS # A list of common English words usually not informative for modeling\nimport nltk # Natural Language Toolkit, for working with human language data\nfrom nltk.corpus import stopwords  # A collection of stopwords from NLTK\n\n# import tensorflow as tf\nimport re\nimport string # Collection of string constants\nimport keras\nfrom keras import layers, losses  # Core layers and losses for building neural network models\nfrom keras.layers import TextVectorization   # Layer to preprocess and vectorize text data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# for embedding visualization\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"  # Setting the default plotly theme to 'plotly_white'\n\nimport re\nimport string\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, losses # TensorFlow's modules for building layers, models, and defining losses\nfrom tensorflow.keras.layers import Input  # Layer to input data to a model\nimport matplotlib.pyplot as plt\nimport warnings # Module to alert the user about some conditions in a program (this coule be very necessary)\nimport sys # System-specific parameters and functions, used to manipulate the Python runtime environment\n\nNow we write the function acquire_training_data downloads a dataset from a specified URL and loads it into a pandas DataFrame. In this case, it is used to obtain training data for a fake news detection model. The function takes a URL string as an argument, fetches the data from that URL using pandas’ read_csv function, and then returns the loaded data as a DataFrame.\n\n# Download NLTK stopwords\nnltk.download('stopwords')\n# NLTK stopwords (we need english version)\nnltk_stopwords = set(stopwords.words('english'))\n\n#Step 1: Acquire Training Data\ndef acquire_training_data(url):\n    data = pd.read_csv(url)\n    return data\ntrain_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true\"\n#Acquire the training data\ntraining_data = acquire_training_data(train_url)\n# training_data = pd.read_csv(\"./fake_news_train.csv\")\ntraining_data.head()\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\ntitle\ntext\nfake\n\n\n\n\n0\n17366\nMerkel: Strong result for Austria's FPO 'big c...\nGerman Chancellor Angela Merkel said on Monday...\n0\n\n\n1\n5634\nTrump says Pence will lead voter fraud panel\nWEST PALM BEACH, Fla.President Donald Trump sa...\n0\n\n\n2\n17487\nJUST IN: SUSPECTED LEAKER and “Close Confidant...\nOn December 5, 2017, Circa s Sara Carter warne...\n1\n\n\n3\n12217\nThyssenkrupp has offered help to Argentina ove...\nGermany s Thyssenkrupp, has offered assistance...\n0\n\n\n4\n5535\nTrump say appeals court decision on travel ban...\nPresident Donald Trump on Thursday called the ...\n0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n\nWe now will write a function “make_dataset”, which - 1. Change the text to lowercase. - 2. Remove stopwords from the article text and title. - 3. Construct and return a tf.data.Dataset with two inputs and one output. The input should be of the form (title,text) ,and the output should consist only of the fake column. \nSince batch can greatly increase the speeding of traning, we will also need to batch our dataset prior to returning it using “my_data_set.batch(100)”.\n\nimport tensorflow as tf\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\n\n# Download NLTK stopwords\nnltk.download('stopwords')\n\n# Function to create the dataset\n# makde_dataset is implemented as a function, and used to create both the training/validation and testing data sets\ndef make_dataset(data):\n    # Function to preprocess text\n    def preprocess_text(text):\n        # Convert text to lowercase\n        text = text.lower()\n        # Remove punctuation\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        # Remove stopwords using NLTK\n        stopwords_nltk = set(stopwords.words('english'))\n        words = text.split()\n        text = ' '.join([word for word in words if word not in stopwords_nltk])\n\n        # Remove dash \"–\" this step is not required but necessary later.\n        # We want the most frequent words to be meaningful and indicative\n        # So we need to remove \"-\"\n        text = text.replace('–', '')\n        return text\n\n    # Apply preprocessing to title and text columns\n    data['title'] = data['title'].apply(preprocess_text)\n    data['text'] = data['text'].apply(preprocess_text)\n\n    # Create tf.data.Dataset\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {\"title\": data['title'], \"text\": data['text']},  # Inputs\n        data['fake']  # Output\n    ))\n    #Here we make sure that the constructed Dataset has multiple inputs\n\n    # Batch the dataset\n    dataset = dataset.batch(100)\n\n    return dataset\n\n# Example usage:\n# Assuming train_data is your training DataFrame loaded from the CSV file\ntrain_dataset = make_dataset(training_data)\ntrain_data=train_dataset\n# Example of iterating through the dataset\nfor inputs, output in train_dataset.take(1):\n    print(\"Title:\", inputs['title'][0].numpy())\n    print(\"Text:\", inputs['text'][0].numpy())\n    print(\"Fake:\", output[0].numpy())\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTitle: b'merkel strong result austrias fpo big challenge parties'\nText: b'german chancellor angela merkel said monday strong showing austria antiimmigrant freedom party fpo sunday election big challenge parties speaking news conference berlin merkel added hoping close cooperation austria conservative election winner sebastian kurz european level'\nFake: 0\n\n\n\n\nNow we have constructed our primary Dataset. We split 20% of it to use for validation. Then determining a base rate is also an important step. We will determine the base rate for this data set by examining the labels on the training set.\nInitially, we introduce the split_train_val_dataset function, which is responsible for partitioning the dataset into training and validation subsets. This function takes in a dataset and a validation ratio (defaulting to 0.2, meaning 20% of the data is reserved for validation), then computes the size of the validation set and proceeds to segregate the dataset accordingly.\nFollowing this, the function acquire_training_data is invoked to fetch the test dataset from a specified URL, mirroring the process used for acquiring the training data.\nThen we need to define the calculate_base_rate function on the training data to ascertain the base rate, the number of fake news articles, and the number of real news articles, subsequently printing these statistics.\n\ndef split_train_val_dataset(dataset, val_ratio=0.2): #the ratio fo validation set, we set 0.2 (20%)\n    # Determine sizes of train, val\n    val_size = int(val_ratio * len(dataset))\n\n    # Split dataset into train, validation\n    train_dataset = dataset.skip(val_size)\n    val_dataset = dataset.take(val_size)\n\n    return train_dataset, val_dataset\n\n# Split the training and validation data sets using a function\ntrain_data, val_data= split_train_val_dataset(train_data, val_ratio=0.2)\ntrain=train_data\nval=val_data\ntest_url=\"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/fake_news_test.csv\"\ntest_dataset = acquire_training_data(test_url)\n# test_dataset = pd.read_csv(\"./fake_news_test.csv\")\ntest_data = make_dataset(test_dataset)\n\n# Step 5: Calculate base rate\ndef calculate_base_rate(data):\n    # Count the number of fake news and real news articles\n    num_fake = sum(data['fake'])\n    num_real = len(data) - num_fake\n\n    # Calculate the proportion of fake news articles in the dataset\n    fake_proportion = num_fake / len(data)\n\n    # For the Base Rate for the data set：\n    # The base rate represents the proportion of fake news articles in the dataset.\n    # It provides a baseline for evaluating the performance of the fake news detection model.\n    # A higher base rate indicates a larger proportion of fake news articles in the dataset.\n    # The model's performance should be assessed relative to this base rate.\n\n    base_rate = fake_proportion\n\n    return base_rate, num_fake, num_real\n\nbase_rate, num_fake, num_real = calculate_base_rate(training_data)\n\n\nprint(\"Base rate:\", base_rate)\nprint(\"Number of fake news articles:\", num_fake)\nprint(\"Number of real news articles:\", num_real)\n\nBase rate: 0.522963160942581\nNumber of fake news articles: 11740\nNumber of real news articles: 10709\n\n\nThe base rate of 0.5229 indicates that approximately 52.3% of the articles in the dataset are labeled as fake news. This means that if we were to randomly guess the label of an article without using any model or additional information, we would have a 52.3% chance of correctly identifying it as fake news.\nTo enhance our ability to visualize and understand the complex structures of neural networks, we utilize two essential tools: pydot and Graphviz. The installation and utilization of these tools are crucial for generating detailed graphical representations of neural network architectures, aiding in both analysis and debugging processes.\n\n# %pip install pydot\n# After install pydot, it enables our python to do visualization of the architecture of neural networks\n# %pip install graphviz:\n# We need to use this command installs the Graphviz software itself, which is the backend that pydot relies on to generate graphical representations of graphs\n\nNow we are setting up a process for text data preprocessing and vectorization, which is a crucial step in preparing text data for machine learning models, especially in natural language processing (NLP) tasks. The goal is to transform textual data into a numerical format that a machine learning model can understand and process.\nWe follow these steps: 1.Import Regular Expression Module 2. Measure Execution Time 3. Set Vocabulary Size 4. Define Standardization Function 5. Create TextVectorization Layer 6. Adapt the Vectorization Layer. See explanations in comments to understand their meaning.\n\nimport re\n#1/The `re` module is imported to facilitate the use of regular expressions\n# which will be used for text cleaning and standardization.\n%time # 2/measures the execution time of the code cell\n# 3/Define the size of the vocabulary\nsize_vocabulary = 2000\n#size_vocabulary` is defined as 2000, indicating that the text vectorization\n#process will consider only the top 2000 words by frequency in the dataset.\n\n# 4/Define the standardization function to clean the text data\ndef standardization(input_data):\n    # Convert text to lowercase\n    lowercase = tf.strings.lower(input_data)\n    # Remove punctuation using regular expression\n    no_punctuation = tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')\n    return no_punctuation #standardize the input data for the model.\n\n# 5/Create a TextVectorization layer, specifying how text should be vectorized.\n# This layer will standardize the text using the previously defined function, tokenize it into words, and convert these tokens into integers.\ntitle_vectorize_layer = tf.keras.layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,  # limites the size of the vocabulary\n    output_mode='int',\n    output_sequence_length=500 # sets the length of the ouputseuqnece to 500\n)\n\n# 6/Adapt the TextVectorization layer to the training data:\ntitle_vectorize_layer.adapt(train_data.map(lambda x, y: x[\"title\"]))\n# This line adapts the title_vectorize_layer to the titles in train_data to learn the vocabulary for text vectorization.\n\nCPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 4.77 µs\n\n\n\n\n\n\nLet’s dive into an exploration using Keras models to tackle a particular question in media analysis: “Which approach yields better results in detecting fake news: focusing solely on the article’s title, delving into the full text, or examining both?”  To investigate this, we’re going to set up three distinct models.\n\n\n\nModel\nInput\n\n\n\n\nModel 1\nOnly the article title as an input\n\n\nModel 2\nOnly the article text as an input\n\n\nModel 3\nBoth the article title and the article text as input\n\n\n\nTo effectively process and analyze text data for our fake news detection task, we will first establish a foundational setup for text vectorization. This involves defining the vocabulary size and creating standardization functions to clean our text data by converting it to lowercase and removing punctuation. Then, we instantiate two TextVectorization layers: one for the titles and another for the full text of the articles. These layers will transform the raw text into numerical data that our machine learning models can understand.\nWe prepare the text data by mapping our train_data to separate the titles and the body text, which will then be fed into the respective vectorization layers to learn the vocabulary and prepare the data for modeling.\nFinally, we use the function train_and_plot_history to train our model and visualize its performance over time, focusing on tracking the accuracy across both training and validation sets to gauge the model’s learning efficiency and generalization capability.\n\n#Model Prep\nsize_vocabulary = 2000 # Like we did before, we set the maximum number of words to include in the vocabulary\n\ndef standardization(input_data): # The function for standardizing text data, we already introduced this before\n    lowercase = tf.strings.lower(input_data)\n    no_punctuation = tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')\n    return no_punctuation\n\ntitle_vectorize_layer = TextVectorization(standardize=standardization, # we introduced this before\n                                          max_tokens=size_vocabulary,\n                                          output_mode='int',\n                                          output_sequence_length=500)\n\ntext_vectorize_layer = TextVectorization(standardize=standardization, # Anoth TextVectorization layer for processing the full text of the articles\n                                         max_tokens=size_vocabulary,\n                                         output_mode='int',\n                                         output_sequence_length=500)\n\ntrain_titles = train_data.map(lambda x, y: x[\"title\"]) # Prepare the title data from the training set for vectorization\ntrain_text = train_data.map(lambda x, y: x[\"text\"]) # Prepare the full text data from the training set for vectorization\n\ntitle_vectorize_layer.adapt(train_titles)\ntext_vectorize_layer.adapt(train_text)\n\ndef train_and_plot_history(model, train_data, val_data, epochs=50):\n    history = model.fit(train_data, validation_data=val_data, epochs=epochs, verbose=False)\n    plt.plot(history.history[\"accuracy\"], label=\"training\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(f'Model Training History')\n    plt.legend()\n    plt.show()\n\n\n\nNow let’s begin to construct the model 1 for article title only. We use the function create_title_model() function builds a TensorFlow model for title classification. It starts with vectorizing the text input, then processes it through an embedding layer, and applies dropout for regularization. The model features a GlobalAveragePooling1D layer and a dense layer for feature extraction, leading in a binary classification output. We can optimize the model for accuracy using the Adam optimizer and sparse categorical crossentropy, making it suitable for tasks requiring discernment between two classes in textual datasets. Below is a gentel introduction to the Adam Optimization Algorithm if you are interested: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n\n# Define and compile title model\ndef create_title_model():\n    # Input layer\n    title_input = tf.keras.Input(shape=(1,), dtype=tf.string, name=\"title\")\n    # Apply the title_vectorize_layer to the title_input\n    title_features = title_vectorize_layer(title_input)\n    # Embedding layer\n    title_features = layers.Embedding(size_vocabulary, output_dim=3, name=\"embedding_title\")(title_features)\n    # Apply Dropout regularization to the embedded title features to reduce overfitting\n    title_features = layers.Dropout(0.2)(title_features)\n    # Reduce the spatial dimensions and obtain a fixed-length vector\n    title_features = layers.GlobalAveragePooling1D()(title_features)\n    # Apply another Dropout regularization to the pooled title features\n    title_features = layers.Dropout(0.2)(title_features)\n    # Add a Dense layer with 32 units and ReLU activation for further feature transformation\n    title_features = layers.Dense(32, activation='relu')(title_features)\n    # Add the final output layer with 2 units (assuming binary classification)\n    output = layers.Dense(2, activation='sigmoid',name=\"fake\")(title_features)\n\n    model = tf.keras.Model(inputs=title_input, outputs=output)\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model\n\n# Now we can return Returns a compiled TensorFlow model ready for training on title data.\n\nNow we import necessary functionalities from IPython.display and tensorflow.keras.utils for displaying images and plotting the model structure.  Then you can see the model’s structure is summarized and visualized using model.summary() and plot_model(), respectively, providing a clear representation of the layers and flow of data within the network. The resulting model diagram is displayed in the notebook for inspection.  Finally, we deploy train_and_plot_history() function we defined before, train the model using the provided training and validation datasets, and to plot the training history, aiding in the evaluation of the model’s performance over epochs.\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile title model\nmodel1 = create_title_model()\nmodel1.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 1 Summary:\")\nmodel1.summary()\nplot_model(model1, to_file='model1.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model1.png'))\n\n# Train and plot history for model1\ntrain_and_plot_history(model1, train, val)\n\n\nModel 1 Summary:\n\n\nModel: \"functional_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ title (InputLayer)                   │ (None, 1)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ text_vectorization_1                 │ (None, 500)                 │               0 │\n│ (TextVectorization)                  │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_title (Embedding)          │ (None, 500, 3)              │           6,000 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (Dropout)                    │ (None, 500, 3)              │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d             │ (None, 3)                   │               0 │\n│ (GlobalAveragePooling1D)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (Dropout)                  │ (None, 3)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (Dense)                        │ (None, 32)                  │             128 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ fake (Dense)                         │ (None, 2)                   │              66 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 6,194 (24.20 KB)\n\n\n\n Trainable params: 6,194 (24.20 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:599: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n  output, from_logits = _get_logits(\n\n\n\n\n\n\n\n\n\n\n\n\nNow we come to our second model, which focus on article text only. Similar to the title model, it starts with an input layer designed to receive text data. The input is then transformed through a vectorization layer, followed by an embedding layer to capture textual features. We keep optimize the model for accuracy using the Adam optimizer and sparse categorical crossentropy, making it suitable for tasks requiring discernment between two classes in textual datasets.\n\n# Define and compile text model\ndef create_text_model():\n    # Define the input layer for the model, specifying the expected shape and data type for text inputs\n    text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name=\"text\")\n\n    # Vectorize the text input; this converts strings into numerical representations that can be processed by the model\n    text_features = text_vectorize_layer(text_input)\n\n    # Apply an embedding layer to create dense vector representations of the text, capturing semantic meanings of words\n    text_features = layers.Embedding(size_vocabulary, output_dim=7, name=\"embedding_text\")(text_features)\n\n    # Prevent overfitting by randomly setting a fraction of input units to 0 at each update during training\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Use this to reduce the dimensions of the feature map and generate a fixed size output vector\n    text_features = layers.GlobalAveragePooling1D()(text_features)\n\n    # Another dropout layer post-pooling for further regularization\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Introduce a dense layer to learn non-linear combinations of features with ReLU activation for non-linearity\n    text_features = layers.Dense(32, activation='relu')(text_features)\n\n    # Final dense layer with sigmoid activation for binary classification output\n    output = layers.Dense(2, activation='sigmoid', name=\"fake\")(text_features)\n\n    model = tf.keras.Model(inputs=text_input, outputs=output) # Finally, construct the model object with text input and output layers, encapsulating the entire network\n     # Compile the model with Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric for evaluation\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model  # Return the fully constructed and compiled model\n\nSimilarly, we initializes and compiles a model2 using create_text_model(), then visualizes its structure and trains it on provided datasets, displaying the training history\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile text model 2\nmodel2 = create_text_model()\nmodel2.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 2 Summary:\")\nmodel2.summary()\nplot_model(model2, to_file='model2.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model2.png'))\n# Train and plot history for model3\ntrain_and_plot_history(model2, train, val)\n\n\nModel 2 Summary:\n\n\nModel: \"functional_3\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ text (InputLayer)                    │ (None, 1)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ text_vectorization_2                 │ (None, 500)                 │               0 │\n│ (TextVectorization)                  │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding_text (Embedding)           │ (None, 500, 7)              │          14,000 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (Dropout)                  │ (None, 500, 7)              │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling1d_1           │ (None, 7)                   │               0 │\n│ (GlobalAveragePooling1D)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (Dropout)                  │ (None, 7)                   │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (Dense)                      │ (None, 32)                  │             256 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ fake (Dense)                         │ (None, 2)                   │              66 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 14,322 (55.95 KB)\n\n\n\n Trainable params: 14,322 (55.95 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we proceed to the third and the last model. We now build and compilea a combined neural network model that processes titles and texts simultaneously for binary classification. The model has two input layers, one for titles and another for text, which are then independently vectorized and embedded. Both title and text pathways undergo dropout regularization and global average pooling before their features are concatenated. The combined features are then passed through a dense layer to produce the final binary classification output.\n\n# Define and compile combined model\ndef create_combined_model():\n    # Input layers for titles and texts with string data type\n    titles_input = tf.keras.Input(shape=(1,), name=\"title\", dtype=\"string\")\n    text_input = tf.keras.Input(shape=(1,), name=\"text\", dtype=\"string\")\n\n    # Vectorize the title and text inputs to numerical representations\n    title_features = title_vectorize_layer(titles_input)\n    text_features = text_vectorize_layer(text_input)\n\n    # Embedding layers to create dense vector representations for titles and texts\n    title_features = layers.Embedding(size_vocabulary, output_dim=3, name=\"embedding_title\")(title_features)\n    text_features = layers.Embedding(size_vocabulary, output_dim=7, name=\"embedding_text\")(text_features)\n\n    # Dropout layers to reduce overfitting by randomly omitting features during training\n    title_features = layers.Dropout(0.2)(title_features)\n    text_features = layers.Dropout(0.2)(text_features)\n\n    # Global average pooling to reduce each set of features to a single vector\n    title_features = layers.GlobalAveragePooling1D()(title_features)\n    text_features = layers.GlobalAveragePooling1D()(text_features)\n\n    # Dense layers to further process and transform the pooled features\n    title_features = layers.Dense(32, activation='relu')(title_features)\n    text_features = layers.Dense(32, activation='relu')(text_features)\n\n    # Concatenation of title and text features for combined analysis\n    main = layers.concatenate([title_features, text_features], axis=1)\n    # Final dense layer for binary classification output\n    output = layers.Dense(2, name=\"fake\")(main)\n    # Assembling the model with defined inputs and output\n    model = tf.keras.Model(inputs=[titles_input, text_input], outputs=output)\n\n    # Compiling the model with Adam optimizer and sparse categorical cross-entropy loss\n    model.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n    return model\n\nSimilar to what we did before, we initializes and compiles a model3 using create_text_model(), then visualizes its structure and trains it on provided datasets, displaying the training history\n\n\nfrom IPython.display import display, Image\nfrom tensorflow.keras.utils import plot_model\n# Create and compile combine model\nmodel3= create_combined_model()\nmodel3.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n\n# Print model summary with output shapes and layer names\nprint(\"\\nModel 3 Summary:\")\nmodel3.summary()\nplot_model(model3, to_file='model3.png', show_shapes=True, show_layer_names=True)\ndisplay(Image(filename='model3.png'))\n\n# Train and plot history for model3\ntrain_and_plot_history(model3, train, val)\n\n\nModel 3 Summary:\n\n\nModel: \"functional_5\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ title (InputLayer)        │ (None, 1)              │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text (InputLayer)         │ (None, 1)              │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization_1      │ (None, 500)            │              0 │ title[0][0]            │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_vectorization_2      │ (None, 500)            │              0 │ text[0][0]             │\n│ (TextVectorization)       │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_title           │ (None, 500, 3)         │          6,000 │ text_vectorization_1[… │\n│ (Embedding)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_text            │ (None, 500, 7)         │         14,000 │ text_vectorization_2[… │\n│ (Embedding)               │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (Dropout)       │ (None, 500, 3)         │              0 │ embedding_title[0][0]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (Dropout)       │ (None, 500, 7)         │              0 │ embedding_text[0][0]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (None, 3)              │              0 │ dropout_4[0][0]        │\n│ (GlobalAveragePooling1D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (None, 7)              │              0 │ dropout_5[0][0]        │\n│ (GlobalAveragePooling1D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (Dense)           │ (None, 32)             │            128 │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (Dense)           │ (None, 32)             │            256 │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (Concatenate) │ (None, 64)             │              0 │ dense_2[0][0],         │\n│                           │                        │                │ dense_3[0][0]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ fake (Dense)              │ (None, 2)              │            130 │ concatenate[0][0]      │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n\n\n\n Total params: 20,514 (80.13 KB)\n\n\n\n Trainable params: 20,514 (80.13 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we evaluate three models (model1, model2, model3) on both validation and training datasets, calculating and printing their loss and accuracy metrics:\n\n# Evaluate model1, model 2, model 3 on the validation dataset and training dataset\nmodels = [model1, model2, model3]\ndataset_names = [\"Validation\", \"Training\"]\ndatasets = [val, train]\n\nfor i, model in enumerate(models, start=1):\n    for dataset_name, dataset in zip(dataset_names, datasets):\n        loss, accuracy = model.evaluate(dataset)\n        print(f\"Model {i} {dataset_name} Accuracy:\", accuracy)\n\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.9163 - loss: 0.2051\nModel 1 Validation Accuracy: 0.9082221984863281\n180/180 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9119 - loss: 0.2019\nModel 1 Training Accuracy: 0.9130870699882507\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.9734 - loss: 0.0907\nModel 2 Validation Accuracy: 0.9733333587646484\n180/180 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - accuracy: 0.9905 - loss: 0.0294\nModel 2 Training Accuracy: 0.9905287027359009\n45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - accuracy: 0.9724 - loss: 0.1055\nModel 3 Validation Accuracy: 0.968666672706604\n180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 9ms/step - accuracy: 0.9882 - loss: 0.0303\nModel 3 Training Accuracy: 0.9894701838493347\n\n\n\n\n\nModel\nTraining Accuracy\nValidation Accuracy\n\n\n\n\nModel 1\n0.9655\n0.9467\n\n\nModel 2\n0.9989\n0.9762\n\n\nModel 3\n0.9998\n0.9849\n\n\n\nOverall, we observe that model 3 demonstrates the best performance among the three models, with the highest training and validation accuracies. Model 2 also performs well but shows a slightly gap between training and validation accuracies compared to Model 3. Model 1, while still achieving good accuracies, has the lowest performance among the three models."
  },
  {
    "objectID": "posts/16BHW6/index.html#model-evaluation",
    "href": "posts/16BHW6/index.html#model-evaluation",
    "title": "PIC16B HW6",
    "section": "",
    "text": "Now, we will test our model 3 performance on unseen test data\nWe can download the test data here : “test_url =”https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true”“. Previously, in data preparation section (Part 2), we already convert this data using the make_dataset function we defined. Below is a recap:\n# Split the training and validation data sets using a function\ntrain_data, val_data = split_train_val_dataset(train_data, val_ratio=0.2)\ntrain = train_data\nval = val_data\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/fake_news_test.csv\"\ntest_dataset = acquire_training_data(test_url)\n\ntest_data = make_dataset(test_dataset)\nNow we evaluate model 3 on the data: we evaluated Model 3 using test data and prints the evaluation results (test loss and accuracy), then visualizes these results using a bar chart to compare the metrics.\n\n# Evaluate Model 3\nevaluation_result = model3.evaluate(test_data)\n\n# Print evaluation results\nprint(\"Test Loss:\", evaluation_result[0])\nprint(\"Test Accuracy:\", evaluation_result[1])\n\n# Print visualization\nplt.bar([\"Loss\", \"Accuracy\"], evaluation_result, color=['blue', 'green'])\nplt.xlabel('Metrics')\nplt.ylabel('Values')\nplt.title('Model3 Evaluation Results on Test Data')\nplt.show()\n\n225/225 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step - accuracy: 0.9709 - loss: 0.1103\nTest Loss: 0.10525856167078018\nTest Accuracy: 0.9708672761917114\n\n\n\n\n\n\n\n\n\nBased on the provided test results, if we used the model as a fake news detector, we would be correct approximately 98% of the time. A test accuracy of 98% suggests that the model has learned to distinguish between real and fake news with high accuracy based on the given dataset."
  },
  {
    "objectID": "posts/16BHW6/index.html#embedding-visualization",
    "href": "posts/16BHW6/index.html#embedding-visualization",
    "title": "PIC16B HW6",
    "section": "",
    "text": "Now it could be fun to look at the embedding learned by our model. We need to comment on at least 5 words whose location in the embedding you find interpretable.\n\n\nPCA is a dimensionality reduction technique that aims to transform high-dimensional data into a lower-dimensional space while preserving the most important information. It identifies the principal components, which are the directions of maximum variance in the data.\nBy applying PCA to the learned word embeddings, we can reduce their dimensionality and visualize them in a lower-dimensional space, such as 2D or 3D. This allows us to understand the structure and relationships between the word embeddings in a more interpretable way.\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\n\"\"\"\nWe performs Principal Component Analysis (PCA) on the embedding weights obtained from a trained model\nto reduce dimensionality and analyze the word embeddings. It identifies and prints the top words based on\nembedding magnitudes, then visualizes all embeddings in a 3D scatter plot using Plotly Express.\n\nWe assumes the availability of `model1` and `title_vectorize_layer` from which it extracts embedding\nweights and vocabulary, respectively. The embeddings are reduced to three dimensions using PCA, and the words\nare then ranked and displayed based on the norm of their embeddings. Finally, a 3D scatter plot is generated\nto visually explore the word embeddings space.\n\"\"\"\n\n# Assuming you have obtained the embedding weights and vocabulary\n# Replace 'weights' and 'vocab' with actual values\nweights = model1.get_layer('embedding_title').get_weights()[0]  # Example embedding weights\nvocab = title_vectorize_layer.get_vocabulary()  # Example vocabulary\n\n# Perform PCA for dimensionality reduction\npca = PCA(n_components=3)\nweights_pca = pca.fit_transform(weights)\n\n# Extract embeddings for each word\nembedding_dict = {word: embedding for word, embedding in zip(vocab, weights_pca)}\n\n# Sort words based on embedding values\nsorted_words = sorted(embedding_dict, key=lambda x: np.linalg.norm(embedding_dict[x]), reverse=True)\n\n# Print the top words with highest embeddings\nnum_top_words = 5\nprint(f\"Top {num_top_words} words with highest embeddings:\")\nfor word in sorted_words[:num_top_words]:\n    print(f\"Word: {word}, Embedding: {embedding_dict[word]}\")\n\n# Perform additional analysis and commentary on the embeddings\n\n# Create DataFrame for plotting\nembedding_df = pd.DataFrame({\n    'word': vocab,\n    'x0': weights_pca[:, 0],\n    'x1': weights_pca[:, 1],\n    'x2': weights_pca[:, 2]\n})\n\n\nTop 5 words with highest embeddings:\nWord: video, Embedding: [17.325254    0.7191003   0.11118298]\nWord: trump’s, Embedding: [11.223864    0.1662118   0.04897542]\nWord: watch, Embedding: [9.809493   0.2826847  0.06626459]\nWord: breaking, Embedding: [ 9.319804    0.02514263 -0.03231914]\nWord: gop, Embedding: [ 8.889053    0.01651091 -0.01013779]\n\n\n\n1st:video: With an embedding of [17.325254, 0.7191003, 0.11118298], “video” stands out with the highest vector magnitude. This prominent position implies a strong presence or frequent usage in the dataset, possibly indicating its significance or centrality in the content.\n2nd:trump’s: The embedding [11.223864, 0.1662118, 0.04897542] places “trump’s” as the second most significant term. Its vector shows it has a substantial, albeit lesser magnitude than “video,” suggesting its importance in the analyzed text, potentially related to political content.\n3rd:watch: “watch” has an embedding of [9.809493, 0.2826847, 0.06626459], ranking third. This suggests it is a key term, possibly associated with content that calls for attention or action, such as news or media.\n4th: breaking: With an embedding of [9.319804, 0.02514263, -0.03231914], “breaking” appears as the fourth word. Its presence might indicate frequent use in urgent or newsworthy contexts, highlighting its relevance in news-related discourse.\n5th:gop: The embedding [8.889053, 0.01651091, -0.01013779] for “gop” positions it fifth, suggesting its significant role in discussions, likely related to political topics, given its association with the Republican Party in the United States.\n\n\n\n\nT-SNE is a widely used technique for visualizing high-dimensional data in a lower-dimensional space, such as 2D or 3D. It aims to preserve the local structure of the data while revealing global patterns and clusters. By visualizing the word embeddings using t-SNE, we can gain insights into the semantic structure and relationships between words. Words that are semantically similar or related are expected to be clustered together in the t-SNE plot.\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\n\"\"\"\nNow we applies t-SNE (t-Distributed Stochastic Neighbor Embedding) to the embedding weights from a neural network model,\nreducing the dimensionality to three components for visualization and analysis of word embeddings.\n\nThe process involves extracting embedding weights and vocabulary from the specified model layer, then applying t-SNE to transform\nthese high-dimensional embeddings into a 3D space. The script identifies the top words with the highest embedding magnitudes,\nprints them, and then creates a 3D scatter plot using Plotly Express to visualize the distribution and relationships of word embeddings.\n\nKey steps include:\n- Obtaining embedding weights and vocabulary from the model.\n- Reducing dimensionality of embeddings with t-SNE.\n- Sorting and displaying words with the highest embeddings.\n- Visualizing the embeddings in a 3D scatter plot, with interactive features to explore word relationships.\n\"\"\"\n\n# Assuming you have obtained the embedding weights and vocabulary\n# Replace 'weights' and 'vocab' with actual values\nweights = model1.get_layer('embedding_title').get_weights()[0]  # Example embedding weights\nvocab = title_vectorize_layer.get_vocabulary()  # Example vocabulary\n\n# Perform t-SNE for dimensionality reduction\ntsne = TSNE(n_components=3)\nweights_tsne = tsne.fit_transform(weights)\n\n# Extract embeddings for each word\nembedding_dict = {word: embedding for word, embedding in zip(vocab, weights_tsne)}\n\n# Sort words based on embedding values\nsorted_words = sorted(embedding_dict, key=lambda x: np.linalg.norm(embedding_dict[x]), reverse=True)\n\n# Print the top words with highest embeddings\nnum_top_words = 5\nprint(f\"Top {num_top_words} words with highest embeddings:\")\nfor word in sorted_words[:num_top_words]:\n    print(f\"Word: {word}, Embedding: {embedding_dict[word]}\")\n\n# Create DataFrame for plotting\nembedding_df = pd.DataFrame({\n    'word': vocab,\n    'x0': weights_tsne[:, 0],\n    'x1': weights_tsne[:, 1],\n    'x2': weights_tsne[:, 2]\n})\n\n\nTop 5 words with highest embeddings:\nWord: talks, Embedding: [-24.842272   -9.705764    3.0962868]\nWord: south, Embedding: [-24.89313   -9.58717    3.052512]\nWord: urges, Embedding: [-24.94897   -9.438914   3.003081]\nWord: turkey, Embedding: [-24.980162   -9.349924    2.9750898]\nWord: says, Embedding: [-24.70634    -9.946184    3.2103448]\n\n\nt-SNE Embedding:\n\ntalks: This word has the highest embedding in the t-SNE plot, with coordinates [-24.842272, -9.705764, 3.0962868]. Its location suggests that it is relatively distinct from other words in the embedding space.\nsouth: The word “south” has the second-highest embedding, with coordinates [-24.89313, -9.58717, 3.052512]. Its proximity to “talks” indicates that these words may share some semantic similarities or appear in similar contexts.\nurges: The word “urges” has the third-highest embedding, with coordinates [-24.94897, -9.438914, 3.003081]. Its location near “talks” and “south” suggests that it is also semantically related to these words.\nturkey: The word “turkey” has the fourth-highest embedding, with coordinates [-24.980162, -9.349924, 2.9750898]. Its proximity to the previous words indicates that it may share some contextual similarities with them.\nsays: The word “says” has the fifth-highest embedding, with coordinates [-24.70634, -9.946184, 3.2103448]. Its location close to the other top words suggests that it is semantically related to them.\n\n\n\n\nNow it’s thrilled to showcase both PCA and t-SNE’s 3-dimensional embeddings. How exciting!\nTo begin, we configure Plotly to utilize an “iframe” renderer, ideal for displaying plots in various environments such as Jupyter notebooks or web interfaces. Next, we generate a 3D scatter plot representing word embeddings, where each point represents a word. This plot provides interactivity, allowing users to hover over a point to reveal the corresponding word. Furthermore, we save the plot as an HTML file for easy access and display it inline for immediate visualization.\n\n\n\n# Set the renderer to \"iframe\"\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\n# Create a scatter plot using Plotly Express\nfig = px.scatter_3d(embedding_df, x='x0', y='x1', z='x2', hover_name='word')\n# Each point represents a word, positioned based on its 'x0', 'x1', and 'x2' coordinates\n# Hovering over a point will show the corresponding word\n\n# Save the plot as an HTML file\noutput_path = \"scatter_plot.html\"\nfig.write_html(output_path)\n\n# Display the plot\nfig.show()\n\n\n\n\n\n\n\n\n\n# Set the renderer to \"iframe\"\nimport plotly.io as pio\npio.renderers.default = \"iframe\"\n\n# Create a scatter plot using Plotly Express\nfig = px.scatter_3d(embedding_df, x='x0', y='x1', z='x2', hover_name='word')\n# Each point represents a word, positioned based on its 'x0', 'x1', and 'x2' coordinates\n# Hovering over a point will show the corresponding word\n\n# Save the plot as an HTML file\noutput_path = \"tsne_scatter_plot.html\"\nfig.write_html(output_path)\n\n# Display the plot\nfig.show()\n\n\n\n\n\n\n\nNow we have successfully presented the learned word embeddings through visualizations using PCA and t-SNE. The analysis has provided insights into the positioning and interpretation of at least five words within the embedding space.\nThank you for dedicating your time to explore and understand this project."
  },
  {
    "objectID": "posts/16BHW1/index.html",
    "href": "posts/16BHW1/index.html",
    "title": "PIC 16B HW1",
    "section": "",
    "text": "import pandas as pd\n\n# advanced plotting tools for data frames\n# basically a bunch of matplotlib shortcuts\nimport seaborn as sns \n\nfrom matplotlib import pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-1-database-creation",
    "href": "posts/16BHW1/index.html#section-1-database-creation",
    "title": "PIC 16B HW1",
    "section": "Section 1: Database Creation",
    "text": "Section 1: Database Creation\nWe are required to create a database with three tables: temperatures, stations, and countries. We need to know how to access country names and relate them to temperature readings. We also need to keep these as three seperate tables in our database.\nLecture Notes: “Databases provide us with a structured way to move subsets of data from storage into memory. Python has a module called sqlite3 (already installed in PIC16B-24W environment) which we can use to create, manipulate, and query databases. There’s also a very handy pandas interface, enabling us to efficiently create pandas data frames containing exactly the data that we want.”\n\nimport sqlite3\nconn = sqlite3.connect(\"temps.db\")\n\n\ndf = pd.read_csv(\"temps.csv\")\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\ndf.head()\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\n\ndf.shape\n\n(1359937, 14)\n\n\n\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    return(df)\n\n\nData Cleaning\n\ndf = prepare_df(df)\ndf.head()\n\n\n\n\n\n\n\n\nID\nYear\nMonth\nTemp\n\n\n\n\n0\nACW00011604\n1961\n1\n-0.89\n\n\n1\nACW00011604\n1961\n2\n2.36\n\n\n2\nACW00011604\n1961\n3\n4.72\n\n\n3\nACW00011604\n1961\n4\n7.73\n\n\n4\nACW00011604\n1961\n5\n11.28\n\n\n\n\n\n\n\n\n\nAdding Temperatures to Our Database\n\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\nfor i, df in enumerate(df_iter):\n    df = prepare_df(df)\n    df.to_sql(\"temperatures\", conn, if_exists = \"replace\" if i == 0 else \"append\", index = False)\n\n\n\nAdding Stations to Our Database\n\nurl = \"station-metadata.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"stations\", conn, if_exists = \"replace\", index=False)\n\n27585\n\n\n\n\nAdding Countries to Our Database\n\nurl = \"country.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"countries\", conn, if_exists = \"replace\", index=False)\n\n279\n\n\n\ndf = pd.read_csv(\"country.csv\")\ndf = df.rename(columns={'Name': 'Country'})\ndf.to_csv(\"country_modified.csv\", index=False)\n\n\n\nLet’s check our Databse:\n\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\nprint(cursor.fetchall())\n\n[('temperatures',), ('stations',), ('countries',)]\n\n\n\ncursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n\nfor result in cursor.fetchall():\n    print(result[0])\n\nCREATE TABLE \"temperatures\" (\n\"ID\" TEXT,\n  \"Year\" INTEGER,\n  \"Month\" INTEGER,\n  \"Temp\" REAL\n)\nCREATE TABLE \"stations\" (\n\"ID\" TEXT,\n  \"LATITUDE\" REAL,\n  \"LONGITUDE\" REAL,\n  \"STNELEV\" REAL,\n  \"NAME\" TEXT\n)\nCREATE TABLE \"countries\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-2-write-a-query-function",
    "href": "posts/16BHW1/index.html#section-2-write-a-query-function",
    "title": "PIC 16B HW1",
    "section": "Section 2: Write a Query Function",
    "text": "Section 2: Write a Query Function\nIn this section, we need to first write a climate_database.py file with the function query_climate_database() which accepts five arguments: \n1) db_file: the file name for the database 2) country: a string giving the name of a country for which data should be returned 3) year_begin: integer giving the earliest years for which should be returne  4) year_end: integer giving the latest years for which should be returned 5) month: an integer giving the month of the year for which should be returned\nThe return value of query_climate_database() is a Pandas dataframe of temeperature readings for the specified country, in the specified date range,in the specified month of year. We are required to have these columns: NAME, LATITUDE, LONGITUDE, Country, Year, Month, Temp\n\nfrom climate_database import query_climate_database\nimport inspect\nprint(inspect.getsource(query_climate_database))\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    \n    query = '''\n    SELECT S.NAME, S.LATITUDE, S.LONGITUDE, C.Name AS COUNTRY, \n       T.Year AS Year, T.Month AS Month, T.Temp AS Temp\n    FROM temperatures T\n    JOIN stations S ON T.ID=S.ID\n    JOIN countries C ON S.ID=SUBSTR(C.ID, 1, LENGTH(S.ID)) -- Assuming ID matching logic\n    WHERE C.Name = ? AND T.Year BETWEEN ? AND ? AND T.Month = ?\n    ''',\n    (country, year_begin, year_end, month)\n\n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    return df\n\n\n\n\nquery_climate_database(db_file = \"temps.db\",\n                       country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020,\n                       month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nName\nYear\nMonth\nTemp\n\n\n\n\n0\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n4\n-41.08\n\n\n1\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n5\n-48.40\n\n\n2\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n6\n-50.70\n\n\n3\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n7\n-49.14\n\n\n4\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n10\n-43.66\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8468\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n8\n0.00\n\n\n8469\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n9\n-2.09\n\n\n8470\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n10\n-8.70\n\n\n8471\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n11\n-20.90\n\n\n8472\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n12\n-25.40\n\n\n\n\n8473 rows × 7 columns\n\n\n\n\nANOTHER APPROACH\n\nimport sqlite3\nimport pandas as pd\n\ndb_file = 'temps.db'\n\n\nconn = sqlite3.connect(db_file)\ncursor = conn.cursor()\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS countries (\n    country_id INTEGER PRIMARY KEY,\n    country_name TEXT NOT NULL\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS stations (\n    station_id INTEGER PRIMARY KEY,\n    station_name TEXT NOT NULL,\n    latitude REAL,\n    longitude REAL,\n    country_id INTEGER,\n    FOREIGN KEY (country_id) REFERENCES countries (country_id)\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS temperatures (\n    temperature_id INTEGER PRIMARY KEY,\n    station_id INTEGER,\n    country_id INTEGER,\n    year INTEGER,\n    month INTEGER,\n    temp REAL,\n    FOREIGN KEY (station_id) REFERENCES stations (station_id),\n    FOREIGN KEY (country_id) REFERENCES countries (country_id)\n)\n''')\n\n\nconn.commit()\n\n\ndef load_csv_to_table(csv_file, table_name, conn):\n    df = pd.read_csv(csv_file)\n    df.to_sql(table_name, conn, if_exists='replace', index=False)\n\n\nload_csv_to_table('country.csv', 'countries', conn)\nload_csv_to_table('station-metadata.csv', 'stations', conn)\nload_csv_to_table('temps.csv', 'temperatures', conn)\n\nconn.close()\n\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    \n    temp_column = f'VALUE{month}'\n    \n    query = f'''\n    SELECT st.NAME, st.LATITUDE, st.LONGITUDE, co.Name AS Country, \n           te.Year, {month} AS Month, te.{temp_column} AS Temp\n    FROM temperatures te\n    INNER JOIN stations st ON te.ID = st.ID\n    INNER JOIN countries co ON co.`FIPS 10-4` = SUBSTR(te.ID, 1, 2)\n    WHERE co.`FIPS 10-4` = (SELECT `FIPS 10-4` FROM countries WHERE Name = \"{country}\")\n    AND te.Year BETWEEN {year_begin} AND {year_end}\n    AND te.{temp_column} IS NOT NULL\n    '''\n    \n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    return df\n\n\nquery_climate_database(db_file =\"temps.db\", country =\"India\", year_begin = 1980, year_end = 2020,month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n2348.0\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n2457.0\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n2419.0\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n2351.0\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n2481.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n510.0\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n690.0\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n810.0\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n560.0\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n570.0\n\n\n\n\n3152 rows × 7 columns\n\n\n\nWhich works well."
  },
  {
    "objectID": "posts/16BHW1/index.html#section-3-write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "href": "posts/16BHW1/index.html#section-3-write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "title": "PIC 16B HW1",
    "section": "Section 3: Write A Geographic Scatter Function for Yearly Temperature Increases",
    "text": "Section 3: Write A Geographic Scatter Function for Yearly Temperature Increases\nConsider this question: How does the average yearly change in temperature vary within a given country?\nIn this section, we are going to write a function called temperature_coefficient_plot() to generate an interactive geographic scatterplot, constructing using Plotly Express with a point for each station.\n\nNote: Apply () method can be used\n\n\ndf_countries = pd.read_csv('country.csv')\nprint(df_countries.columns.tolist())\ndf_countries\n\n['FIPS 10-4', 'ISO 3166', 'Name']\n\n\n\n\n\n\n\n\n\nFIPS 10-4\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n...\n...\n...\n...\n\n\n274\n-\n-\nWorld\n\n\n275\nYM\nYE\nYemen\n\n\n276\n-\n-\nZaire\n\n\n277\nZA\nZM\nZambia\n\n\n278\nZI\nZW\nZimbabwe\n\n\n\n\n279 rows × 3 columns\n\n\n\n\ndf_temps = pd.read_csv('temps.csv')\nprint(df_temps.columns.tolist())\ndf_temps.head()\n\n['ID', 'Year', 'VALUE1', 'VALUE2', 'VALUE3', 'VALUE4', 'VALUE5', 'VALUE6', 'VALUE7', 'VALUE8', 'VALUE9', 'VALUE10', 'VALUE11', 'VALUE12']\n\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\n\ndf_stationmetadata = pd.read_csv('station-metadata.csv')\nprint(df_stationmetadata.columns.tolist())\ndf_stationmetadata\n\n['ID', 'LATITUDE', 'LONGITUDE', 'STNELEV', 'NAME']\n\n\n\n\n\n\n\n\n\nID\nLATITUDE\nLONGITUDE\nSTNELEV\nNAME\n\n\n\n\n0\nACW00011604\n57.7667\n11.8667\n18.0\nSAVE\n\n\n1\nAE000041196\n25.3330\n55.5170\n34.0\nSHARJAH_INTER_AIRP\n\n\n2\nAEM00041184\n25.6170\n55.9330\n31.0\nRAS_AL_KHAIMAH_INTE\n\n\n3\nAEM00041194\n25.2550\n55.3640\n10.4\nDUBAI_INTL\n\n\n4\nAEM00041216\n24.4300\n54.4700\n3.0\nABU_DHABI_BATEEN_AIR\n\n\n...\n...\n...\n...\n...\n...\n\n\n27580\nZI000067983\n-20.2000\n32.6160\n1132.0\nCHIPINGE\n\n\n27581\nZI000067991\n-22.2170\n30.0000\n457.0\nBEITBRIDGE\n\n\n27582\nZIXLT371333\n-17.8300\n31.0200\n1471.0\nHARARE_BELVEDERE\n\n\n27583\nZIXLT443557\n-18.9800\n32.4500\n1018.0\nGRAND_REEF\n\n\n27584\nZIXLT622116\n-19.4300\n29.7500\n1411.0\nGWELO\n\n\n\n\n27585 rows × 5 columns\n\n\n\n\nimport pandas as pd\nimport sqlite3\nimport plotly.express as px\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    conn = sqlite3.connect(db_file)\n    \n    country_code_query = f\"SELECT `FIPS 10-4` FROM countries WHERE Name = '{country}'\"\n    country_code = pd.read_sql_query(country_code_query, conn).iloc[0, 0]\n    \n\n    temp_column = f'VALUE{month}'\n    \n\n    query = f'''\n    SELECT st.NAME, st.LATITUDE, st.LONGITUDE, '{country}' AS Country, \n           te.Year, {month} AS Month, te.{temp_column} AS Temp\n    FROM temperatures te\n    INNER JOIN stations st ON te.ID = st.ID\n    WHERE SUBSTR(te.ID, 1, 2) = '{country_code}'\n    AND te.Year BETWEEN {year_begin} AND {year_end}\n    AND te.{temp_column} IS NOT NULL\n    '''\n\n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    df = df.groupby('NAME').filter(lambda x: len(x) &gt;= min_obs)\n    \n\n    def calculate_slope(df):\n        if len(df) &lt; min_obs:\n            return np.nan  \n        X = df['Year'].values.reshape(-1, 1)\n        y = df['Temp'].values\n        reg = LinearRegression().fit(X, y)\n        return reg.coef_[0]\n    \n    df['Slope'] = df.groupby('NAME').apply(calculate_slope)\n    \n    df = df.dropna(subset=['Slope'])\n    \n\n    df = df.drop_duplicates(subset=['NAME'])\n    \n\n    fig = px.scatter_mapbox(df, lat=\"LATITUDE\", lon=\"LONGITUDE\", \n                            color=\"Slope\",\n                            size=np.abs(df['Slope']), \n                            **kwargs)\n    \n\n    if 'color_continuous_scale' not in kwargs:\n        fig.update_traces(marker=dict(colorscale='RdYlGn'))\n    \n    fig.update_layout(mapbox_style=\"carto-positron\", mapbox_zoom=2)\n    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n    \n    return fig\n\ncolor_map = px.colors.diverging.RdGy_r\n\n\nfig = temperature_coefficient_plot(\n    db_file=\"climate_data.db\", \n    country=\"India\", \n    year_begin=1980, \n    year_end=2020, \n    month=1, \n    min_obs=10,\n    zoom=3,\n    mapbox_style=\"carto-positron\",\n    color_continuous_scale=color_map)\n\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-4-create-two-more-interesting-figures",
    "href": "posts/16BHW1/index.html#section-4-create-two-more-interesting-figures",
    "title": "PIC 16B HW1",
    "section": "Section 4: Create Two More Interesting Figures",
    "text": "Section 4: Create Two More Interesting Figures\n\nimport plotly\nplotly.__version__\n\n'5.18.0'\n\n\n\nFigure 1\nQuestion Address: How does the elevation above sea level vary with latitude across different geographical locations?\n\nimport pandas as pd\nfilename = \"station-metadata.csv\"\nstations = pd.read_csv(filename)\nstations= stations.dropna(subset = [\"LATITUDE\", \"STNELEV\"])\n\n\nfrom plotly import express as px\n\nfig = px.scatter(data_frame = stations,\n                 x = \"LATITUDE\",\n                 y = \"STNELEV\",\n                 width = 500,\n                 height = 300,\n                )\n\n#reduce whitespace\nfig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n# show the plot\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\npic1.jpg\n\n\nBy plotting latitude against station elevation, researchers can analyze patterns such as:\nAre higher elevations found at specific latitudes? Is there a correlation between latitude and elevation, and is it positive or negative? How does the distribution of elevations vary across different latitudes? Are there any outliers that suggest unique geographical features?\n\n\nFigure 2\nQuestion Address: How do temperature values for January 1961 vary across different IDs (which could represent different locations or stations) in the dataset provided?\n\nimport pandas as pd\nimport plotly.express as px\n\ndef plot_temperature_boxplot_january_1961(csv_filename):\n    df = pd.read_csv(csv_filename)\n    \n    df_january_1961 = df[df['Year'] == 1961][['ID', 'VALUE1']]\n    \n    # Rename 'VALUE1' to 'Temperature' for clarity\n    df_january_1961.rename(columns={'VALUE1': 'Temperature'}, inplace=True)\n    \n    # Create the boxplot\n    fig = px.box(data_frame=df_january_1961,\n                 x=\"ID\",\n                 y=\"Temperature\",\n                 width=500,\n                 height=300)\n\n    # Reduce whitespace\n    fig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n    \n    # Show the plot\n    fig.show()\nplot_temperature_boxplot_january_1961('temps.csv')\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\npic2.jpg\n\n\nBy constructing a boxplot of January temperatures across different locations, researchers can investigate patterns such as:\nWhat is the typical range of temperatures experienced in various locations during January? Are there any locations with particularly high or low median temperatures compared to others? How does the interquartile range (IQR) of temperatures compare among different locations? Are there any anomalies indicating extreme weather events or microclimates in specific locations?"
  },
  {
    "objectID": "posts/FlaskBlogPost/index.html",
    "href": "posts/FlaskBlogPost/index.html",
    "title": "Part 3: Flask Web App Development for Option Intrinsic Value Prediction",
    "section": "",
    "text": "After completing data preprocessing and constructing a one-dimensional Convolutional Neural Network (CNN), we have successfully enabled the prediction of call and put options’ intrinsic values. The subsequent step involves operationalizing this model: we will explore how to integrate it into a web application, thus allowing users to make predictions and view results. This transition marks our shift from theoretical analysis to practical application, demonstrating the real-world utility of our intellectual efforts.\n\n\nThe implementation strategy for our Flask web application development can be encapsulated as follows:\n\nWeb Application Framework Construction: Utilize the Flask framework to build a web application that processes user-uploaded financial data and displays prediction outcomes.\nModel Preparation: Define a Convolutional Neural Network (CNN) specifically designed for financial data prediction. This model includes multiple convolutional layers, batch normalization layers, and residual connections to boost performance and training efficiency—a milestone already achieved by our team.\nModel Loading and Data Preprocessing: Load the pre-trained model (best_model_ultimatel.pth) and perform data preprocessing. This step involves reading data from an uploaded CSV file and applying the preprocess_data function to execute feature scaling, data splitting, and other preparatory operations, mirroring the CNN model setup.\nModel Training and Prediction: Employ the PyTorch library to load the pre-trained model and input the preprocessed data for prediction.\nResults Presentation: Exhibit the model’s performance metrics on the test dataset, such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared score, along with the prediction outcomes. These are visualized using Plotly charts, providing a comprehensive view to the users.\n\n\n\n\nflask1.png\n\n\n\napp.py: Central to the application, this file contains key functions like Convolution1D, preprocess_data, Index, show_prediction, get_table_info, view_uploaded_database, and view_database, which are integral to the app’s operation.\nTemplates folder: This directory holds all the HTML files needed for the app’s user interface, enabling interactions and data display. It includes index.html, plot.html, view_uploaded_data.html, show_prediction.html, Test_Set_Predictions.html, and view_data.html.\nData folder: Contains sample CSV files, df_2023_h1_feature.csv and df_2023_h1_target.csv, used for data upload and result demonstration in the app.\nModel folder: Houses the pre-trained model file essential for making data predictions.\n__pycache__ folder: A system-generated directory that caches bytecode, enhancing the program’s execution speed.\nStatic folder: Stores static files, crucial for the app’s styling and interactive features.\n\nThis organizational structure ensures that each aspect of our Flask web application is well-arranged and easily accessible, supporting efficient development and maintenance.\n\n\n\nIn the app.py file, several key functionalities are pivotal to the web application’s operation, specifically tailored for financial data analysis and option pricing evaluation. These include:\n\nUpload and Preprocess Financial Data: This functionality allows users to upload their financial datasets and applies preprocessing techniques to prepare the data for analysis.\nView Uploaded CSV Files: Users can view the list of uploaded CSV files, providing an overview of the data available for processing.\nView Details of the Uploaded CSV Files: This feature enables users to delve into the specifics of each uploaded CSV file, examining the data more closely.\nEvaluate Option Pricing and Display Evaluation Results: The application assesses the pricing of options based on the uploaded data and displays the results, offering valuable insights into option valuation.\n\nThe app.py file incorporates essential libraries and modules to facilitate web development, data processing, machine learning, and visualization:\nfrom flask import Flask, render_template, url_for, request, flash, redirect\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom werkzeug.utils import secure_filename\nfrom torch import nn\nimport torch.nn.functional as F\nfrom flask import jsonify\nimport sqlite3\nimport math\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.graph_objects as go\nimport os\n\n\nThe Convolution1D class within our application is a custom neural network module extending nn.Module from PyTorch, designed for one-dimensional convolutional operations. This class embodies a series of convolutional, batch normalization, and fully connected layers, structured to facilitate complex pattern recognition in financial data. Notably, this implementation includes residual connections and dropout for robustness and generalization.\nNote: Building on the foundational work previously established by our team members, this segment is presented without extensive analysis to minimize redundancy.\n\n\n\nIn this section of the code, we address the computational efficiency and resource optimization for running our neural network model. The code snippet demonstrates the dynamic allocation of processing units, preferring GPU over CPU for faster computation, which is crucial for handling complex models like Convolution1D. We then load the model’s state dictionary from the file ‘best_model_ultimate.pt’. The map_location argument ensures that the loaded state dict is moved to the appropriate device. This step initializes the model with previously trained parameters, allowing for further training,evaluation, or inference without retraining from scratch. Here’s a detailed look at the operations:\n# Check for available GPU, otherwise use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# Initialize the Convolution1D model and transfer it to the chosen device\nmodel_loaded = Convolution1D().to(device)\n# Load the previously trained model state\nmodel_loaded.load_state_dict(torch.load('model/best_model_new.pt', map_location=device))\n# Set the model to evaluation mode\nmodel_loaded.eval()\n\n\n\nThe preprocess_data function tasked with preparing the financial data for subsequent analysis. It performs several key steps:\n\nData Loading: Reads the financial datasets from the specified CSV files.\nNormalization: Applies StandardScaler to normalize specific columns, ensuring uniform data scaling.\nData Merging: Combines the feature and target data into a single DataFrame for comprehensive analysis.\nData Splitting: Segregates the dataset into training, validation, and test sets, facilitating a structured approach to model training and evaluation.\n\nGiven that these processes align with our prior data handling endeavors, we will highlight only the main actions and points, avoiding detailed analysis to prevent redundancy.\n\n\n\nThe index function in app.py serves as the main entry point for our Flask web application. It handles both GET and POST requests, managing file uploads, data preprocessing, model evaluation, and rendering the results. This function aligns with our previous work, emphasizing efficient data processing and model integration. Key points include handling file uploads, data preprocessing, model prediction, error calculation, and result visualization. Below is the detailed code:\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    \"\"\"\n    This function serves as the endpoint for the root URL ('/'). It handles both GET and POST requests,\n    rendering the index page of the web application. During a POST request, it processes uploaded files\n    for option pricing evaluation, performs predictions, and returns the results along with rendering\n    the HTML template.\n\n    Returns:\n        render_template: Renders the HTML template based on the request method and the operations performed.\n    \"\"\"\n    # Check if the request method is POST, which indicates that data has been submitted to the server\n    if request.method == 'POST':\n        # Check if both files are present in the request\n        if 'file1' not in request.files or 'file2' not in request.files:\n            # If either file is missing, flash a message to the user and reload the page\n            flash('No file part')\n            return redirect(request.url)\n        file1 = request.files['file1']\n        file2 = request.files['file2']\n        \n        # Check if file names are not empty, meaning that the user has selected files\n        if file1.filename == '' or file2.filename == '':\n            # If no file is selected, flash a message and reload the page\n            flash('No selected file')\n            return redirect(request.url)\n        \n        # Check if both files exist and proceed with processing\n        if file1 and file2:\n            # Secure the file names and prepare the file paths\n            filename1 = secure_filename(file1.filename)\n            filename2 = secure_filename(file2.filename)\n            file1_path = os.path.join(app.config['UPLOAD_FOLDER'], filename1)\n            file2_path = os.path.join(app.config['UPLOAD_FOLDER'], filename2)\n            # Save the files to the server\n            file1.save(file1_path)\n            file2.save(file2_path)\n            # Notify the user that files have been uploaded successfully\n            flash('Files successfully uploaded')\n\n            # Preprocess the data from the uploaded files\n            X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(file1_path, file2_path)\n\n            # Evaluate the model on the uploaded data\n            criterion = nn.MSELoss()  # Mean Squared Error Loss function\n            with torch.no_grad():  # No gradient computation for evaluation to save memory and computations\n                output = model_loaded(X_test.to(device)).squeeze(-1)  # Model prediction\n                predictions = output\n                test_loss = criterion(predictions, y_test.to(device))  # Calculate the test loss\n\n            # Compute the Root Mean Square Error (RMSE) for the test data\n            mse_loss = criterion(predictions, y_test)\n            rmse_loss = mse_loss.item() ** (0.5)\n            \n            # Compute the R-squared (R2) score to measure the goodness of fit\n            from sklearn.metrics import r2_score\n            r2 = r2_score(y_test, predictions)\n            \n            # Create a plot of the predictions against the true values\n            fig = go.Figure()\n            fig.add_trace(go.Scatter(x=np.arange(len(output)), y=output.squeeze().numpy(), mode='lines', name='Predicted', line=dict(color='red')))\n            fig.add_trace(go.Scatter(x=np.arange(len(y_test)), y=y_test.numpy(), mode='lines', name='True', line=dict(color='blue')))\n            fig.update_layout(title='Test Set Predictions', xaxis_title='Index', yaxis_title='Value')\n            \n            # Save the plot output to a file\n            plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n            fig.write_html(plot_output_path)\n            \n            # Render the index HTML template with the results and plot path\n            return render_template('index.html', test_loss=test_loss.item(), mse_loss=mse_loss.item(),\n                                   rmse_loss=rmse_loss, r2_score=r2, plot=plot_output_path)\n\n    # If the request method is GET, render the index HTML template without any prediction or plot\n    return render_template('index.html', prediction=None, plot=None)\n\nIn summary, the index function is integral to the Flask application. It is pivotal for deploying predictive models effectively, ensuring that the application not only performs its intended analytical tasks but also provides a user-friendly interface for interaction and result interpretation. \n\n### show_prediction\n\nThe `show_prediction` function in `app.py` is designed to handle GET requests specifically for displaying the prediction results on a separate page. This functionality is crucial for providing users with access to the outcome of their data analysis, ensuring a clear and dedicated view of the predictive results.\n\nHere's a detailed analysis of the function:\n\n- **Path Definition**: Initially, the function defines the path to the prediction results file, typically stored in the `static` directory. This standardization of file location facilitates consistent access and retrieval of the results.\n\n- **Existence Check**: The function then checks if the prediction results file exists at the specified path. This check is essential to prevent errors that would occur if the application attempted to display a non-existent file.\n\n- **Conditional Rendering**: If the file exists, the function proceeds to render an HTML template (`Test_Set_Predictions.html`) specifically designed to display the prediction results. This template is passed the path of the prediction plot file, ensuring that the correct data is displayed.\n\n- **Redirection**: In cases where the prediction results file does not exist, the function redirects the user to the index page. This redirection mechanism prevents user confusion and ensures a smooth user experience by guiding them back to the starting point of the application.\n\nHere is the complete code snippet:\n\n```python\n@app.route('/show_prediction', methods=['GET'])\ndef show_prediction():\n    \n    # Define the path to the prediction results file, assumed to be in the 'static' directory\n    plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n    \n    # Check if the prediction results file exists\n    if not os.path.exists(plot_output_path):\n        # If the file does not exist, redirect the user to the index page\n        return redirect(url_for('index'))\n\n    # If the file exists, render the template to display the prediction results,\n    # passing the path of the prediction plot file to the template\n    return render_template('Test_Set_Predictions.html', plot_output_path=plot_output_path)\n\n### get_table_info\n\nThe `get_table_info` function is designed to streamline the process of extracting filenames from full file paths, which is a common requirement in web applications handling file uploads. By utilizing `os.path.basename`, it efficiently strips the directory path, leaving only the file name. This functionality is particularly useful in scenarios where the display or processing of filenames, independent of their storage paths, is required. Here's how the function operates:\n\n```python\ndef get_table_info(file1_path, file2_path):\n    return [os.path.basename(file1_path), os.path.basename(file2_path)]\n\n### view_uploaded_data\n\nThe `view_uploaded_data` function in the Flask web application serves to showcase the files that have been uploaded by users. This endpoint, accessible via a GET request, retrieves and displays the contents of the upload directory in the application's user interface. Here's an in-depth look at the function and its code:\n\n```python\n@app.route('/view_uploaded_data', methods=['GET'])\ndef view_uploaded_data():\n    \"\"\"\n    Handles the GET request to display the uploaded database files.\n\n    This endpoint fetches the list of files present in the upload directory and displays them\n    on the 'view_uploaded_data.html' page. This allows users to see which files have been\n    uploaded to the application.\n\n    The function retrieves the filenames from the specified upload folder set in the app's configuration\n    and passes these filenames to the rendering template.\n    \n    \"\"\"\n    \n    # Retrieve the list of files in the upload directory\n    files = os.listdir(app.config['UPLOAD_FOLDER'])\n    \n    # Render the HTML template, passing the list of files for display on the webpage\n    return render_template('view_uploaded_data.html', files=files)\n\n### view_data\n\nThe `view_data` endpoint in the Flask application is designed to showcase the details of the uploaded CSV files through a GET request. It facilitates the inspection of the contents of these files, enhancing the user's ability to interact with and analyze the uploaded data. The function operates by expecting `filename1` and `filename2` as query parameters, utilizing these to locate and display the respective files' contents. Here's a closer look at the function and its operations:\n\n```python\n@app.route('/view_data', methods=['GET'])\ndef view_data():\n    \"\"\"\n    The function checks for the existence of the specified files in the upload directory.\n    If both files exist, it reads them as CSVs and prepares the data for viewing. If either\n    file is missing or an error occurs during file reading, the user is redirected to the\n    file upload view with an appropriate error message.\n    \"\"\"\n    # Retrieve filenames from the request's query parameters\n    filename1 = request.args.get('filename1')\n    filename2 = request.args.get('filename2')\n    \n    # Validate that both filenames are provided\n    if not filename1 or not filename2:\n        flash('No data file selected.')\n        return redirect(url_for('view_uploaded_data'))\n    \n    # Construct full file paths\n    file1_path = os.path.join(app.config['UPLOAD_FOLDER'], filename1)\n    file2_path = os.path.join(app.config['UPLOAD_FOLDER'], filename2)\n\n    # Check if both files exist in the specified upload folder\n    if not os.path.exists(file1_path) or not os.path.exists(file2_path):\n        flash('Data file not found.')\n        return redirect(url_for('view_uploaded_data'))\n\n    try:\n        # Attempt to read the files as CSVs and store their contents\n        ds = pd.read_csv(file1_path)\n        target = pd.read_csv(file2_path)\n        table_data = {'Dataset 1': ds, 'Dataset 2': target}\n    except Exception as e:\n        # Handle any error that occurs during file reading and flash an error message\n        flash(f'Error accessing CSV files: {e}')\n        return redirect(url_for('view_uploaded_data'))\n    # Render the view template with the loaded table data and filenames\n    return render_template('view_data.html', tables=table_data, filename1=filename1, filename2=filename2)\n\nThe concluding part of our Flask application's code features the standard Python idiom to check if the script is executed as the main program and not imported as a module. This check is crucial for initiating the Flask server only when the script is run directly, ensuring that the application's startup process is controlled and deliberate. The `app.run(debug=True)` line activates the Flask application server with debug mode enabled, which is beneficial during development for its detailed error feedback and live reloading capabilities. Here's the segment:\n\n```python\n# This conditional statement checks if the script is run as the main program.\n# Ensure that code is only executed when the script is run directly, and not when imported as a module.\nif __name__ == '__main__':\n    # The app.run(debug=True) command starts the Flask application server.\n    # The debug=True argument enables debug mode, which provides useful feedback in the browser for development,\n    # including detailed tracebacks and live reloading on code changes.\n    app.run(debug=True)\n\n## 3.2 Evaluative Overview of HTML Templates: Implications for User Interface and Experience\n\n![flask2.png](index_files/figure-html/cell-26-1-flask2.png)\n\nOur web application uses a set of HTML templates, each carefully crafted to improve how users interact with and see data. These templates are essential to the app's design, blending good looks with practical use. They guide users from the start of entering data to the end of seeing the results. \n- `index.html`: Serves as the primary gateway to the web application, designed for predicting call option values. It incorporates Bootstrap for styling, providing a responsive layout with file upload forms, navigation buttons, and result display sections, thus ensuring a user-friendly experience.\n\n- `plot.html`: Utilizes Plotly for dynamic data visualization, offering interactive charts that render complex datasets in an easily digestible format, enhancing the analytical capabilities of the application.\n\n- `view_uploaded_data.html`: Lists the uploaded database files, enabling users to access and review the data they have provided, fostering transparency and control over the processed information.\n\n- `view_data.html`: Exhibits the content from two distinct datasets, providing a comprehensive view of the data under analysis and facilitating a deeper understanding of the predictive context.\n\n- `show_prediction.html`: Displays the outcome of predictive analyses, guiding users to detailed visual representations and insights derived from their data.\n\n- `Test_Set_Predictions.html`: Incorporates Plotly JavaScript to generate interactive data visualizations, allowing for an engaging and informative exploration of predictive results within the web environment.\n\nNext, we will conduct a comprehensive analysis of each template's functionalities and contributions, examining the web pages in our prototype to assess their quality and effectiveness.\n\n### 3.2.1 Welcome Page\n\nOur welcome page design seamlessly integrates various elements to optimize `user experience` and `functionality`. Users are provided with intuitive `\"Browse\" buttons` to swiftly upload local CSV files. Upon clicking the `\"Upload & Save\" button`, evaluation results are promptly generated within a few-second timeframe, ensuring `efficiency` in data processing. Additionally, users can easily access and review their uploaded dataset (csv files) online by selecting the `\"View Data\"`. For a comprehensive analysis, users can explore `interactive prediction graphs` through the `\"View Prediction\" feature`, enhancing their ability to interpret and analyze data trends effectively.\n\n![flask3.png](index_files/figure-html/cell-31-1-flask3.png)\n\n#### Color Scheme and Aesthetics `index.html`\n\n- **Color Choice:** In `index.html`, we deliberately choose a light blue background color (#ADD8E6) to promote a serene ambiance conducive to focused reading and analysis. The semi-transparent white background (rgba(255, 255, 255, 0.8)) within container elements aims to highlight content while maintaining visual harmony.\n```html\n&lt;style&gt;\n    body {\n        background-color: #ADD8E6;\n        padding-top: 20px;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        height: 100vh;\n    }\n    .container {\n        max-width: 800px;\n        text-align: center;\n        background-color: rgba(255, 255, 255, 0.8);\n        padding: 40px;\n        border-radius: 20px;\n    }\n    /* Additional CSS styles for buttons, labels, and text sizes are also defined in this section */\n&lt;/style&gt;\n\n#### Modular Design with Bootstrap in `index.html`\n\n- **Grid System Utilization:** We utilize Bootstrap's grid system to create a responsive layout, dividing content into grid columns with classes like `container`, `row`, and `col-*`, ensuring seamless alignment across devices. This fosters a visually appealing and user-friendly design. Here's how it's integrated:\n\n```html\n&lt;div class=\"container\"&gt;\n    &lt;!-- Content structured using Bootstrap's grid system --&gt;\n&lt;/div&gt;\n\n- **Custom CSS Classes Integration:** Custom CSS classes are integrated to style elements such as buttons, forms, and text, maintaining a cohesive design language and enhancing visual appeal.\n\n```css\n.btn-group .btn {\n    margin: 0 10px;\n    font-size: 36px;\n}\n\n- **Responsive Design Features:** Leveraging Bootstrap's responsive utilities like breakpoints and flexbox classes (`d-flex`, `justify-content-center`, `align-items-center`), we ensure our webpage adapts smoothly to various screen sizes and orientations for optimal user experience.\n\n```html\n&lt;div class=\"container\"&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n&lt;/div&gt;\n\n- **Component Reusability:** By using Bootstrap's built-in components such as navigation bars, buttons, and forms, we enhance code modularity and maintain a consistent design language throughout the project, saving time and effort in UI development.\n\n```html\n&lt;div class=\"btn-group\" role=\"group\" aria-label=\"Actions\"&gt;\n    &lt;a href=\"{{ url_for('view_data') }}\" class=\"btn btn-info\"&gt;View Data&lt;/a&gt;\n    &lt;a href=\"{{ url_for('show_prediction') }}\" class=\"btn btn-info\"&gt;View Prediction&lt;/a&gt;\n&lt;/div&gt;\n\n### 3.2.2 Evaluation & Results Page\n\nAfter clicking the `\"Upload & Save\"` button, the client is directed to our **Evaluation & Results** page, where they can view both numerical results and an interactive graph which provides visual insights, allowing users to explore and analyze the data trends effectively.\n\n![flask4.png](index_files/figure-html/cell-39-1-flask4.png)\n\n\n**Numerical Results Display in `evaluate_and_visualize.html`**\n\n```html\n{% if test_loss is defined %}\n    &lt;h2&gt;Evaluation Results:&lt;/h2&gt;\n    &lt;p&gt;Test Loss: {{ test_loss }}&lt;/p&gt;\n    &lt;p&gt;MSE Loss: {{ mse_loss }}&lt;/p&gt;\n    &lt;p&gt;RMSE Loss: {{ rmse_loss }}&lt;/p&gt;\n    &lt;p&gt;R2 Score: {{ r2_score }}&lt;/p&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n{% endif %}\n\nClarity: The page presents evaluation metrics such as Test Loss, Mean Squared Error (MSE) Loss, Root Mean Squared Error (RMSE) Loss, and R-squared (R2) Score in a clear and structured manner using HTML &lt;p&gt; tags. This clarity enhances the understanding of model performance.\nPrecision: The page ensures the precision and accuracy of displayed numerical values, crucial for data analysis. It typically maintains a precision of at least ten decimal places, ensuring data accuracy for in-depth analysis and comparison.\nContextual Rendering: The use of conditional blocks ensures that numerical results are displayed only when relevant data is available, preventing confusion and presenting information contextually.\n\nEmbedding Plotly Graph in evaluate_and_visualize.html\n&lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n\nVisual Analysis: The page enhances data analysis by embedding a Plotly graph within an &lt;iframe&gt;. This interactive graph provides visual insights into trends and patterns, complementing the numerical results.\nInteractivity: Users can interact with the embedded Plotly graph, such as zooming, panning, and hovering over data points to view detailed information. This interactivity fosters a deeper understanding of data trends and anomalies.\nIntegration: The seamless integration of the Plotly graph within the HTML page enhances user experience, allowing for a comprehensive analysis of model performance with both numerical and visual data representations.\n\n\n\n\nBy clicking the “View Data” button, users are directed to the data page, where all previously uploaded data files are displayed. Each file is accompanied by a “View” button on the right-hand side, allowing users to view the uploaded data online with a single click.\n\n\n\nflask5.png\n\n\nFile Listing in view_data.html\n&lt;!-- Table body section to display the content. --&gt;\n&lt;tbody&gt;\n    &lt;!-- Loop through each file in the 'files' list passed from the Flask backend. --&gt;\n    {% for file in files %}\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename1=file, filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt; &lt;!-- Link to view data. --&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\nThe “File Name” column displays each uploaded file’s name, fetched from the files list passed from the backend. Within each table row (\n\n), the file name is displayed in the “File Name” column (\n\n{{ file }}\n\n). This ensures that users can easily identify and select the files they want to view.\n\nActionable Links in view_data.html\n&lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n\nThe “Actions” column provides a convenient “View” link for each file, allowing users to seamlessly navigate to detailed data views with a single click. This intuitive design enhances the overall user experience and promotes efficient data exploration.\nThe “View” links are dynamically generated using Flask’s powerful url_for function, ensuring accurate and reliable navigation to the corresponding data views.\n\n\n\n\nWhen users click the “View” button on the View Data Page, they are seamlessly navigated to a dynamically generated web page that displays the data they have previously uploaded. This feature provides users with a convenient and intuitive way to access and examine their uploaded datasets within the application, enhancing the overall user experience and facilitating efficient data analysis.\n\n\n\nflask6.png\n\n\nDynamic Content Rendering in view_uploaded_data.html\nThe &lt;tbody&gt; section of the table dynamically displays uploaded files. This functionality is achieved through the use of server-side templating, specifically with Jinja2 in Flask, allowing for iteration over a list of files and rendering each as a row in the table.\n\nFunctionality: Iteration over the files array to create a table row for each file.\nData Binding: Server-side rendering with { file } to bind file names directly into the table.\nDynamic URL Generation: The url_for function generates actionable links for each file, enabling user interaction.\n\nHere is the code snippet in view_uploaded_data.html illustrating this functionality:\n&lt;tbody&gt;\n    &lt;!-- Table body section to display the content. --&gt;\n    {% for file in files %}\n    &lt;!-- Loop through each file in the 'files' list passed from the Flask backend. --&gt;\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename1=file, filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\n### 3.2.5 View Prediction Page\n\nUpon selecting the \"View Prediction\" button on the initial interface, users are directed to a page displaying test set predictions, featuring an interactive graph created with Plotly. This visualization fosters an engaging user experience, permitting detailed examination of the predictions. The graph's interactive features—zoom, pan, and data point hover—provide enriched informational access, allowing tailored analytical perspectives.\n\n![flask7.png](index_files/figure-html/cell-53-1-flask7.png)\n\nThe graph offers intuitive controls for a seamless user experience. Users can double-click to revert to the original zoom level after examining specific intervals. The operation bar in the upper right corner allows users to download the plot as a PNG, autoscale the axes, and reset the axes effortlessly.\n\n![flask8.png](index_files/figure-html/cell-55-1-flask8.png)\n\n![flask9.png](index_files/figure-html/cell-56-1-flask9.png)\n\n**Dynamic Plot Rendering with Plotly in `plot.html`**\n```html\n&lt;script src=\"https://cdn.plot.ly/plotly-latest.min.js\"&gt;&lt;/script&gt;\n&lt;div id=\"plot\"&gt;&lt;/div&gt;\n&lt;script&gt;\n    var plot_path = \"{{ plot_path }}\";\n    Plotly.d3.html(plot_path, function(error, data) {\n        if (error) {\n            return console.warn(error);\n        }\n        document.getElementById('plot').innerHTML = data;\n    });\n&lt;/script&gt;\n\nIntegration with Plotly: The inclusion of the Plotly library through the &lt;script&gt; tag is a significant aspect of this template.\nAsynchronous Data Fetching: The JavaScript block fetches the plot data asynchronously using Plotly’s d3.html function. This method loads the plot data from a specified path (plot_path), which is dynamically provided by the server-side application. This approach ensures that the webpage remains responsive and that the plot is updated seamlessly without the need for a full page reload.\nDynamic Content Loading: The template utilizes an empty\n\nelement with the id plot, which serves as a placeholder for the graph. The actual content of the graph is loaded dynamically through JavaScript, enabling the webpage to render data-driven plots efficiently.\n\nConditional Rendering and Link Generation in show_prediction.html\n{% if prediction %}\n    &lt;h3&gt;Predicted Mean: {{ prediction }}&lt;/h3&gt;\n    &lt;p&gt;&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;View Test Set Predictions Plot&lt;/a&gt;&lt;/p&gt;\n{% else %}\n    &lt;p&gt;No prediction available&lt;/p&gt;\n{% endif %}\n&lt;a href=\"{{ url_for('index') }}\" class=\"btn btn-primary\"&gt;Go Back&lt;/a&gt;\n\nConditional Content Display: The template employs Jinja2’s conditional syntax {% if prediction %} to check the presence of a prediction variable. This approach ensures that the user interface adapts to the data context, displaying the prediction results when available. If the prediction variable contains a value, the template renders an &lt;h3&gt; tag showing the predicted mean, enhancing the user’s understanding of the model output.\nDynamic Link Creation: The template dynamically generates a link to a plot (&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;) when prediction data is available. This link, opened in a new tab (target=“_blank”), leads to a detailed visualization of the test set predictions.\n\n\n\n\n\nOur web application, through its meticulously designed templates and key features, offers a streamlined and enriched user experience. We are committed to enabling users to efficiently manage, analyze, and interpret their data within a cohesive and intuitive environment. By providing a user-friendly interface and powerful functionality, we sincerely aim to empower users to harness the full potential of their data. Our goal is to support users in making informed decisions and fostering a deeper understanding of their analytical contexts."
  },
  {
    "objectID": "posts/FlaskBlogPost/index.html#web-app-implementation-outline",
    "href": "posts/FlaskBlogPost/index.html#web-app-implementation-outline",
    "title": "Part 3: Flask Web App Development for Option Intrinsic Value Prediction",
    "section": "",
    "text": "The implementation strategy for our Flask web application development can be encapsulated as follows:\n\nWeb Application Framework Construction: Utilize the Flask framework to build a web application that processes user-uploaded financial data and displays prediction outcomes.\nModel Preparation: Define a Convolutional Neural Network (CNN) specifically designed for financial data prediction. This model includes multiple convolutional layers, batch normalization layers, and residual connections to boost performance and training efficiency—a milestone already achieved by our team.\nModel Loading and Data Preprocessing: Load the pre-trained model (best_model_ultimatel.pth) and perform data preprocessing. This step involves reading data from an uploaded CSV file and applying the preprocess_data function to execute feature scaling, data splitting, and other preparatory operations, mirroring the CNN model setup.\nModel Training and Prediction: Employ the PyTorch library to load the pre-trained model and input the preprocessed data for prediction.\nResults Presentation: Exhibit the model’s performance metrics on the test dataset, such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared score, along with the prediction outcomes. These are visualized using Plotly charts, providing a comprehensive view to the users.\n\n\n\n\nflask1.png\n\n\n\napp.py: Central to the application, this file contains key functions like Convolution1D, preprocess_data, Index, show_prediction, get_table_info, view_uploaded_database, and view_database, which are integral to the app’s operation.\nTemplates folder: This directory holds all the HTML files needed for the app’s user interface, enabling interactions and data display. It includes index.html, plot.html, view_uploaded_data.html, show_prediction.html, Test_Set_Predictions.html, and view_data.html.\nData folder: Contains sample CSV files, df_2023_h1_feature.csv and df_2023_h1_target.csv, used for data upload and result demonstration in the app.\nModel folder: Houses the pre-trained model file essential for making data predictions.\n__pycache__ folder: A system-generated directory that caches bytecode, enhancing the program’s execution speed.\nStatic folder: Stores static files, crucial for the app’s styling and interactive features.\n\nThis organizational structure ensures that each aspect of our Flask web application is well-arranged and easily accessible, supporting efficient development and maintenance."
  },
  {
    "objectID": "posts/FlaskBlogPost/index.html#overview-and-impact-analysis-of-functions-in-app.py",
    "href": "posts/FlaskBlogPost/index.html#overview-and-impact-analysis-of-functions-in-app.py",
    "title": "Part 3: Flask Web App Development for Option Intrinsic Value Prediction",
    "section": "",
    "text": "In the app.py file, several key functionalities are pivotal to the web application’s operation, specifically tailored for financial data analysis and option pricing evaluation. These include:\n\nUpload and Preprocess Financial Data: This functionality allows users to upload their financial datasets and applies preprocessing techniques to prepare the data for analysis.\nView Uploaded CSV Files: Users can view the list of uploaded CSV files, providing an overview of the data available for processing.\nView Details of the Uploaded CSV Files: This feature enables users to delve into the specifics of each uploaded CSV file, examining the data more closely.\nEvaluate Option Pricing and Display Evaluation Results: The application assesses the pricing of options based on the uploaded data and displays the results, offering valuable insights into option valuation.\n\nThe app.py file incorporates essential libraries and modules to facilitate web development, data processing, machine learning, and visualization:\nfrom flask import Flask, render_template, url_for, request, flash, redirect\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom werkzeug.utils import secure_filename\nfrom torch import nn\nimport torch.nn.functional as F\nfrom flask import jsonify\nimport sqlite3\nimport math\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.graph_objects as go\nimport os\n\n\nThe Convolution1D class within our application is a custom neural network module extending nn.Module from PyTorch, designed for one-dimensional convolutional operations. This class embodies a series of convolutional, batch normalization, and fully connected layers, structured to facilitate complex pattern recognition in financial data. Notably, this implementation includes residual connections and dropout for robustness and generalization.\nNote: Building on the foundational work previously established by our team members, this segment is presented without extensive analysis to minimize redundancy.\n\n\n\nIn this section of the code, we address the computational efficiency and resource optimization for running our neural network model. The code snippet demonstrates the dynamic allocation of processing units, preferring GPU over CPU for faster computation, which is crucial for handling complex models like Convolution1D. We then load the model’s state dictionary from the file ‘best_model_ultimate.pt’. The map_location argument ensures that the loaded state dict is moved to the appropriate device. This step initializes the model with previously trained parameters, allowing for further training,evaluation, or inference without retraining from scratch. Here’s a detailed look at the operations:\n# Check for available GPU, otherwise use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# Initialize the Convolution1D model and transfer it to the chosen device\nmodel_loaded = Convolution1D().to(device)\n# Load the previously trained model state\nmodel_loaded.load_state_dict(torch.load('model/best_model_new.pt', map_location=device))\n# Set the model to evaluation mode\nmodel_loaded.eval()\n\n\n\nThe preprocess_data function tasked with preparing the financial data for subsequent analysis. It performs several key steps:\n\nData Loading: Reads the financial datasets from the specified CSV files.\nNormalization: Applies StandardScaler to normalize specific columns, ensuring uniform data scaling.\nData Merging: Combines the feature and target data into a single DataFrame for comprehensive analysis.\nData Splitting: Segregates the dataset into training, validation, and test sets, facilitating a structured approach to model training and evaluation.\n\nGiven that these processes align with our prior data handling endeavors, we will highlight only the main actions and points, avoiding detailed analysis to prevent redundancy.\n\n\n\nThe index function in app.py serves as the main entry point for our Flask web application. It handles both GET and POST requests, managing file uploads, data preprocessing, model evaluation, and rendering the results. This function aligns with our previous work, emphasizing efficient data processing and model integration. Key points include handling file uploads, data preprocessing, model prediction, error calculation, and result visualization. Below is the detailed code:\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    \"\"\"\n    This function serves as the endpoint for the root URL ('/'). It handles both GET and POST requests,\n    rendering the index page of the web application. During a POST request, it processes uploaded files\n    for option pricing evaluation, performs predictions, and returns the results along with rendering\n    the HTML template.\n\n    Returns:\n        render_template: Renders the HTML template based on the request method and the operations performed.\n    \"\"\"\n    # Check if the request method is POST, which indicates that data has been submitted to the server\n    if request.method == 'POST':\n        # Check if both files are present in the request\n        if 'file1' not in request.files or 'file2' not in request.files:\n            # If either file is missing, flash a message to the user and reload the page\n            flash('No file part')\n            return redirect(request.url)\n        file1 = request.files['file1']\n        file2 = request.files['file2']\n        \n        # Check if file names are not empty, meaning that the user has selected files\n        if file1.filename == '' or file2.filename == '':\n            # If no file is selected, flash a message and reload the page\n            flash('No selected file')\n            return redirect(request.url)\n        \n        # Check if both files exist and proceed with processing\n        if file1 and file2:\n            # Secure the file names and prepare the file paths\n            filename1 = secure_filename(file1.filename)\n            filename2 = secure_filename(file2.filename)\n            file1_path = os.path.join(app.config['UPLOAD_FOLDER'], filename1)\n            file2_path = os.path.join(app.config['UPLOAD_FOLDER'], filename2)\n            # Save the files to the server\n            file1.save(file1_path)\n            file2.save(file2_path)\n            # Notify the user that files have been uploaded successfully\n            flash('Files successfully uploaded')\n\n            # Preprocess the data from the uploaded files\n            X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(file1_path, file2_path)\n\n            # Evaluate the model on the uploaded data\n            criterion = nn.MSELoss()  # Mean Squared Error Loss function\n            with torch.no_grad():  # No gradient computation for evaluation to save memory and computations\n                output = model_loaded(X_test.to(device)).squeeze(-1)  # Model prediction\n                predictions = output\n                test_loss = criterion(predictions, y_test.to(device))  # Calculate the test loss\n\n            # Compute the Root Mean Square Error (RMSE) for the test data\n            mse_loss = criterion(predictions, y_test)\n            rmse_loss = mse_loss.item() ** (0.5)\n            \n            # Compute the R-squared (R2) score to measure the goodness of fit\n            from sklearn.metrics import r2_score\n            r2 = r2_score(y_test, predictions)\n            \n            # Create a plot of the predictions against the true values\n            fig = go.Figure()\n            fig.add_trace(go.Scatter(x=np.arange(len(output)), y=output.squeeze().numpy(), mode='lines', name='Predicted', line=dict(color='red')))\n            fig.add_trace(go.Scatter(x=np.arange(len(y_test)), y=y_test.numpy(), mode='lines', name='True', line=dict(color='blue')))\n            fig.update_layout(title='Test Set Predictions', xaxis_title='Index', yaxis_title='Value')\n            \n            # Save the plot output to a file\n            plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n            fig.write_html(plot_output_path)\n            \n            # Render the index HTML template with the results and plot path\n            return render_template('index.html', test_loss=test_loss.item(), mse_loss=mse_loss.item(),\n                                   rmse_loss=rmse_loss, r2_score=r2, plot=plot_output_path)\n\n    # If the request method is GET, render the index HTML template without any prediction or plot\n    return render_template('index.html', prediction=None, plot=None)\n\nIn summary, the index function is integral to the Flask application. It is pivotal for deploying predictive models effectively, ensuring that the application not only performs its intended analytical tasks but also provides a user-friendly interface for interaction and result interpretation. \n\n### show_prediction\n\nThe `show_prediction` function in `app.py` is designed to handle GET requests specifically for displaying the prediction results on a separate page. This functionality is crucial for providing users with access to the outcome of their data analysis, ensuring a clear and dedicated view of the predictive results.\n\nHere's a detailed analysis of the function:\n\n- **Path Definition**: Initially, the function defines the path to the prediction results file, typically stored in the `static` directory. This standardization of file location facilitates consistent access and retrieval of the results.\n\n- **Existence Check**: The function then checks if the prediction results file exists at the specified path. This check is essential to prevent errors that would occur if the application attempted to display a non-existent file.\n\n- **Conditional Rendering**: If the file exists, the function proceeds to render an HTML template (`Test_Set_Predictions.html`) specifically designed to display the prediction results. This template is passed the path of the prediction plot file, ensuring that the correct data is displayed.\n\n- **Redirection**: In cases where the prediction results file does not exist, the function redirects the user to the index page. This redirection mechanism prevents user confusion and ensures a smooth user experience by guiding them back to the starting point of the application.\n\nHere is the complete code snippet:\n\n```python\n@app.route('/show_prediction', methods=['GET'])\ndef show_prediction():\n    \n    # Define the path to the prediction results file, assumed to be in the 'static' directory\n    plot_output_path = os.path.join('static', 'Test_Set_Predictions.html')\n    \n    # Check if the prediction results file exists\n    if not os.path.exists(plot_output_path):\n        # If the file does not exist, redirect the user to the index page\n        return redirect(url_for('index'))\n\n    # If the file exists, render the template to display the prediction results,\n    # passing the path of the prediction plot file to the template\n    return render_template('Test_Set_Predictions.html', plot_output_path=plot_output_path)\n\n### get_table_info\n\nThe `get_table_info` function is designed to streamline the process of extracting filenames from full file paths, which is a common requirement in web applications handling file uploads. By utilizing `os.path.basename`, it efficiently strips the directory path, leaving only the file name. This functionality is particularly useful in scenarios where the display or processing of filenames, independent of their storage paths, is required. Here's how the function operates:\n\n```python\ndef get_table_info(file1_path, file2_path):\n    return [os.path.basename(file1_path), os.path.basename(file2_path)]\n\n### view_uploaded_data\n\nThe `view_uploaded_data` function in the Flask web application serves to showcase the files that have been uploaded by users. This endpoint, accessible via a GET request, retrieves and displays the contents of the upload directory in the application's user interface. Here's an in-depth look at the function and its code:\n\n```python\n@app.route('/view_uploaded_data', methods=['GET'])\ndef view_uploaded_data():\n    \"\"\"\n    Handles the GET request to display the uploaded database files.\n\n    This endpoint fetches the list of files present in the upload directory and displays them\n    on the 'view_uploaded_data.html' page. This allows users to see which files have been\n    uploaded to the application.\n\n    The function retrieves the filenames from the specified upload folder set in the app's configuration\n    and passes these filenames to the rendering template.\n    \n    \"\"\"\n    \n    # Retrieve the list of files in the upload directory\n    files = os.listdir(app.config['UPLOAD_FOLDER'])\n    \n    # Render the HTML template, passing the list of files for display on the webpage\n    return render_template('view_uploaded_data.html', files=files)\n\n### view_data\n\nThe `view_data` endpoint in the Flask application is designed to showcase the details of the uploaded CSV files through a GET request. It facilitates the inspection of the contents of these files, enhancing the user's ability to interact with and analyze the uploaded data. The function operates by expecting `filename1` and `filename2` as query parameters, utilizing these to locate and display the respective files' contents. Here's a closer look at the function and its operations:\n\n```python\n@app.route('/view_data', methods=['GET'])\ndef view_data():\n    \"\"\"\n    The function checks for the existence of the specified files in the upload directory.\n    If both files exist, it reads them as CSVs and prepares the data for viewing. If either\n    file is missing or an error occurs during file reading, the user is redirected to the\n    file upload view with an appropriate error message.\n    \"\"\"\n    # Retrieve filenames from the request's query parameters\n    filename1 = request.args.get('filename1')\n    filename2 = request.args.get('filename2')\n    \n    # Validate that both filenames are provided\n    if not filename1 or not filename2:\n        flash('No data file selected.')\n        return redirect(url_for('view_uploaded_data'))\n    \n    # Construct full file paths\n    file1_path = os.path.join(app.config['UPLOAD_FOLDER'], filename1)\n    file2_path = os.path.join(app.config['UPLOAD_FOLDER'], filename2)\n\n    # Check if both files exist in the specified upload folder\n    if not os.path.exists(file1_path) or not os.path.exists(file2_path):\n        flash('Data file not found.')\n        return redirect(url_for('view_uploaded_data'))\n\n    try:\n        # Attempt to read the files as CSVs and store their contents\n        ds = pd.read_csv(file1_path)\n        target = pd.read_csv(file2_path)\n        table_data = {'Dataset 1': ds, 'Dataset 2': target}\n    except Exception as e:\n        # Handle any error that occurs during file reading and flash an error message\n        flash(f'Error accessing CSV files: {e}')\n        return redirect(url_for('view_uploaded_data'))\n    # Render the view template with the loaded table data and filenames\n    return render_template('view_data.html', tables=table_data, filename1=filename1, filename2=filename2)\n\nThe concluding part of our Flask application's code features the standard Python idiom to check if the script is executed as the main program and not imported as a module. This check is crucial for initiating the Flask server only when the script is run directly, ensuring that the application's startup process is controlled and deliberate. The `app.run(debug=True)` line activates the Flask application server with debug mode enabled, which is beneficial during development for its detailed error feedback and live reloading capabilities. Here's the segment:\n\n```python\n# This conditional statement checks if the script is run as the main program.\n# Ensure that code is only executed when the script is run directly, and not when imported as a module.\nif __name__ == '__main__':\n    # The app.run(debug=True) command starts the Flask application server.\n    # The debug=True argument enables debug mode, which provides useful feedback in the browser for development,\n    # including detailed tracebacks and live reloading on code changes.\n    app.run(debug=True)\n\n## 3.2 Evaluative Overview of HTML Templates: Implications for User Interface and Experience\n\n![flask2.png](index_files/figure-html/cell-26-1-flask2.png)\n\nOur web application uses a set of HTML templates, each carefully crafted to improve how users interact with and see data. These templates are essential to the app's design, blending good looks with practical use. They guide users from the start of entering data to the end of seeing the results. \n- `index.html`: Serves as the primary gateway to the web application, designed for predicting call option values. It incorporates Bootstrap for styling, providing a responsive layout with file upload forms, navigation buttons, and result display sections, thus ensuring a user-friendly experience.\n\n- `plot.html`: Utilizes Plotly for dynamic data visualization, offering interactive charts that render complex datasets in an easily digestible format, enhancing the analytical capabilities of the application.\n\n- `view_uploaded_data.html`: Lists the uploaded database files, enabling users to access and review the data they have provided, fostering transparency and control over the processed information.\n\n- `view_data.html`: Exhibits the content from two distinct datasets, providing a comprehensive view of the data under analysis and facilitating a deeper understanding of the predictive context.\n\n- `show_prediction.html`: Displays the outcome of predictive analyses, guiding users to detailed visual representations and insights derived from their data.\n\n- `Test_Set_Predictions.html`: Incorporates Plotly JavaScript to generate interactive data visualizations, allowing for an engaging and informative exploration of predictive results within the web environment.\n\nNext, we will conduct a comprehensive analysis of each template's functionalities and contributions, examining the web pages in our prototype to assess their quality and effectiveness.\n\n### 3.2.1 Welcome Page\n\nOur welcome page design seamlessly integrates various elements to optimize `user experience` and `functionality`. Users are provided with intuitive `\"Browse\" buttons` to swiftly upload local CSV files. Upon clicking the `\"Upload & Save\" button`, evaluation results are promptly generated within a few-second timeframe, ensuring `efficiency` in data processing. Additionally, users can easily access and review their uploaded dataset (csv files) online by selecting the `\"View Data\"`. For a comprehensive analysis, users can explore `interactive prediction graphs` through the `\"View Prediction\" feature`, enhancing their ability to interpret and analyze data trends effectively.\n\n![flask3.png](index_files/figure-html/cell-31-1-flask3.png)\n\n#### Color Scheme and Aesthetics `index.html`\n\n- **Color Choice:** In `index.html`, we deliberately choose a light blue background color (#ADD8E6) to promote a serene ambiance conducive to focused reading and analysis. The semi-transparent white background (rgba(255, 255, 255, 0.8)) within container elements aims to highlight content while maintaining visual harmony.\n```html\n&lt;style&gt;\n    body {\n        background-color: #ADD8E6;\n        padding-top: 20px;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        height: 100vh;\n    }\n    .container {\n        max-width: 800px;\n        text-align: center;\n        background-color: rgba(255, 255, 255, 0.8);\n        padding: 40px;\n        border-radius: 20px;\n    }\n    /* Additional CSS styles for buttons, labels, and text sizes are also defined in this section */\n&lt;/style&gt;\n\n#### Modular Design with Bootstrap in `index.html`\n\n- **Grid System Utilization:** We utilize Bootstrap's grid system to create a responsive layout, dividing content into grid columns with classes like `container`, `row`, and `col-*`, ensuring seamless alignment across devices. This fosters a visually appealing and user-friendly design. Here's how it's integrated:\n\n```html\n&lt;div class=\"container\"&gt;\n    &lt;!-- Content structured using Bootstrap's grid system --&gt;\n&lt;/div&gt;\n\n- **Custom CSS Classes Integration:** Custom CSS classes are integrated to style elements such as buttons, forms, and text, maintaining a cohesive design language and enhancing visual appeal.\n\n```css\n.btn-group .btn {\n    margin: 0 10px;\n    font-size: 36px;\n}\n\n- **Responsive Design Features:** Leveraging Bootstrap's responsive utilities like breakpoints and flexbox classes (`d-flex`, `justify-content-center`, `align-items-center`), we ensure our webpage adapts smoothly to various screen sizes and orientations for optimal user experience.\n\n```html\n&lt;div class=\"container\"&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n&lt;/div&gt;\n\n- **Component Reusability:** By using Bootstrap's built-in components such as navigation bars, buttons, and forms, we enhance code modularity and maintain a consistent design language throughout the project, saving time and effort in UI development.\n\n```html\n&lt;div class=\"btn-group\" role=\"group\" aria-label=\"Actions\"&gt;\n    &lt;a href=\"{{ url_for('view_data') }}\" class=\"btn btn-info\"&gt;View Data&lt;/a&gt;\n    &lt;a href=\"{{ url_for('show_prediction') }}\" class=\"btn btn-info\"&gt;View Prediction&lt;/a&gt;\n&lt;/div&gt;\n\n### 3.2.2 Evaluation & Results Page\n\nAfter clicking the `\"Upload & Save\"` button, the client is directed to our **Evaluation & Results** page, where they can view both numerical results and an interactive graph which provides visual insights, allowing users to explore and analyze the data trends effectively.\n\n![flask4.png](index_files/figure-html/cell-39-1-flask4.png)\n\n\n**Numerical Results Display in `evaluate_and_visualize.html`**\n\n```html\n{% if test_loss is defined %}\n    &lt;h2&gt;Evaluation Results:&lt;/h2&gt;\n    &lt;p&gt;Test Loss: {{ test_loss }}&lt;/p&gt;\n    &lt;p&gt;MSE Loss: {{ mse_loss }}&lt;/p&gt;\n    &lt;p&gt;RMSE Loss: {{ rmse_loss }}&lt;/p&gt;\n    &lt;p&gt;R2 Score: {{ r2_score }}&lt;/p&gt;\n    &lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n{% endif %}\n\nClarity: The page presents evaluation metrics such as Test Loss, Mean Squared Error (MSE) Loss, Root Mean Squared Error (RMSE) Loss, and R-squared (R2) Score in a clear and structured manner using HTML &lt;p&gt; tags. This clarity enhances the understanding of model performance.\nPrecision: The page ensures the precision and accuracy of displayed numerical values, crucial for data analysis. It typically maintains a precision of at least ten decimal places, ensuring data accuracy for in-depth analysis and comparison.\nContextual Rendering: The use of conditional blocks ensures that numerical results are displayed only when relevant data is available, preventing confusion and presenting information contextually.\n\nEmbedding Plotly Graph in evaluate_and_visualize.html\n&lt;iframe src=\"{{ plot }}\" width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n\nVisual Analysis: The page enhances data analysis by embedding a Plotly graph within an &lt;iframe&gt;. This interactive graph provides visual insights into trends and patterns, complementing the numerical results.\nInteractivity: Users can interact with the embedded Plotly graph, such as zooming, panning, and hovering over data points to view detailed information. This interactivity fosters a deeper understanding of data trends and anomalies.\nIntegration: The seamless integration of the Plotly graph within the HTML page enhances user experience, allowing for a comprehensive analysis of model performance with both numerical and visual data representations.\n\n\n\n\nBy clicking the “View Data” button, users are directed to the data page, where all previously uploaded data files are displayed. Each file is accompanied by a “View” button on the right-hand side, allowing users to view the uploaded data online with a single click.\n\n\n\nflask5.png\n\n\nFile Listing in view_data.html\n&lt;!-- Table body section to display the content. --&gt;\n&lt;tbody&gt;\n    &lt;!-- Loop through each file in the 'files' list passed from the Flask backend. --&gt;\n    {% for file in files %}\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename1=file, filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt; &lt;!-- Link to view data. --&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\nThe “File Name” column displays each uploaded file’s name, fetched from the files list passed from the backend. Within each table row (\n\n), the file name is displayed in the “File Name” column (\n\n{{ file }}\n\n). This ensures that users can easily identify and select the files they want to view.\n\nActionable Links in view_data.html\n&lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n\nThe “Actions” column provides a convenient “View” link for each file, allowing users to seamlessly navigate to detailed data views with a single click. This intuitive design enhances the overall user experience and promotes efficient data exploration.\nThe “View” links are dynamically generated using Flask’s powerful url_for function, ensuring accurate and reliable navigation to the corresponding data views.\n\n\n\n\nWhen users click the “View” button on the View Data Page, they are seamlessly navigated to a dynamically generated web page that displays the data they have previously uploaded. This feature provides users with a convenient and intuitive way to access and examine their uploaded datasets within the application, enhancing the overall user experience and facilitating efficient data analysis.\n\n\n\nflask6.png\n\n\nDynamic Content Rendering in view_uploaded_data.html\nThe &lt;tbody&gt; section of the table dynamically displays uploaded files. This functionality is achieved through the use of server-side templating, specifically with Jinja2 in Flask, allowing for iteration over a list of files and rendering each as a row in the table.\n\nFunctionality: Iteration over the files array to create a table row for each file.\nData Binding: Server-side rendering with { file } to bind file names directly into the table.\nDynamic URL Generation: The url_for function generates actionable links for each file, enabling user interaction.\n\nHere is the code snippet in view_uploaded_data.html illustrating this functionality:\n&lt;tbody&gt;\n    &lt;!-- Table body section to display the content. --&gt;\n    {% for file in files %}\n    &lt;!-- Loop through each file in the 'files' list passed from the Flask backend. --&gt;\n    &lt;tr&gt;\n        &lt;td&gt;{{ file }}&lt;/td&gt; &lt;!-- Displaying the file name. --&gt;\n        &lt;td&gt;&lt;a href=\"{{ url_for('view_data', filename1=file, filename2=file) }}\"&gt;View&lt;/a&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    {% endfor %}\n&lt;/tbody&gt;\n\n### 3.2.5 View Prediction Page\n\nUpon selecting the \"View Prediction\" button on the initial interface, users are directed to a page displaying test set predictions, featuring an interactive graph created with Plotly. This visualization fosters an engaging user experience, permitting detailed examination of the predictions. The graph's interactive features—zoom, pan, and data point hover—provide enriched informational access, allowing tailored analytical perspectives.\n\n![flask7.png](index_files/figure-html/cell-53-1-flask7.png)\n\nThe graph offers intuitive controls for a seamless user experience. Users can double-click to revert to the original zoom level after examining specific intervals. The operation bar in the upper right corner allows users to download the plot as a PNG, autoscale the axes, and reset the axes effortlessly.\n\n![flask8.png](index_files/figure-html/cell-55-1-flask8.png)\n\n![flask9.png](index_files/figure-html/cell-56-1-flask9.png)\n\n**Dynamic Plot Rendering with Plotly in `plot.html`**\n```html\n&lt;script src=\"https://cdn.plot.ly/plotly-latest.min.js\"&gt;&lt;/script&gt;\n&lt;div id=\"plot\"&gt;&lt;/div&gt;\n&lt;script&gt;\n    var plot_path = \"{{ plot_path }}\";\n    Plotly.d3.html(plot_path, function(error, data) {\n        if (error) {\n            return console.warn(error);\n        }\n        document.getElementById('plot').innerHTML = data;\n    });\n&lt;/script&gt;\n\nIntegration with Plotly: The inclusion of the Plotly library through the &lt;script&gt; tag is a significant aspect of this template.\nAsynchronous Data Fetching: The JavaScript block fetches the plot data asynchronously using Plotly’s d3.html function. This method loads the plot data from a specified path (plot_path), which is dynamically provided by the server-side application. This approach ensures that the webpage remains responsive and that the plot is updated seamlessly without the need for a full page reload.\nDynamic Content Loading: The template utilizes an empty\n\nelement with the id plot, which serves as a placeholder for the graph. The actual content of the graph is loaded dynamically through JavaScript, enabling the webpage to render data-driven plots efficiently.\n\nConditional Rendering and Link Generation in show_prediction.html\n{% if prediction %}\n    &lt;h3&gt;Predicted Mean: {{ prediction }}&lt;/h3&gt;\n    &lt;p&gt;&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;View Test Set Predictions Plot&lt;/a&gt;&lt;/p&gt;\n{% else %}\n    &lt;p&gt;No prediction available&lt;/p&gt;\n{% endif %}\n&lt;a href=\"{{ url_for('index') }}\" class=\"btn btn-primary\"&gt;Go Back&lt;/a&gt;\n\nConditional Content Display: The template employs Jinja2’s conditional syntax {% if prediction %} to check the presence of a prediction variable. This approach ensures that the user interface adapts to the data context, displaying the prediction results when available. If the prediction variable contains a value, the template renders an &lt;h3&gt; tag showing the predicted mean, enhancing the user’s understanding of the model output.\nDynamic Link Creation: The template dynamically generates a link to a plot (&lt;a href=\"{{ plot }}\" target=\"_blank\"&gt;) when prediction data is available. This link, opened in a new tab (target=“_blank”), leads to a detailed visualization of the test set predictions."
  },
  {
    "objectID": "posts/FlaskBlogPost/index.html#summary",
    "href": "posts/FlaskBlogPost/index.html#summary",
    "title": "Part 3: Flask Web App Development for Option Intrinsic Value Prediction",
    "section": "",
    "text": "Our web application, through its meticulously designed templates and key features, offers a streamlined and enriched user experience. We are committed to enabling users to efficiently manage, analyze, and interpret their data within a cohesive and intuitive environment. By providing a user-friendly interface and powerful functionality, we sincerely aim to empower users to harness the full potential of their data. Our goal is to support users in making informed decisions and fostering a deeper understanding of their analytical contexts."
  },
  {
    "objectID": "posts/16BHW2/index.html",
    "href": "posts/16BHW2/index.html",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In today’s tutorial, we are going to learn how to use webscraping to build a “recommender system”, answering the following questions:  What movie or TV shows share a actor with your favorite movie or show? We assume that if Movie Y has many of the same actors as your favorite Movie X, you might also enjoy Y. To see how we develop a webscraper, please scroll down to section 2.\n\n\n\n\n\nWe need to first choose one favorite movie on TMDB page, here I choose “Harry Potter and the Philosopher’s Stone”, with url: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/\n\n\n\nLet’s “reherse” what our scraper will do; follong these steps: First, we click on the Full Cast & Crew link, which leads us to the page origianl-url/cast (https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/cast) in this case. Second, we click on the portrait of one of the actors, which leads us to a different url, introducing the actor’s acting credit, like this: https://www.themoviedb.org/person/10980-daniel-radcliffe  Finally, we stay in this page, and scroll down to examine the actor’s Acting section, seeing the titles of a few movies and TV shows in this section. Remember our scraper is going to replicate the exact same process: “Staring with your favorite movie, it’s going to look at all the actors in that movie, and then log all the other movies of TV shows they worked on” **Note that it would be agood idea to use the Developer Tools to inspect individual HTML elements and look for patterns among the names you are looking for.\n\n\n\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nUse this code to initialize the project\n\n\n\nAdd the folloing line to the file settings.py to prevent scraper from downloading too much data while you’re still testing.\nCLOSESPIDER_PAGECOUNT = 20\nPS: you will remove this line later! PPS: If you run into 403 Forbidden errors latter, you need to change user agent line in setting.py, one way to change user agent on scrapy shell is\nscrapy shell -s USER_AGENT='Scrapy/2.8.0 (+https://scrapy.org)' https://www.themoviedb.org/...\n\n\n\n\nIn this section, we create a file tmdb_spider.py inside the spiders directory called tmdb_spider.py. Note we will write scraper codes in this file.\n\n# to run \n# scrapy crawl tmdb_spider -o movies.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    # Give a unique identifier for spider name, used to trigger this certain spider from the command line\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n        \"\"\"\n        Initialize the spider instance with a specific movie's subdirectory.\n        This subdirectory is essential for crafting the starting URL from which the spider begins scraping.\n        \n        :param subdir: Subdirectory for the movie on TMDB site, used to build the start URL\n        :param args: Positional arguments\n        :param kwargs: Keyword arguments\n        \"\"\"\n        super(TmdbSpider, self).__init__(*args, **kwargs)\n        # Set the starting URL to scrape based on the provided movie subdirectory.\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\n    def parse(self, response):\n        \"\"\"\n        Parses the main movie page, extracts the from the full cast, and makes a request to that link\n        :param response: The response object containing the content of the movies' main page\n        \"\"\"\n        # Extracts the link to the \"full cast and crew\" page from the main movie page\n        full_cast_link = response.css('p.new_button a::attr(href)').get()\n        if full_cast_link:\n            # If the link is found, make a request to the cast list page\n            yield response.follow(full_cast_link, self.parse_full_credits)\n    \n    def parse_full_credits(self, response):\n        \"\"\"\n        Parses the \"Full Cast & Crew\" page, extracts each individual actor's personal page links, and makes requests to those pages.\n        :param response: contains the content of the \"Full Cast & Crew\" page.\n        \"\"\"\n        # Selects only the first \"panel pad\" section of the page using CSS selectors\n        first_panel_pad = response.xpath('(//section[contains(@class, \"panel\") and contains(@class, \"pad\")])[1]')\n        for actor in first_panel_pad.css('ol.people.credits &gt; li'):\n            # Extracts the individual actor page link，not including crew members\n            actor_page = actor.css('a::attr(href)').get()\n            if actor_page:\n                # Makes a request to the actor's personal page, directing go to its acting role section\n                yield response.follow(actor_page + '?credit_department=Acting', self.parse_actor_page)\n                \n    def parse_actor_page(self, response):\n        \"\"\"\n        Parses the actor's personal page, extracting information about the movies or TV shows the actor has participated in.\n        :param response: The response object containing the content of the actor's personal page. \n        We want only the works listed in \"Acting\" section for the actor page.\n        We need to determine both the name of actor and the name of each movie/show.\n        \"\"\"\n        # Extracts the actor's name\n        actor_name = response.css('h2.title a::text').get()\n        # Directly gets all texts of this structure by using xpath a[@class='tooltip']/bdi\n        movies = response.xpath('//a[@class=\"tooltip\"]/bdi/text()').getall()\n        # Extracts the title of the work\n        for title in movies:\n            # Yields a dictionary (two key-value pairs) containing the actor's name and the title of the work\n            yield {\n                'actor': actor_name,\n                'movie_or_TV_name': title\n            }\n\nAfter successfully build the spider, we can run this command in terminal: \nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone \nWhich run the spider and save a results.csv file with columns for actor names and the movies and TV shows on which they featured in.\nOnce the spider is fully written, we can comment out the line  CLOSESPIDER_PAGECOUNT = 20  in the settings.py file, then run this command in the terminal to generate a results.csv  scrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nThis results.csv will contain columns for actor names and the movies and TV shows on which they featured in.\n\n\n\nIn this section, I will introduce visualization of numbers of shared actors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\ndata=pd.read_csv('results.csv')\nprint(data)\n\n                 actor                    movie_or_TV_name\n0     Daniel Radcliffe  Have I Got a Bit More News for You\n1     Daniel Radcliffe     David Holmes: The Boy Who Lived\n2     Daniel Radcliffe           100 Years of Warner Bros.\n3     Daniel Radcliffe                            Mulligan\n4     Daniel Radcliffe                             Digman!\n...                ...                                 ...\n2956      Rupert Grint                            The View\n2957      Rupert Grint                                GMTV\n2958      Rupert Grint      The Tonight Show with Jay Leno\n2959      Rupert Grint                 An Audience with...\n2960      Rupert Grint                               Today\n\n[2961 rows x 2 columns]\n\n\n\nprint(data.head(35))\n\n               actor                                   movie_or_TV_name\n0   Daniel Radcliffe                 Have I Got a Bit More News for You\n1   Daniel Radcliffe                    David Holmes: The Boy Who Lived\n2   Daniel Radcliffe                          100 Years of Warner Bros.\n3   Daniel Radcliffe                                           Mulligan\n4   Daniel Radcliffe                                            Digman!\n5   Daniel Radcliffe                                     Extrapolations\n6   Daniel Radcliffe                       Weird: The Al Yankovic Story\n7   Daniel Radcliffe                                      The Lost City\n8   Daniel Radcliffe  Harry Potter 20th Anniversary: Return to Hogwarts\n9   Daniel Radcliffe                         (K)nox: The Rob Knox Story\n10  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Music...\n11  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Reverend\n12  Daniel Radcliffe                     Endgame & Rough for Theatre II\n13  Daniel Radcliffe                               Escape from Pretoria\n14  Daniel Radcliffe                                        Guns Akimbo\n15  Daniel Radcliffe                            The Kelly Clarkson Show\n16  Daniel Radcliffe                               Playmobil: The Movie\n17  Daniel Radcliffe                                    Miracle Workers\n18  Daniel Radcliffe                                    Beast of Burden\n19  Daniel Radcliffe                                      2 Dope Queens\n20  Daniel Radcliffe  The Robot Chicken Walking Dead Special: Die wa...\n21  Daniel Radcliffe                                             Jungle\n22  Daniel Radcliffe  National Theatre Live: Rosencrantz & Guildenst...\n23  Daniel Radcliffe                                     Lost in London\n24  Daniel Radcliffe                                           Imperium\n25  Daniel Radcliffe                                     Swiss Army Man\n26  Daniel Radcliffe                                   Now You See Me 2\n27  Daniel Radcliffe                                Victor Frankenstein\n28  Daniel Radcliffe                                   The Gamechangers\n29  Daniel Radcliffe                 The Late Show with Stephen Colbert\n30  Daniel Radcliffe                                         Trainwreck\n31  Daniel Radcliffe                     Tom Felton Meets the Superfans\n32  Daniel Radcliffe                                           Hot Ones\n33  Daniel Radcliffe                                    BoJack Horseman\n34  Daniel Radcliffe                                 Trailblazer Honors\n\n\n\n\"\"\"\nCounts the occurrences of each unique value in the 'actor' column of the dataframe 'data' and returns a Series.\nThe index of the Series will be the actor names, and the values will be the count of movies each actor has appeared in.\n\"\"\"\nactor_counts = data['actor'].value_counts()\n\n\n\n\n\nactor_counts\n\nactor\nJohn Cleese          241\nJohn Hurt            233\nJulie Walters        152\nRobbie Coltrane      150\nLeslie Phillips      134\n                    ... \nBen Borowiecki         2\nEmily Dale             2\nWill Theakston         2\nLeilah Sutherland      1\nSaunders Triplets      1\nName: count, Length: 63, dtype: int64\n\n\n\n\"\"\"\nThis script visualizes the number of movies each actor has appeared in using a bar plot.\n\"\"\"\n\n# Creates a new figure with a specified size.\nplt.figure(figsize=(12,6))\n\n# Creates a bar plot using seaborn. The x-axis represents actors, and the y-axis represents the count of movies.\n# `actor_counts` is assumed to be a pandas Series where the index contains actor names and values represent movie counts.\nsns.barplot(x=actor_counts.index, y=actor_counts.values)\n\n# Rotates the x-axis labels (actor names) by 90 degrees to prevent overlap and improve readability.\nplt.xticks(rotation=90)\n\n# Sets the label for the x-axis as 'Actor'.\nplt.xlabel('Actor')\n\n# Sets the label for the y-axis as 'Movie Count'.\nplt.ylabel('Movie Count')\n\n# Sets the title of the plot as 'Number of Movies for Each Actor'.\nplt.title('Number of Movies for Each Actor')\n\n# Adjusts the layout to make sure everything fits within the figure area without any clipping.\nplt.tight_layout()\n\n# Displays the plot.\nplt.show()"
  },
  {
    "objectID": "posts/16BHW2/index.html#introduction",
    "href": "posts/16BHW2/index.html#introduction",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In today’s tutorial, we are going to learn how to use webscraping to build a “recommender system”, answering the following questions:  What movie or TV shows share a actor with your favorite movie or show? We assume that if Movie Y has many of the same actors as your favorite Movie X, you might also enjoy Y. To see how we develop a webscraper, please scroll down to section 2."
  },
  {
    "objectID": "posts/16BHW2/index.html#setup",
    "href": "posts/16BHW2/index.html#setup",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "We need to first choose one favorite movie on TMDB page, here I choose “Harry Potter and the Philosopher’s Stone”, with url: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/\n\n\n\nLet’s “reherse” what our scraper will do; follong these steps: First, we click on the Full Cast & Crew link, which leads us to the page origianl-url/cast (https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/cast) in this case. Second, we click on the portrait of one of the actors, which leads us to a different url, introducing the actor’s acting credit, like this: https://www.themoviedb.org/person/10980-daniel-radcliffe  Finally, we stay in this page, and scroll down to examine the actor’s Acting section, seeing the titles of a few movies and TV shows in this section. Remember our scraper is going to replicate the exact same process: “Staring with your favorite movie, it’s going to look at all the actors in that movie, and then log all the other movies of TV shows they worked on” **Note that it would be agood idea to use the Developer Tools to inspect individual HTML elements and look for patterns among the names you are looking for.\n\n\n\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nUse this code to initialize the project\n\n\n\nAdd the folloing line to the file settings.py to prevent scraper from downloading too much data while you’re still testing.\nCLOSESPIDER_PAGECOUNT = 20\nPS: you will remove this line later! PPS: If you run into 403 Forbidden errors latter, you need to change user agent line in setting.py, one way to change user agent on scrapy shell is\nscrapy shell -s USER_AGENT='Scrapy/2.8.0 (+https://scrapy.org)' https://www.themoviedb.org/..."
  },
  {
    "objectID": "posts/16BHW2/index.html#write-scraper",
    "href": "posts/16BHW2/index.html#write-scraper",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In this section, we create a file tmdb_spider.py inside the spiders directory called tmdb_spider.py. Note we will write scraper codes in this file.\n\n# to run \n# scrapy crawl tmdb_spider -o movies.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    # Give a unique identifier for spider name, used to trigger this certain spider from the command line\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n        \"\"\"\n        Initialize the spider instance with a specific movie's subdirectory.\n        This subdirectory is essential for crafting the starting URL from which the spider begins scraping.\n        \n        :param subdir: Subdirectory for the movie on TMDB site, used to build the start URL\n        :param args: Positional arguments\n        :param kwargs: Keyword arguments\n        \"\"\"\n        super(TmdbSpider, self).__init__(*args, **kwargs)\n        # Set the starting URL to scrape based on the provided movie subdirectory.\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\n    def parse(self, response):\n        \"\"\"\n        Parses the main movie page, extracts the from the full cast, and makes a request to that link\n        :param response: The response object containing the content of the movies' main page\n        \"\"\"\n        # Extracts the link to the \"full cast and crew\" page from the main movie page\n        full_cast_link = response.css('p.new_button a::attr(href)').get()\n        if full_cast_link:\n            # If the link is found, make a request to the cast list page\n            yield response.follow(full_cast_link, self.parse_full_credits)\n    \n    def parse_full_credits(self, response):\n        \"\"\"\n        Parses the \"Full Cast & Crew\" page, extracts each individual actor's personal page links, and makes requests to those pages.\n        :param response: contains the content of the \"Full Cast & Crew\" page.\n        \"\"\"\n        # Selects only the first \"panel pad\" section of the page using CSS selectors\n        first_panel_pad = response.xpath('(//section[contains(@class, \"panel\") and contains(@class, \"pad\")])[1]')\n        for actor in first_panel_pad.css('ol.people.credits &gt; li'):\n            # Extracts the individual actor page link，not including crew members\n            actor_page = actor.css('a::attr(href)').get()\n            if actor_page:\n                # Makes a request to the actor's personal page, directing go to its acting role section\n                yield response.follow(actor_page + '?credit_department=Acting', self.parse_actor_page)\n                \n    def parse_actor_page(self, response):\n        \"\"\"\n        Parses the actor's personal page, extracting information about the movies or TV shows the actor has participated in.\n        :param response: The response object containing the content of the actor's personal page. \n        We want only the works listed in \"Acting\" section for the actor page.\n        We need to determine both the name of actor and the name of each movie/show.\n        \"\"\"\n        # Extracts the actor's name\n        actor_name = response.css('h2.title a::text').get()\n        # Directly gets all texts of this structure by using xpath a[@class='tooltip']/bdi\n        movies = response.xpath('//a[@class=\"tooltip\"]/bdi/text()').getall()\n        # Extracts the title of the work\n        for title in movies:\n            # Yields a dictionary (two key-value pairs) containing the actor's name and the title of the work\n            yield {\n                'actor': actor_name,\n                'movie_or_TV_name': title\n            }\n\nAfter successfully build the spider, we can run this command in terminal: \nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone \nWhich run the spider and save a results.csv file with columns for actor names and the movies and TV shows on which they featured in.\nOnce the spider is fully written, we can comment out the line  CLOSESPIDER_PAGECOUNT = 20  in the settings.py file, then run this command in the terminal to generate a results.csv  scrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nThis results.csv will contain columns for actor names and the movies and TV shows on which they featured in."
  },
  {
    "objectID": "posts/16BHW2/index.html#make-your-recommendations-visualization",
    "href": "posts/16BHW2/index.html#make-your-recommendations-visualization",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In this section, I will introduce visualization of numbers of shared actors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\ndata=pd.read_csv('results.csv')\nprint(data)\n\n                 actor                    movie_or_TV_name\n0     Daniel Radcliffe  Have I Got a Bit More News for You\n1     Daniel Radcliffe     David Holmes: The Boy Who Lived\n2     Daniel Radcliffe           100 Years of Warner Bros.\n3     Daniel Radcliffe                            Mulligan\n4     Daniel Radcliffe                             Digman!\n...                ...                                 ...\n2956      Rupert Grint                            The View\n2957      Rupert Grint                                GMTV\n2958      Rupert Grint      The Tonight Show with Jay Leno\n2959      Rupert Grint                 An Audience with...\n2960      Rupert Grint                               Today\n\n[2961 rows x 2 columns]\n\n\n\nprint(data.head(35))\n\n               actor                                   movie_or_TV_name\n0   Daniel Radcliffe                 Have I Got a Bit More News for You\n1   Daniel Radcliffe                    David Holmes: The Boy Who Lived\n2   Daniel Radcliffe                          100 Years of Warner Bros.\n3   Daniel Radcliffe                                           Mulligan\n4   Daniel Radcliffe                                            Digman!\n5   Daniel Radcliffe                                     Extrapolations\n6   Daniel Radcliffe                       Weird: The Al Yankovic Story\n7   Daniel Radcliffe                                      The Lost City\n8   Daniel Radcliffe  Harry Potter 20th Anniversary: Return to Hogwarts\n9   Daniel Radcliffe                         (K)nox: The Rob Knox Story\n10  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Music...\n11  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Reverend\n12  Daniel Radcliffe                     Endgame & Rough for Theatre II\n13  Daniel Radcliffe                               Escape from Pretoria\n14  Daniel Radcliffe                                        Guns Akimbo\n15  Daniel Radcliffe                            The Kelly Clarkson Show\n16  Daniel Radcliffe                               Playmobil: The Movie\n17  Daniel Radcliffe                                    Miracle Workers\n18  Daniel Radcliffe                                    Beast of Burden\n19  Daniel Radcliffe                                      2 Dope Queens\n20  Daniel Radcliffe  The Robot Chicken Walking Dead Special: Die wa...\n21  Daniel Radcliffe                                             Jungle\n22  Daniel Radcliffe  National Theatre Live: Rosencrantz & Guildenst...\n23  Daniel Radcliffe                                     Lost in London\n24  Daniel Radcliffe                                           Imperium\n25  Daniel Radcliffe                                     Swiss Army Man\n26  Daniel Radcliffe                                   Now You See Me 2\n27  Daniel Radcliffe                                Victor Frankenstein\n28  Daniel Radcliffe                                   The Gamechangers\n29  Daniel Radcliffe                 The Late Show with Stephen Colbert\n30  Daniel Radcliffe                                         Trainwreck\n31  Daniel Radcliffe                     Tom Felton Meets the Superfans\n32  Daniel Radcliffe                                           Hot Ones\n33  Daniel Radcliffe                                    BoJack Horseman\n34  Daniel Radcliffe                                 Trailblazer Honors\n\n\n\n\"\"\"\nCounts the occurrences of each unique value in the 'actor' column of the dataframe 'data' and returns a Series.\nThe index of the Series will be the actor names, and the values will be the count of movies each actor has appeared in.\n\"\"\"\nactor_counts = data['actor'].value_counts()\n\n\n\n\n\nactor_counts\n\nactor\nJohn Cleese          241\nJohn Hurt            233\nJulie Walters        152\nRobbie Coltrane      150\nLeslie Phillips      134\n                    ... \nBen Borowiecki         2\nEmily Dale             2\nWill Theakston         2\nLeilah Sutherland      1\nSaunders Triplets      1\nName: count, Length: 63, dtype: int64\n\n\n\n\"\"\"\nThis script visualizes the number of movies each actor has appeared in using a bar plot.\n\"\"\"\n\n# Creates a new figure with a specified size.\nplt.figure(figsize=(12,6))\n\n# Creates a bar plot using seaborn. The x-axis represents actors, and the y-axis represents the count of movies.\n# `actor_counts` is assumed to be a pandas Series where the index contains actor names and values represent movie counts.\nsns.barplot(x=actor_counts.index, y=actor_counts.values)\n\n# Rotates the x-axis labels (actor names) by 90 degrees to prevent overlap and improve readability.\nplt.xticks(rotation=90)\n\n# Sets the label for the x-axis as 'Actor'.\nplt.xlabel('Actor')\n\n# Sets the label for the y-axis as 'Movie Count'.\nplt.ylabel('Movie Count')\n\n# Sets the title of the plot as 'Number of Movies for Each Actor'.\nplt.title('Number of Movies for Each Actor')\n\n# Adjusts the layout to make sure everything fits within the figure area without any clipping.\nplt.tight_layout()\n\n# Displays the plot.\nplt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html",
    "href": "posts/16BHW4/index.html",
    "title": "PIC16B HW4",
    "section": "",
    "text": "In this tutorial, four approaches of simulating a two-dimensional heat diffusion will be introduced: matrix multiplication, sparse matrix in JAX, direction operation with numpy, and with jax.\n\n\n\n\n\nN = 101\nepsilon = 0.2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport time\nimport jax\nfrom jax.experimental import sparse\nimport jax.numpy as jnp\nfrom jax import jit\nimport inspect\n\n\n# This is the initial condition\n# Put 1 unit of heat at midpoint\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\nplt.imshow(u0)\n\n\n\n\n\n\n\n\n\n\n\n\nWe will first uses matrix-vector multiplication to simulate the heat diffusion in the 2D space. The vector here is created by flattening the current solution: \\(u_k^{i,j}\\)\nEach iteration of the update is given by:\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\nWe actually view \\(u_k^{i,j}\\) as the element with index N x i + j. The matrix A has the size of N2xN2, without all zeros or all zero columns\n\n#The corresponding matrix A:\nn = N * N\ndiagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\ndiagonals[1][(N-1)::N] = 0\ndiagonals[2][(N-1)::N] = 0\nA = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n\nWe will define a function get_A(N), which takes the value “N” as the argument and returns the corresponding matrix A in heat_equation.py (put the function you defined in a py. file).\n\ndef get_A(N):\n    \"\"\"The function get_A(N) takes the value N as the argument and returns the output matrix A with matrix multiplication\n    \"\"\"\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\nThen with the get_A() and advance_time_matvecmul(), we run the code for 2700 iterations. We introduce time module previously in import libraries to help us obvserve how long does it takes.\n\nu = [u0] # Initialize a list 'u' with the initial grid state 'u0'\n\nA = get_A(N) # # Generate the Matrix A using the function 'get_A' with the grid size 'N'\nstart_time = time.time() # Record the starting time of the simulation\nfor i in range (1,2701): # Loop for 2700 iterations\n    # 'i' takes values from 1 to 2700 (inclusive)\n    u.append(advance_time_matvecmul(A, u[-1], epsilon)) #The updated grid state is appended to the list 'u' using the 'append' method\n\nprint(time.time() - start_time) # Calculate and print the elapsed time\n\n73.26655387878418\n\n\nWe observe this method 1 runs for 73 seconds. One thing for sure: this method runs excruciatingly slow.\nWe still need to visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\n\"\"\"Create a figure and a 3x3 grid of subplots\n'figsize' specifies the width and height of the figure in inches\n\"\"\"\n\naxs = axs.flatten() # Flatten the 2D array of Axes objects into a 1D array\n# This makes it easier to access individual subplots using a single index\nsubplot_index = 0 # Initialize a variable to keep track of the current subplot index\n\nfor i in range(1, 2701):\n    if i % 300 == 0: # Check if the current iteration is divisible by 300\n        axs[subplot_index].imshow(u[i-1]) # Display the grid state at the current iteration minus 1 (u[i-1])\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u[i-1].shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs) # Set the locations of the x-axis ticks for the current subplot\n        axs[subplot_index].set_xticklabels(xtick_labels) # Set the labels for the x-axis ticks of the current subplot\n        axs[subplot_index].set_title(f\"Iteration={i}\")\n        \"\"\"Set the title of the current subplot\n        The title indicates the current iteration number\"\"\"\n        subplot_index += 1 # Increment the subplot index to move to the next subplot\n        if subplot_index &gt;= 9:\n            \"\"\"Check if all 9 subplots have been filled\n            If true, exit the loop using 'break'\"\"\"\n            break\n\nplt.subplots_adjust(wspace=0.3, hspace=0.3) # Adjust the spacing between subplots\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWith a sparsed matrix, matrix multiplication will be much faster since the use of batched coordinate (BCOO) only take O(N^2) time for each update.\nWe will define a function get_sparse_A(N), which returns A_sp_matrix, a matrix A in a sparse format, given N in heat_equation.py. At the same time, we repeate Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul.\n\n# Converting initial condition to JAX array\nu0 = jnp.zeros((N, N)) # Initialize the grid to zero\nu0 = u0.at[int(N/2), int(N/2)].set(1.0) # Set the middle center element to 1.0\n\ndef get_sparse_A(N):\n    \"\"\"Construct the sparse Laplacian matrix for the 2D finite difference grid.\n        N: The size of the grid (N x N).\n        A_sparse: The sparse Laplacian matrix in BCOO format.\n    \"\"\"\n    n = N * N # Total number of grid points\n    \n    # Define the diagonals for the Laplacian matrix\n    diagonals = [-4 * jnp.ones(n), jnp.ones(n-1), jnp.ones(n-1), jnp.ones(n-N), jnp.ones(n-N)]\n    diagonals[1] = diagonals[1].at[(N-1)::N].set(0)\n    diagonals[2] = diagonals[2].at[(N-1)::N].set(0) # Adjust for the grid boundary\n\n    # Use JAX to construct the dense Laplacian matrix and convert to sparse format\n    A_dense = jnp.diag(diagonals[0]) + jnp.diag(diagonals[1], 1) + jnp.diag(diagonals[2], -1) + jnp.diag(diagonals[3], N) + jnp.diag(diagonals[4], -N)\n    A_sparse = sparse.BCOO.fromdense(A_dense) # Convert to sparse BCOO format\n    return A_sparse\n\n@jit\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0] # Extract the grid dimension from the current state\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N)) # Scaled change is added to the current state u to produce the updated state\n    \"\"\"\n    Compute the update for the grid state using matrix-vector multiplication\n    u.flatten(): this converts the 2D array into a 1D array\n    A@u.flatten: @ is the matrix multiplication operator\n    epislon: scales the result of matrix-vector multiplication and subsequent reshaping\n    The result is reshaped back to an N x N grid\n    The scaled change is added to the current state u to produce the updated stat\n    \"\"\"\n    return u\n\nThen with the get_sparse_A() and jit-ed version of advance_time_matvecmul(), we run the code for 2700 iterations. Let’s observe how long does it takes.\n\n# We still introduce time module to help to calculate the elapsed time\nu = [u0]\nA = get_sparse_A(N)\nstart_time = time.time()\nfor i in range (1,2701):\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\nprint(time.time() - start_time) \n\n0.8678162097930908\n\n\nWe observe this method 2 runs for 0.867 seconds! Since method 1 runs for 73 seconds, method 2 is 84 times faster than method 1.\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\n# We still use this way to plot graphs\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u[i-1])\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u[i-1].shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n        axs[subplot_index].set_title(f\"Iteration={i}\")\n        subplot_index += 1\n        if subplot_index &gt;= 9:\n            break\n\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMatrix-vector multiplication approach is not absolutely necessary in terms of computation. With vectorized array operations like np. roll(), the operations could be simpler.\nWe can then write a function advance_time_numpy(u, epsilon) that advances the solution by one timestep. We could pay zeroes to the input array to form an (N+2)x(N=2) array internally, but the argument and the returned solution should still be N x N.\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input grid 'u' via vectorized opertaions,\n    simulating a diffusion process. We use Euler method as the applied update rule.\n    \n    u: The input grid representing the current state of the system.\n    epsilon: The diffusion coefficient controlling the rate of diffusion.\n    u_next: The updated grid after one time step of the diffusion process.\n    \"\"\"\n    N = u.shape[0]  \n    \"\"\"Extract the size of the grid (assuming a square grid)\n    Pad the input array with zeros on all sides for boundary conditions\n    This ensures that the boundary values remain zero during the diffusion process\"\"\"\n    \n    u_padded = np.pad(u, 1, mode='constant', constant_values=0)\n    # Compute the Laplacian of u using vectorized operations\n    laplacian_u = (np.roll(u_padded, 1, axis=0)  # Shift the array one step down\n                   + np.roll(u_padded, -1, axis=0) \n                   + np.roll(u_padded, 1, axis=1) # Shift the array one step to the right\n                   + np.roll(u_padded, -1, axis=1) \n                   -4 * u_padded)[1:-1, 1:-1] # Extract the inner part of the array (excluding the padded boundary)\n    \"\"\" We use np.roll to shift the padded array in four directions (up, down, left, right)\n    and then sum the shifted arrays to compute the Laplacian\"\"\"\n    \n    u_next = u + epsilon * laplacian_u \n    \"\"\" Update the grid \"u\" based on the Laplacian and the diffusion coefficient 'epsilon'\n    The update rule is: u_next = u + epsilon * laplacian_u \"\"\"\n    return u_next\n\nThen with the advance_time_numpy(u,epsilon), we run the code for 2700 iterations. Let’s obvserve how long does it takes.\n\n\nu = u0\nstart_time = time.time()\nfor t in range(1, 2701):\n    u = advance_time_numpy(u, epsilon) # Update the grid state 'u' using the 'advance_time_numpy' function\n    \nprint(time.time() - start_time)\n\n0.21011614799499512\n\n\nIt only takes 0.21 s to run the method 3, method 1 takes 73s, it’s 347x faster than method 1\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nu = u0\nfig, axs = plt.subplots(3, 3, figsize=(9, 9))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n    # Update the grid state 'u' using the 'advance_time_numpy' function\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u)\n        axs[subplot_index].set_title(f\"Iteration {i}\")\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u.shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n\n        subplot_index += 1\n\n        if subplot_index &gt;= 9:\n            break\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nNow, we will use jax to do the similar using just-in-time compilation.\nWe will now define a function advance_time_jax(u, epsilon) but without using (sparse) matrix multiplication routines. It will be simple if we use the function advance_time_numpy() as the starting point. Keep in mind that jax does not support index assignment.”\n\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef advance_time_jax(u, epsilon):\n    \"\"\"\n    Advances the simulation state by one time step using the Laplacian operator and Euler's method.\n    \n    This function computes the Laplacian of the input array 'u' using direct JAX operations for faster execution.\n    It then updates the simulation state based on the computed Laplacian and a given 'epsilon' value, which\n    represents the time step size or the diffusion coefficient.\n\n    \"\"\"\n    N = u.shape[0]\n    \"\"\"Pad the input array with zeros to handle edge conditions\n    The 'mode' argument specifies the padding mode, which is set to 'constant'\n    The 'constant_values' argument specifies the value to be used for padding, which is set to 0.\"\"\"\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values=0)\n\n    # Compute the Laplacian using vectorized operations\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                   jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    \n   # Update the simulation state based on the computed Laplacian and the given 'epsilon' value.\n    u_next = u + epsilon * laplacian_u\n    return u_next\n\nThen with the advance_time_jax(u,epsilon), we run the code for 2700 iterations. Let’s obvserve how long does it takes.\n\nu = u0\nstart_time = time.time()\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)  # Update the grid state 'u' using the 'advance_time_jax' function\nprint(time.time() - start_time)\n\n0.10694193840026855\n\n\nIt only takes 0.10 s to run the method 4. We know method 3 takes 0.21s, method 4 is about 2x faster than method 3.\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nu = u0\nfig, axs = plt.subplots(3, 3, figsize=(9, 9))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon) # # Update the grid state 'u' using the 'advance_time_jax' function\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u)\n        axs[subplot_index].set_title(f\"Iteration {i}\")\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u.shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n\n        num_yticks = 6\n        ytick_locs = np.linspace(0, u.shape[0]-1, num_yticks)\n        ytick_labels = np.linspace(0, 100, num_yticks).astype(int)\n        axs[subplot_index].set_yticks(ytick_locs)\n        axs[subplot_index].set_yticklabels(ytick_labels)\n\n        subplot_index += 1\n\n        if subplot_index &gt;= 9:\n            break\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nNow let’s compare the performances of four models. Let’s summarize which one is fastest, and which one is easier for us to write.\n\n\n\nModel\nTime\n\n\n\n\nModel 1\n73s\n\n\nModel 2\n0.86s\n\n\nModel 3\n0.21s\n\n\nModel 4\n0.10s\n\n\n\nPerformance Comparison: The matrix multiplication approach (Approach 1) is the slowest among the given methods. Using a sparse matrix with JAX (Approach 2) provides a significant speedup, approximately 80 times faster than the matrix multiplication approach. Utilizing np.roll() (Approach 3) simplifies the computation for the CPU by eliminating the heat points around and adding them together, resulting in improved performance compared to the matrix multiplication approach. JAX (Approach 4) generally offers better performance compared to NumPy.\nSpeed of Implementation: Method 4 is the fastest and the most performant\nEase of Implementation: Method one appears to be the easiest to implement since the code is already provided. The other approaches may require additional understanding of sparse matrices, JIT compilation, and vectorized operations.\n\n\n\n\n\n\n\n\nApproach\nPros\nCons\n\n\n\n\n1. Matrix-Vector Multiplication\n- Straightforward implementation- Easy to understand\n- Computationally expensive for large grids due to dense matrix operations\n\n\n2. Sparse Matrix-Vector Multiplication\n- More memory-efficient than dense matrices- Potentially faster for large grids\n- Requires familiarity with sparse matrix operations\n\n\n3. Vectorized Operations (NumPy)\n- Avoids explicit matrix construction- Can be more memory-efficient\n- Requires understanding of array broadcasting and slicing\n\n\n4. Vectorized Operations (JAX)\n- Combines the benefits of vectorized operations with JAX’s JIT compilation for potential performance improvements\n- Requires familiarity with JAX"
  },
  {
    "objectID": "posts/16BHW4/index.html#basic-setting-up",
    "href": "posts/16BHW4/index.html#basic-setting-up",
    "title": "PIC16B HW4",
    "section": "",
    "text": "N = 101\nepsilon = 0.2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport time\nimport jax\nfrom jax.experimental import sparse\nimport jax.numpy as jnp\nfrom jax import jit\nimport inspect\n\n\n# This is the initial condition\n# Put 1 unit of heat at midpoint\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\nplt.imshow(u0)"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-1-simulation-with-matrix-multiplication",
    "href": "posts/16BHW4/index.html#approach-1-simulation-with-matrix-multiplication",
    "title": "PIC16B HW4",
    "section": "",
    "text": "We will first uses matrix-vector multiplication to simulate the heat diffusion in the 2D space. The vector here is created by flattening the current solution: \\(u_k^{i,j}\\)\nEach iteration of the update is given by:\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\nWe actually view \\(u_k^{i,j}\\) as the element with index N x i + j. The matrix A has the size of N2xN2, without all zeros or all zero columns\n\n#The corresponding matrix A:\nn = N * N\ndiagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\ndiagonals[1][(N-1)::N] = 0\ndiagonals[2][(N-1)::N] = 0\nA = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n\nWe will define a function get_A(N), which takes the value “N” as the argument and returns the corresponding matrix A in heat_equation.py (put the function you defined in a py. file).\n\ndef get_A(N):\n    \"\"\"The function get_A(N) takes the value N as the argument and returns the output matrix A with matrix multiplication\n    \"\"\"\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\nThen with the get_A() and advance_time_matvecmul(), we run the code for 2700 iterations. We introduce time module previously in import libraries to help us obvserve how long does it takes.\n\nu = [u0] # Initialize a list 'u' with the initial grid state 'u0'\n\nA = get_A(N) # # Generate the Matrix A using the function 'get_A' with the grid size 'N'\nstart_time = time.time() # Record the starting time of the simulation\nfor i in range (1,2701): # Loop for 2700 iterations\n    # 'i' takes values from 1 to 2700 (inclusive)\n    u.append(advance_time_matvecmul(A, u[-1], epsilon)) #The updated grid state is appended to the list 'u' using the 'append' method\n\nprint(time.time() - start_time) # Calculate and print the elapsed time\n\n73.26655387878418\n\n\nWe observe this method 1 runs for 73 seconds. One thing for sure: this method runs excruciatingly slow.\nWe still need to visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\n\"\"\"Create a figure and a 3x3 grid of subplots\n'figsize' specifies the width and height of the figure in inches\n\"\"\"\n\naxs = axs.flatten() # Flatten the 2D array of Axes objects into a 1D array\n# This makes it easier to access individual subplots using a single index\nsubplot_index = 0 # Initialize a variable to keep track of the current subplot index\n\nfor i in range(1, 2701):\n    if i % 300 == 0: # Check if the current iteration is divisible by 300\n        axs[subplot_index].imshow(u[i-1]) # Display the grid state at the current iteration minus 1 (u[i-1])\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u[i-1].shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs) # Set the locations of the x-axis ticks for the current subplot\n        axs[subplot_index].set_xticklabels(xtick_labels) # Set the labels for the x-axis ticks of the current subplot\n        axs[subplot_index].set_title(f\"Iteration={i}\")\n        \"\"\"Set the title of the current subplot\n        The title indicates the current iteration number\"\"\"\n        subplot_index += 1 # Increment the subplot index to move to the next subplot\n        if subplot_index &gt;= 9:\n            \"\"\"Check if all 9 subplots have been filled\n            If true, exit the loop using 'break'\"\"\"\n            break\n\nplt.subplots_adjust(wspace=0.3, hspace=0.3) # Adjust the spacing between subplots\nplt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-2-sparse-matrix-in-jax",
    "href": "posts/16BHW4/index.html#approach-2-sparse-matrix-in-jax",
    "title": "PIC16B HW4",
    "section": "",
    "text": "With a sparsed matrix, matrix multiplication will be much faster since the use of batched coordinate (BCOO) only take O(N^2) time for each update.\nWe will define a function get_sparse_A(N), which returns A_sp_matrix, a matrix A in a sparse format, given N in heat_equation.py. At the same time, we repeate Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul.\n\n# Converting initial condition to JAX array\nu0 = jnp.zeros((N, N)) # Initialize the grid to zero\nu0 = u0.at[int(N/2), int(N/2)].set(1.0) # Set the middle center element to 1.0\n\ndef get_sparse_A(N):\n    \"\"\"Construct the sparse Laplacian matrix for the 2D finite difference grid.\n        N: The size of the grid (N x N).\n        A_sparse: The sparse Laplacian matrix in BCOO format.\n    \"\"\"\n    n = N * N # Total number of grid points\n    \n    # Define the diagonals for the Laplacian matrix\n    diagonals = [-4 * jnp.ones(n), jnp.ones(n-1), jnp.ones(n-1), jnp.ones(n-N), jnp.ones(n-N)]\n    diagonals[1] = diagonals[1].at[(N-1)::N].set(0)\n    diagonals[2] = diagonals[2].at[(N-1)::N].set(0) # Adjust for the grid boundary\n\n    # Use JAX to construct the dense Laplacian matrix and convert to sparse format\n    A_dense = jnp.diag(diagonals[0]) + jnp.diag(diagonals[1], 1) + jnp.diag(diagonals[2], -1) + jnp.diag(diagonals[3], N) + jnp.diag(diagonals[4], -N)\n    A_sparse = sparse.BCOO.fromdense(A_dense) # Convert to sparse BCOO format\n    return A_sparse\n\n@jit\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0] # Extract the grid dimension from the current state\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N)) # Scaled change is added to the current state u to produce the updated state\n    \"\"\"\n    Compute the update for the grid state using matrix-vector multiplication\n    u.flatten(): this converts the 2D array into a 1D array\n    A@u.flatten: @ is the matrix multiplication operator\n    epislon: scales the result of matrix-vector multiplication and subsequent reshaping\n    The result is reshaped back to an N x N grid\n    The scaled change is added to the current state u to produce the updated stat\n    \"\"\"\n    return u\n\nThen with the get_sparse_A() and jit-ed version of advance_time_matvecmul(), we run the code for 2700 iterations. Let’s observe how long does it takes.\n\n# We still introduce time module to help to calculate the elapsed time\nu = [u0]\nA = get_sparse_A(N)\nstart_time = time.time()\nfor i in range (1,2701):\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\nprint(time.time() - start_time) \n\n0.8678162097930908\n\n\nWe observe this method 2 runs for 0.867 seconds! Since method 1 runs for 73 seconds, method 2 is 84 times faster than method 1.\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\n# We still use this way to plot graphs\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u[i-1])\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u[i-1].shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n        axs[subplot_index].set_title(f\"Iteration={i}\")\n        subplot_index += 1\n        if subplot_index &gt;= 9:\n            break\n\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-3-direct-operation-with-numpy",
    "href": "posts/16BHW4/index.html#approach-3-direct-operation-with-numpy",
    "title": "PIC16B HW4",
    "section": "",
    "text": "Matrix-vector multiplication approach is not absolutely necessary in terms of computation. With vectorized array operations like np. roll(), the operations could be simpler.\nWe can then write a function advance_time_numpy(u, epsilon) that advances the solution by one timestep. We could pay zeroes to the input array to form an (N+2)x(N=2) array internally, but the argument and the returned solution should still be N x N.\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input grid 'u' via vectorized opertaions,\n    simulating a diffusion process. We use Euler method as the applied update rule.\n    \n    u: The input grid representing the current state of the system.\n    epsilon: The diffusion coefficient controlling the rate of diffusion.\n    u_next: The updated grid after one time step of the diffusion process.\n    \"\"\"\n    N = u.shape[0]  \n    \"\"\"Extract the size of the grid (assuming a square grid)\n    Pad the input array with zeros on all sides for boundary conditions\n    This ensures that the boundary values remain zero during the diffusion process\"\"\"\n    \n    u_padded = np.pad(u, 1, mode='constant', constant_values=0)\n    # Compute the Laplacian of u using vectorized operations\n    laplacian_u = (np.roll(u_padded, 1, axis=0)  # Shift the array one step down\n                   + np.roll(u_padded, -1, axis=0) \n                   + np.roll(u_padded, 1, axis=1) # Shift the array one step to the right\n                   + np.roll(u_padded, -1, axis=1) \n                   -4 * u_padded)[1:-1, 1:-1] # Extract the inner part of the array (excluding the padded boundary)\n    \"\"\" We use np.roll to shift the padded array in four directions (up, down, left, right)\n    and then sum the shifted arrays to compute the Laplacian\"\"\"\n    \n    u_next = u + epsilon * laplacian_u \n    \"\"\" Update the grid \"u\" based on the Laplacian and the diffusion coefficient 'epsilon'\n    The update rule is: u_next = u + epsilon * laplacian_u \"\"\"\n    return u_next\n\nThen with the advance_time_numpy(u,epsilon), we run the code for 2700 iterations. Let’s obvserve how long does it takes.\n\n\nu = u0\nstart_time = time.time()\nfor t in range(1, 2701):\n    u = advance_time_numpy(u, epsilon) # Update the grid state 'u' using the 'advance_time_numpy' function\n    \nprint(time.time() - start_time)\n\n0.21011614799499512\n\n\nIt only takes 0.21 s to run the method 3, method 1 takes 73s, it’s 347x faster than method 1\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nu = u0\nfig, axs = plt.subplots(3, 3, figsize=(9, 9))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n    # Update the grid state 'u' using the 'advance_time_numpy' function\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u)\n        axs[subplot_index].set_title(f\"Iteration {i}\")\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u.shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n\n        subplot_index += 1\n\n        if subplot_index &gt;= 9:\n            break\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-4-with-jax",
    "href": "posts/16BHW4/index.html#approach-4-with-jax",
    "title": "PIC16B HW4",
    "section": "",
    "text": "Now, we will use jax to do the similar using just-in-time compilation.\nWe will now define a function advance_time_jax(u, epsilon) but without using (sparse) matrix multiplication routines. It will be simple if we use the function advance_time_numpy() as the starting point. Keep in mind that jax does not support index assignment.”\n\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef advance_time_jax(u, epsilon):\n    \"\"\"\n    Advances the simulation state by one time step using the Laplacian operator and Euler's method.\n    \n    This function computes the Laplacian of the input array 'u' using direct JAX operations for faster execution.\n    It then updates the simulation state based on the computed Laplacian and a given 'epsilon' value, which\n    represents the time step size or the diffusion coefficient.\n\n    \"\"\"\n    N = u.shape[0]\n    \"\"\"Pad the input array with zeros to handle edge conditions\n    The 'mode' argument specifies the padding mode, which is set to 'constant'\n    The 'constant_values' argument specifies the value to be used for padding, which is set to 0.\"\"\"\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values=0)\n\n    # Compute the Laplacian using vectorized operations\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                   jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    \n   # Update the simulation state based on the computed Laplacian and the given 'epsilon' value.\n    u_next = u + epsilon * laplacian_u\n    return u_next\n\nThen with the advance_time_jax(u,epsilon), we run the code for 2700 iterations. Let’s obvserve how long does it takes.\n\nu = u0\nstart_time = time.time()\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)  # Update the grid state 'u' using the 'advance_time_jax' function\nprint(time.time() - start_time)\n\n0.10694193840026855\n\n\nIt only takes 0.10 s to run the method 4. We know method 3 takes 0.21s, method 4 is about 2x faster than method 3.\nNow let’s visualize the diffusion of heat every 300 iterations. We present them in 3 by 3 grid of 2D heat maps\n\nu = u0\nfig, axs = plt.subplots(3, 3, figsize=(9, 9))\naxs = axs.flatten()\nsubplot_index = 0\n\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon) # # Update the grid state 'u' using the 'advance_time_jax' function\n    if i % 300 == 0:\n        axs[subplot_index].imshow(u)\n        axs[subplot_index].set_title(f\"Iteration {i}\")\n\n        num_xticks = 6\n        xtick_locs = np.linspace(0, u.shape[1]-1, num_xticks)\n        xtick_labels = np.linspace(0, 100, num_xticks).astype(int)\n        axs[subplot_index].set_xticks(xtick_locs)\n        axs[subplot_index].set_xticklabels(xtick_labels)\n\n        num_yticks = 6\n        ytick_locs = np.linspace(0, u.shape[0]-1, num_yticks)\n        ytick_labels = np.linspace(0, 100, num_yticks).astype(int)\n        axs[subplot_index].set_yticks(ytick_locs)\n        axs[subplot_index].set_yticklabels(ytick_labels)\n\n        subplot_index += 1\n\n        if subplot_index &gt;= 9:\n            break\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#models-comparison",
    "href": "posts/16BHW4/index.html#models-comparison",
    "title": "PIC16B HW4",
    "section": "",
    "text": "Now let’s compare the performances of four models. Let’s summarize which one is fastest, and which one is easier for us to write.\n\n\n\nModel\nTime\n\n\n\n\nModel 1\n73s\n\n\nModel 2\n0.86s\n\n\nModel 3\n0.21s\n\n\nModel 4\n0.10s\n\n\n\nPerformance Comparison: The matrix multiplication approach (Approach 1) is the slowest among the given methods. Using a sparse matrix with JAX (Approach 2) provides a significant speedup, approximately 80 times faster than the matrix multiplication approach. Utilizing np.roll() (Approach 3) simplifies the computation for the CPU by eliminating the heat points around and adding them together, resulting in improved performance compared to the matrix multiplication approach. JAX (Approach 4) generally offers better performance compared to NumPy.\nSpeed of Implementation: Method 4 is the fastest and the most performant\nEase of Implementation: Method one appears to be the easiest to implement since the code is already provided. The other approaches may require additional understanding of sparse matrices, JIT compilation, and vectorized operations.\n\n\n\n\n\n\n\n\nApproach\nPros\nCons\n\n\n\n\n1. Matrix-Vector Multiplication\n- Straightforward implementation- Easy to understand\n- Computationally expensive for large grids due to dense matrix operations\n\n\n2. Sparse Matrix-Vector Multiplication\n- More memory-efficient than dense matrices- Potentially faster for large grids\n- Requires familiarity with sparse matrix operations\n\n\n3. Vectorized Operations (NumPy)\n- Avoids explicit matrix construction- Can be more memory-efficient\n- Requires understanding of array broadcasting and slicing\n\n\n4. Vectorized Operations (JAX)\n- Combines the benefits of vectorized operations with JAX’s JIT compilation for potential performance improvements\n- Requires familiarity with JAX"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PIC16B",
    "section": "",
    "text": "Part 3: Flask Web App Development for Option Intrinsic Value Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPIC16B HW6\n\n\n\n\n\n\nweek 10\n\n\nhw6\n\n\n\n\n\n\n\n\n\nMar 21, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC16B HW5\n\n\n\n\n\n\nweek 8\n\n\nhw5\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC16B Final Project Report\n\n\n\n\n\n\nfinal project\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nYichen Wang, Xipeng Du, Manshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC16B HW4\n\n\n\n\n\n\nweek 6\n\n\nhw4\n\n\n\n\n\n\n\n\n\nFeb 16, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC16B HW3\n\n\n\n\n\n\nweek 6\n\n\nhw2\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC 16B HW2\n\n\n\n\n\n\nweek 5\n\n\nhw2\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC 16B HW1\n\n\n\n\n\n\nweek 4\n\n\nhw1\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nManshu Huang\n\n\n\n\n\n\nNo matching items"
  }
]