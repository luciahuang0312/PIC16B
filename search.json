[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/16BHW4/index.html",
    "href": "posts/16BHW4/index.html",
    "title": "PIC16B HW4",
    "section": "",
    "text": "In this blog, four approaches of simulating a two-dimensional heat diffusion will be presented: matrix multiplication, sparse matrix in JAX, direction operation with numpy, and with jax.\nThis introductory explanation of the mathematical concept is derived from Professor Ko’s Homework Blog \n\nN = 101 # N is the dimension of the grid\nepsilon = 0.2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n# construct initial condition: 1 unit of heat at midpoint. \n# Initializes a grid for simulation with a single unit of heat placed at the center.\nu0 = np.zeros((N, N)) # u0: ndarray\nu0[int(N/2), int(N/2)] = 1.0\nplt.imshow(u0)\n\n\n\n\n\n\n\n\n\n\nWe will first uses matrix-vector multiplication to simulate the heat diffusion in the 2D space. The vector here is created by flattening the current solution  . Each iteration of the update is given by:\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2. \n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\n\ndef get_A(N): \n    \"\"\"The function get_A(N) takes the value N as the argument and returns the corresponding matrix A\n    \"\"\"\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\n\nu = [u0]\nA = get_A(N) # Generate the Matrix A\n\nfor i in range (1,2701): # Loop for 2700 iterations\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\n\nWe observe the performance of approach 1 is excruciating slow. It takes 55.5s.\n\n# Visualization\nfor i in range (1,2701):\n    if i%300==0: # Check if the current step is a multiple of 300\n        plt.imshow(u[i-1]) # Since the list index starts at 0, we use i-1 to access the ith time step\n        # Plot the solution at this time step using matplotlib's imshow\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“In the previous approach, most operations are wasted for computing zeros. As for Approach 2 , we can use the data structure that exploits a lot of zeros in the matrix A: sparse matrix data structures. There is a experimental sparse matrix support in the JAX package. We can use the batched coordinate (BCOO) format to only use O(N^2) space for the matrix, and only take O(N^2) time for each update. Note that there are several sparse matrix representations for more general sparsity patterns, includin CSR (Compressed Sparse Row), CSC (COmpressed Sparse Column), COO (Coordinate formate), etc.”\nWe will define a function get_sparse_A(N), which returns A_sp_matrix, a matrix A in a sparse format, given N in heat_equation.py. At the same time, we repeate Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul.\n\nimport jax.numpy as jnp\nfrom jax.experimental import sparse\nfrom jax import jit\nimport matplotlib.pyplot as plt\n\nN = 101\nepsilon = 0.2\n\n# Converting initial condition to JAX array\nu0 = jnp.zeros((N, N)) # Initialize the grid to zero\nu0 = u0.at[int(N/2), int(N/2)].set(1.0) # Set the middle center element to 1.0\n\ndef get_sparse_A(N):\n    n = N * N\n    # Define the diagonals for the Laplacian matrix\n    diagonals = [-4 * jnp.ones(n), jnp.ones(n-1), jnp.ones(n-1), jnp.ones(n-N), jnp.ones(n-N)]\n    diagonals[1] = diagonals[1].at[(N-1)::N].set(0)\n    diagonals[2] = diagonals[2].at[(N-1)::N].set(0) # Adjust for the grid boundary\n\n    # Use JAX to construct the dense Laplacian matrix and convert to sparse format\n    A_dense = jnp.diag(diagonals[0]) + jnp.diag(diagonals[1], 1) + jnp.diag(diagonals[2], -1) + jnp.diag(diagonals[3], N) + jnp.diag(diagonals[4], -N)\n    A_sparse = sparse.BCOO.fromdense(A_dense) # Convert to sparse BCOO format\n    return A_sparse\n\n@jit\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2. \n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0] # Extract the grid dimension from the current state\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N)) # Scaled change is added to the current state u to produce the updated state\n    \"\"\"\n    u.flatten(): this converts the 2D array into a 1D array\n    A@u.flatten: @ is the matrix multiplication operator\n    epislon: scales the result of matrix-vector multiplication and subsequent reshaping\n    \"\"\"\n    return u\n\n\n# Repeat Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul\nu = [u0]\nA = get_sparse_A(N)\nfor i in range (1,2701):\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\n\nIn method 2, it only takes 3.8s to run the code for 2700 iterations\n\nfor i in range (1,2701):\n    if i%300==0:\n        plt.imshow(u[i-1]) #the first element is 0 and we want to start at i-1\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe observe that matrix-vector multiplication approach is not absolutely necessary in terms of computation. With vectorized array operations like np. roll(), the operations could be simpler.\nWe can write a function advance_time_numpy(u, epsilon) that advances the solution by one timestep. We could pay zeroes to the input array to form an (N+2)x(N=2) array internally, but the argument and the returned solution should still be N x N.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input grid 'u' via vectorized opertaions, \n    simulating a diffusion process. We use Euler method as the applied update rule.\n    \"\"\"\n    N = u.shape[0] # Extract the size of the grid\n    # Pad the input array with zeros on all sides for boundary conditions\n    u_padded = np.pad(u, 1, mode='constant', constant_values=0)\n    # Compute the Laplacian of u using vectorized operations\n    laplacian_u = (np.roll(u_padded, 1, axis=0) + np.roll(u_padded, -1, axis=0) +\n                   np.roll(u_padded, 1, axis=1) + np.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    # Update the grid 'u' based on the Laplacian and the diffusion coefficient 'epsilon'\n    u_next = u + epsilon * laplacian_u\n    return u_next\n\n\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n\nWe observe Approach 3 only takes 0.2 s to finish.\n\n#Visualization\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n    if i % 300 == 0:\n        plt.imshow(u)\n        plt.title(f\"Iteration {i}\")\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, we will use jax to do the similar using just-in-time compilation.\n“We will define a function advance_time_jax(u, epsilon) without using (sparse) matrix multiplication routines. It will be simple to use the function advance_time_numpy() as the starting point. Keep in mind that jax does not support index assignment.”\n\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef advance_time_jax(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input array 'u' using direct JAX operations for faster execution. \n    It then updates the simulation state based on the coputed Laplacian and a given epsilon. \n    \"\"\"\n    N = u.shape[0]\n    # Pad the input array with zeros to handle edge conditions\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values=0)\n    \n    # Compute the Laplacian using vectorized operations\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                   jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    \n    # Update the solution based on the Laplacian and epsilon\n    \n    u_next = u + epsilon * laplacian_u\n    return u_next\n\nimport matplotlib.pyplot as plt\n\nN = 101\nepsilon = 0.2\nu0 = jnp.zeros((N, N))\nu0 = u0.at[int(N/2), int(N/2)].set(1.0)  # Initial condition\n\n\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)\n\nWe observe appproach 4 only takes 0.1s to finish the operation.\n\n# Visualization\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)\n    if i % 300 == 0:\n        plt.imshow(u)\n        plt.title(f\"Iteration {i}\")\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThank you for reading!"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-1-simulation-with-matrix-multiplication",
    "href": "posts/16BHW4/index.html#approach-1-simulation-with-matrix-multiplication",
    "title": "PIC16B HW4",
    "section": "",
    "text": "We will first uses matrix-vector multiplication to simulate the heat diffusion in the 2D space. The vector here is created by flattening the current solution  . Each iteration of the update is given by:\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2. \n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\n\ndef get_A(N): \n    \"\"\"The function get_A(N) takes the value N as the argument and returns the corresponding matrix A\n    \"\"\"\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\n\nu = [u0]\nA = get_A(N) # Generate the Matrix A\n\nfor i in range (1,2701): # Loop for 2700 iterations\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\n\nWe observe the performance of approach 1 is excruciating slow. It takes 55.5s.\n\n# Visualization\nfor i in range (1,2701):\n    if i%300==0: # Check if the current step is a multiple of 300\n        plt.imshow(u[i-1]) # Since the list index starts at 0, we use i-1 to access the ith time step\n        # Plot the solution at this time step using matplotlib's imshow\n        plt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-2-sparse-matrix-in-jax",
    "href": "posts/16BHW4/index.html#approach-2-sparse-matrix-in-jax",
    "title": "PIC16B HW4",
    "section": "",
    "text": "“In the previous approach, most operations are wasted for computing zeros. As for Approach 2 , we can use the data structure that exploits a lot of zeros in the matrix A: sparse matrix data structures. There is a experimental sparse matrix support in the JAX package. We can use the batched coordinate (BCOO) format to only use O(N^2) space for the matrix, and only take O(N^2) time for each update. Note that there are several sparse matrix representations for more general sparsity patterns, includin CSR (Compressed Sparse Row), CSC (COmpressed Sparse Column), COO (Coordinate formate), etc.”\nWe will define a function get_sparse_A(N), which returns A_sp_matrix, a matrix A in a sparse format, given N in heat_equation.py. At the same time, we repeate Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul.\n\nimport jax.numpy as jnp\nfrom jax.experimental import sparse\nfrom jax import jit\nimport matplotlib.pyplot as plt\n\nN = 101\nepsilon = 0.2\n\n# Converting initial condition to JAX array\nu0 = jnp.zeros((N, N)) # Initialize the grid to zero\nu0 = u0.at[int(N/2), int(N/2)].set(1.0) # Set the middle center element to 1.0\n\ndef get_sparse_A(N):\n    n = N * N\n    # Define the diagonals for the Laplacian matrix\n    diagonals = [-4 * jnp.ones(n), jnp.ones(n-1), jnp.ones(n-1), jnp.ones(n-N), jnp.ones(n-N)]\n    diagonals[1] = diagonals[1].at[(N-1)::N].set(0)\n    diagonals[2] = diagonals[2].at[(N-1)::N].set(0) # Adjust for the grid boundary\n\n    # Use JAX to construct the dense Laplacian matrix and convert to sparse format\n    A_dense = jnp.diag(diagonals[0]) + jnp.diag(diagonals[1], 1) + jnp.diag(diagonals[2], -1) + jnp.diag(diagonals[3], N) + jnp.diag(diagonals[4], -N)\n    A_sparse = sparse.BCOO.fromdense(A_dense) # Convert to sparse BCOO format\n    return A_sparse\n\n@jit\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2. \n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0] # Extract the grid dimension from the current state\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N)) # Scaled change is added to the current state u to produce the updated state\n    \"\"\"\n    u.flatten(): this converts the 2D array into a 1D array\n    A@u.flatten: @ is the matrix multiplication operator\n    epislon: scales the result of matrix-vector multiplication and subsequent reshaping\n    \"\"\"\n    return u\n\n\n# Repeat Part 1 using get_A_sparse() and the jit-ed version of advance_time_matvecmul\nu = [u0]\nA = get_sparse_A(N)\nfor i in range (1,2701):\n    u.append(advance_time_matvecmul(A, u[-1], epsilon))\n\nIn method 2, it only takes 3.8s to run the code for 2700 iterations\n\nfor i in range (1,2701):\n    if i%300==0:\n        plt.imshow(u[i-1]) #the first element is 0 and we want to start at i-1\n        plt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-3-direct-operation-with-numpy",
    "href": "posts/16BHW4/index.html#approach-3-direct-operation-with-numpy",
    "title": "PIC16B HW4",
    "section": "",
    "text": "We observe that matrix-vector multiplication approach is not absolutely necessary in terms of computation. With vectorized array operations like np. roll(), the operations could be simpler.\nWe can write a function advance_time_numpy(u, epsilon) that advances the solution by one timestep. We could pay zeroes to the input array to form an (N+2)x(N=2) array internally, but the argument and the returned solution should still be N x N.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input grid 'u' via vectorized opertaions, \n    simulating a diffusion process. We use Euler method as the applied update rule.\n    \"\"\"\n    N = u.shape[0] # Extract the size of the grid\n    # Pad the input array with zeros on all sides for boundary conditions\n    u_padded = np.pad(u, 1, mode='constant', constant_values=0)\n    # Compute the Laplacian of u using vectorized operations\n    laplacian_u = (np.roll(u_padded, 1, axis=0) + np.roll(u_padded, -1, axis=0) +\n                   np.roll(u_padded, 1, axis=1) + np.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    # Update the grid 'u' based on the Laplacian and the diffusion coefficient 'epsilon'\n    u_next = u + epsilon * laplacian_u\n    return u_next\n\n\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n\nWe observe Approach 3 only takes 0.2 s to finish.\n\n#Visualization\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_numpy(u, epsilon)\n    if i % 300 == 0:\n        plt.imshow(u)\n        plt.title(f\"Iteration {i}\")\n        plt.show()"
  },
  {
    "objectID": "posts/16BHW4/index.html#approach-4-with-jax",
    "href": "posts/16BHW4/index.html#approach-4-with-jax",
    "title": "PIC16B HW4",
    "section": "",
    "text": "Now, we will use jax to do the similar using just-in-time compilation.\n“We will define a function advance_time_jax(u, epsilon) without using (sparse) matrix multiplication routines. It will be simple to use the function advance_time_numpy() as the starting point. Keep in mind that jax does not support index assignment.”\n\nimport jax.numpy as jnp\nfrom jax import jit\n\n@jit\ndef advance_time_jax(u, epsilon):\n    \"\"\"\n    The function computes the Laplacian of the input array 'u' using direct JAX operations for faster execution. \n    It then updates the simulation state based on the coputed Laplacian and a given epsilon. \n    \"\"\"\n    N = u.shape[0]\n    # Pad the input array with zeros to handle edge conditions\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values=0)\n    \n    # Compute the Laplacian using vectorized operations\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                   jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                   4 * u_padded)[1:-1, 1:-1]\n    \n    # Update the solution based on the Laplacian and epsilon\n    \n    u_next = u + epsilon * laplacian_u\n    return u_next\n\nimport matplotlib.pyplot as plt\n\nN = 101\nepsilon = 0.2\nu0 = jnp.zeros((N, N))\nu0 = u0.at[int(N/2), int(N/2)].set(1.0)  # Initial condition\n\n\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)\n\nWe observe appproach 4 only takes 0.1s to finish the operation.\n\n# Visualization\nu = u0\nfor i in range(1, 2701):\n    u = advance_time_jax(u, epsilon)\n    if i % 300 == 0:\n        plt.imshow(u)\n        plt.title(f\"Iteration {i}\")\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThank you for reading!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/16BHW1/index.html",
    "href": "posts/16BHW1/index.html",
    "title": "PIC 16B HW1",
    "section": "",
    "text": "import pandas as pd\n\n# advanced plotting tools for data frames\n# basically a bunch of matplotlib shortcuts\nimport seaborn as sns \n\nfrom matplotlib import pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-1-database-creation",
    "href": "posts/16BHW1/index.html#section-1-database-creation",
    "title": "PIC 16B HW1",
    "section": "Section 1: Database Creation",
    "text": "Section 1: Database Creation\nWe are required to create a database with three tables: temperatures, stations, and countries. We need to know how to access country names and relate them to temperature readings. We also need to keep these as three seperate tables in our database.\nLecture Notes: “Databases provide us with a structured way to move subsets of data from storage into memory. Python has a module called sqlite3 (already installed in PIC16B-24W environment) which we can use to create, manipulate, and query databases. There’s also a very handy pandas interface, enabling us to efficiently create pandas data frames containing exactly the data that we want.”\n\nimport sqlite3\nconn = sqlite3.connect(\"temps.db\")\n\n\ndf = pd.read_csv(\"temps.csv\")\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\ndf.head()\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\n\ndf.shape\n\n(1359937, 14)\n\n\n\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    return(df)\n\n\nData Cleaning\n\ndf = prepare_df(df)\ndf.head()\n\n\n\n\n\n\n\n\nID\nYear\nMonth\nTemp\n\n\n\n\n0\nACW00011604\n1961\n1\n-0.89\n\n\n1\nACW00011604\n1961\n2\n2.36\n\n\n2\nACW00011604\n1961\n3\n4.72\n\n\n3\nACW00011604\n1961\n4\n7.73\n\n\n4\nACW00011604\n1961\n5\n11.28\n\n\n\n\n\n\n\n\n\nAdding Temperatures to Our Database\n\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\nfor i, df in enumerate(df_iter):\n    df = prepare_df(df)\n    df.to_sql(\"temperatures\", conn, if_exists = \"replace\" if i == 0 else \"append\", index = False)\n\n\n\nAdding Stations to Our Database\n\nurl = \"station-metadata.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"stations\", conn, if_exists = \"replace\", index=False)\n\n27585\n\n\n\n\nAdding Countries to Our Database\n\nurl = \"country.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"countries\", conn, if_exists = \"replace\", index=False)\n\n279\n\n\n\ndf = pd.read_csv(\"country.csv\")\ndf = df.rename(columns={'Name': 'Country'})\ndf.to_csv(\"country_modified.csv\", index=False)\n\n\n\nLet’s check our Databse:\n\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\nprint(cursor.fetchall())\n\n[('temperatures',), ('stations',), ('countries',)]\n\n\n\ncursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n\nfor result in cursor.fetchall():\n    print(result[0])\n\nCREATE TABLE \"temperatures\" (\n\"ID\" TEXT,\n  \"Year\" INTEGER,\n  \"Month\" INTEGER,\n  \"Temp\" REAL\n)\nCREATE TABLE \"stations\" (\n\"ID\" TEXT,\n  \"LATITUDE\" REAL,\n  \"LONGITUDE\" REAL,\n  \"STNELEV\" REAL,\n  \"NAME\" TEXT\n)\nCREATE TABLE \"countries\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-2-write-a-query-function",
    "href": "posts/16BHW1/index.html#section-2-write-a-query-function",
    "title": "PIC 16B HW1",
    "section": "Section 2: Write a Query Function",
    "text": "Section 2: Write a Query Function\nIn this section, we need to first write a climate_database.py file with the function query_climate_database() which accepts five arguments: \n1) db_file: the file name for the database 2) country: a string giving the name of a country for which data should be returned 3) year_begin: integer giving the earliest years for which should be returne  4) year_end: integer giving the latest years for which should be returned 5) month: an integer giving the month of the year for which should be returned\nThe return value of query_climate_database() is a Pandas dataframe of temeperature readings for the specified country, in the specified date range,in the specified month of year. We are required to have these columns: NAME, LATITUDE, LONGITUDE, Country, Year, Month, Temp\n\nfrom climate_database import query_climate_database\nimport inspect\nprint(inspect.getsource(query_climate_database))\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    \n    query = '''\n    SELECT S.NAME, S.LATITUDE, S.LONGITUDE, C.Name AS COUNTRY, \n       T.Year AS Year, T.Month AS Month, T.Temp AS Temp\n    FROM temperatures T\n    JOIN stations S ON T.ID=S.ID\n    JOIN countries C ON S.ID=SUBSTR(C.ID, 1, LENGTH(S.ID)) -- Assuming ID matching logic\n    WHERE C.Name = ? AND T.Year BETWEEN ? AND ? AND T.Month = ?\n    ''',\n    (country, year_begin, year_end, month)\n\n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    return df\n\n\n\n\nquery_climate_database(db_file = \"temps.db\",\n                       country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020,\n                       month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nName\nYear\nMonth\nTemp\n\n\n\n\n0\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n4\n-41.08\n\n\n1\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n5\n-48.40\n\n\n2\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n6\n-50.70\n\n\n3\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n7\n-49.14\n\n\n4\nBALDRICK_AWS\n-82.767\n-13.05\nAntarctica\n2008\n10\n-43.66\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8468\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n8\n0.00\n\n\n8469\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n9\n-2.09\n\n\n8470\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n10\n-8.70\n\n\n8471\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n11\n-20.90\n\n\n8472\nVIKTORIYA_ISLAND\n80.167\n36.75\nSvalbard\n1995\n12\n-25.40\n\n\n\n\n8473 rows × 7 columns\n\n\n\n\nANOTHER APPROACH\n\nimport sqlite3\nimport pandas as pd\n\ndb_file = 'temps.db'\n\n\nconn = sqlite3.connect(db_file)\ncursor = conn.cursor()\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS countries (\n    country_id INTEGER PRIMARY KEY,\n    country_name TEXT NOT NULL\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS stations (\n    station_id INTEGER PRIMARY KEY,\n    station_name TEXT NOT NULL,\n    latitude REAL,\n    longitude REAL,\n    country_id INTEGER,\n    FOREIGN KEY (country_id) REFERENCES countries (country_id)\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS temperatures (\n    temperature_id INTEGER PRIMARY KEY,\n    station_id INTEGER,\n    country_id INTEGER,\n    year INTEGER,\n    month INTEGER,\n    temp REAL,\n    FOREIGN KEY (station_id) REFERENCES stations (station_id),\n    FOREIGN KEY (country_id) REFERENCES countries (country_id)\n)\n''')\n\n\nconn.commit()\n\n\ndef load_csv_to_table(csv_file, table_name, conn):\n    df = pd.read_csv(csv_file)\n    df.to_sql(table_name, conn, if_exists='replace', index=False)\n\n\nload_csv_to_table('country.csv', 'countries', conn)\nload_csv_to_table('station-metadata.csv', 'stations', conn)\nload_csv_to_table('temps.csv', 'temperatures', conn)\n\nconn.close()\n\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    \n    temp_column = f'VALUE{month}'\n    \n    query = f'''\n    SELECT st.NAME, st.LATITUDE, st.LONGITUDE, co.Name AS Country, \n           te.Year, {month} AS Month, te.{temp_column} AS Temp\n    FROM temperatures te\n    INNER JOIN stations st ON te.ID = st.ID\n    INNER JOIN countries co ON co.`FIPS 10-4` = SUBSTR(te.ID, 1, 2)\n    WHERE co.`FIPS 10-4` = (SELECT `FIPS 10-4` FROM countries WHERE Name = \"{country}\")\n    AND te.Year BETWEEN {year_begin} AND {year_end}\n    AND te.{temp_column} IS NOT NULL\n    '''\n    \n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    return df\n\n\nquery_climate_database(db_file =\"temps.db\", country =\"India\", year_begin = 1980, year_end = 2020,month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n2348.0\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n2457.0\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n2419.0\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n2351.0\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n2481.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n510.0\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n690.0\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n810.0\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n560.0\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n570.0\n\n\n\n\n3152 rows × 7 columns\n\n\n\nWhich works well."
  },
  {
    "objectID": "posts/16BHW1/index.html#section-3-write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "href": "posts/16BHW1/index.html#section-3-write-a-geographic-scatter-function-for-yearly-temperature-increases",
    "title": "PIC 16B HW1",
    "section": "Section 3: Write A Geographic Scatter Function for Yearly Temperature Increases",
    "text": "Section 3: Write A Geographic Scatter Function for Yearly Temperature Increases\nConsider this question: How does the average yearly change in temperature vary within a given country?\nIn this section, we are going to write a function called temperature_coefficient_plot() to generate an interactive geographic scatterplot, constructing using Plotly Express with a point for each station.\n\nNote: Apply () method can be used\n\n\ndf_countries = pd.read_csv('country.csv')\nprint(df_countries.columns.tolist())\ndf_countries\n\n['FIPS 10-4', 'ISO 3166', 'Name']\n\n\n\n\n\n\n\n\n\nFIPS 10-4\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n...\n...\n...\n...\n\n\n274\n-\n-\nWorld\n\n\n275\nYM\nYE\nYemen\n\n\n276\n-\n-\nZaire\n\n\n277\nZA\nZM\nZambia\n\n\n278\nZI\nZW\nZimbabwe\n\n\n\n\n279 rows × 3 columns\n\n\n\n\ndf_temps = pd.read_csv('temps.csv')\nprint(df_temps.columns.tolist())\ndf_temps.head()\n\n['ID', 'Year', 'VALUE1', 'VALUE2', 'VALUE3', 'VALUE4', 'VALUE5', 'VALUE6', 'VALUE7', 'VALUE8', 'VALUE9', 'VALUE10', 'VALUE11', 'VALUE12']\n\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\n\ndf_stationmetadata = pd.read_csv('station-metadata.csv')\nprint(df_stationmetadata.columns.tolist())\ndf_stationmetadata\n\n['ID', 'LATITUDE', 'LONGITUDE', 'STNELEV', 'NAME']\n\n\n\n\n\n\n\n\n\nID\nLATITUDE\nLONGITUDE\nSTNELEV\nNAME\n\n\n\n\n0\nACW00011604\n57.7667\n11.8667\n18.0\nSAVE\n\n\n1\nAE000041196\n25.3330\n55.5170\n34.0\nSHARJAH_INTER_AIRP\n\n\n2\nAEM00041184\n25.6170\n55.9330\n31.0\nRAS_AL_KHAIMAH_INTE\n\n\n3\nAEM00041194\n25.2550\n55.3640\n10.4\nDUBAI_INTL\n\n\n4\nAEM00041216\n24.4300\n54.4700\n3.0\nABU_DHABI_BATEEN_AIR\n\n\n...\n...\n...\n...\n...\n...\n\n\n27580\nZI000067983\n-20.2000\n32.6160\n1132.0\nCHIPINGE\n\n\n27581\nZI000067991\n-22.2170\n30.0000\n457.0\nBEITBRIDGE\n\n\n27582\nZIXLT371333\n-17.8300\n31.0200\n1471.0\nHARARE_BELVEDERE\n\n\n27583\nZIXLT443557\n-18.9800\n32.4500\n1018.0\nGRAND_REEF\n\n\n27584\nZIXLT622116\n-19.4300\n29.7500\n1411.0\nGWELO\n\n\n\n\n27585 rows × 5 columns\n\n\n\n\nimport pandas as pd\nimport sqlite3\nimport plotly.express as px\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    conn = sqlite3.connect(db_file)\n    \n    country_code_query = f\"SELECT `FIPS 10-4` FROM countries WHERE Name = '{country}'\"\n    country_code = pd.read_sql_query(country_code_query, conn).iloc[0, 0]\n    \n\n    temp_column = f'VALUE{month}'\n    \n\n    query = f'''\n    SELECT st.NAME, st.LATITUDE, st.LONGITUDE, '{country}' AS Country, \n           te.Year, {month} AS Month, te.{temp_column} AS Temp\n    FROM temperatures te\n    INNER JOIN stations st ON te.ID = st.ID\n    WHERE SUBSTR(te.ID, 1, 2) = '{country_code}'\n    AND te.Year BETWEEN {year_begin} AND {year_end}\n    AND te.{temp_column} IS NOT NULL\n    '''\n\n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    \n\n    df = df.groupby('NAME').filter(lambda x: len(x) &gt;= min_obs)\n    \n\n    def calculate_slope(df):\n        if len(df) &lt; min_obs:\n            return np.nan  \n        X = df['Year'].values.reshape(-1, 1)\n        y = df['Temp'].values\n        reg = LinearRegression().fit(X, y)\n        return reg.coef_[0]\n    \n    df['Slope'] = df.groupby('NAME').apply(calculate_slope)\n    \n    df = df.dropna(subset=['Slope'])\n    \n\n    df = df.drop_duplicates(subset=['NAME'])\n    \n\n    fig = px.scatter_mapbox(df, lat=\"LATITUDE\", lon=\"LONGITUDE\", \n                            color=\"Slope\",\n                            size=np.abs(df['Slope']), \n                            **kwargs)\n    \n\n    if 'color_continuous_scale' not in kwargs:\n        fig.update_traces(marker=dict(colorscale='RdYlGn'))\n    \n    fig.update_layout(mapbox_style=\"carto-positron\", mapbox_zoom=2)\n    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n    \n    return fig\n\ncolor_map = px.colors.diverging.RdGy_r\n\n\nfig = temperature_coefficient_plot(\n    db_file=\"climate_data.db\", \n    country=\"India\", \n    year_begin=1980, \n    year_end=2020, \n    month=1, \n    min_obs=10,\n    zoom=3,\n    mapbox_style=\"carto-positron\",\n    color_continuous_scale=color_map)\n\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "posts/16BHW1/index.html#section-4-create-two-more-interesting-figures",
    "href": "posts/16BHW1/index.html#section-4-create-two-more-interesting-figures",
    "title": "PIC 16B HW1",
    "section": "Section 4: Create Two More Interesting Figures",
    "text": "Section 4: Create Two More Interesting Figures\n\nimport plotly\nplotly.__version__\n\n'5.18.0'\n\n\n\nFigure 1\nQuestion Address: How does the elevation above sea level vary with latitude across different geographical locations?\n\nimport pandas as pd\nfilename = \"station-metadata.csv\"\nstations = pd.read_csv(filename)\nstations= stations.dropna(subset = [\"LATITUDE\", \"STNELEV\"])\n\n\nfrom plotly import express as px\n\nfig = px.scatter(data_frame = stations,\n                 x = \"LATITUDE\",\n                 y = \"STNELEV\",\n                 width = 500,\n                 height = 300,\n                )\n\n#reduce whitespace\nfig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n# show the plot\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\npic1.jpg\n\n\nBy plotting latitude against station elevation, researchers can analyze patterns such as:\nAre higher elevations found at specific latitudes? Is there a correlation between latitude and elevation, and is it positive or negative? How does the distribution of elevations vary across different latitudes? Are there any outliers that suggest unique geographical features?\n\n\nFigure 2\nQuestion Address: How do temperature values for January 1961 vary across different IDs (which could represent different locations or stations) in the dataset provided?\n\nimport pandas as pd\nimport plotly.express as px\n\ndef plot_temperature_boxplot_january_1961(csv_filename):\n    df = pd.read_csv(csv_filename)\n    \n    df_january_1961 = df[df['Year'] == 1961][['ID', 'VALUE1']]\n    \n    # Rename 'VALUE1' to 'Temperature' for clarity\n    df_january_1961.rename(columns={'VALUE1': 'Temperature'}, inplace=True)\n    \n    # Create the boxplot\n    fig = px.box(data_frame=df_january_1961,\n                 x=\"ID\",\n                 y=\"Temperature\",\n                 width=500,\n                 height=300)\n\n    # Reduce whitespace\n    fig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n    \n    # Show the plot\n    fig.show()\nplot_temperature_boxplot_january_1961('temps.csv')\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\npic2.jpg\n\n\nBy constructing a boxplot of January temperatures across different locations, researchers can investigate patterns such as:\nWhat is the typical range of temperatures experienced in various locations during January? Are there any locations with particularly high or low median temperatures compared to others? How does the interquartile range (IQR) of temperatures compare among different locations? Are there any anomalies indicating extreme weather events or microclimates in specific locations?"
  },
  {
    "objectID": "posts/16BHW2/index.html",
    "href": "posts/16BHW2/index.html",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In today’s tutorial, we are going to learn how to use webscraping to build a “recommender system”, answering the following questions:  What movie or TV shows share a actor with your favorite movie or show? We assume that if Movie Y has many of the same actors as your favorite Movie X, you might also enjoy Y. To see how we develop a webscraper, please scroll down to section 2.\n\n\n\n\n\nWe need to first choose one favorite movie on TMDB page, here I choose “Harry Potter and the Philosopher’s Stone”, with url: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/\n\n\n\nLet’s “reherse” what our scraper will do; follong these steps: First, we click on the Full Cast & Crew link, which leads us to the page origianl-url/cast (https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/cast) in this case. Second, we click on the portrait of one of the actors, which leads us to a different url, introducing the actor’s acting credit, like this: https://www.themoviedb.org/person/10980-daniel-radcliffe  Finally, we stay in this page, and scroll down to examine the actor’s Acting section, seeing the titles of a few movies and TV shows in this section. Remember our scraper is going to replicate the exact same process: “Staring with your favorite movie, it’s going to look at all the actors in that movie, and then log all the other movies of TV shows they worked on” **Note that it would be agood idea to use the Developer Tools to inspect individual HTML elements and look for patterns among the names you are looking for.\n\n\n\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nUse this code to initialize the project\n\n\n\nAdd the folloing line to the file settings.py to prevent scraper from downloading too much data while you’re still testing.\nCLOSESPIDER_PAGECOUNT = 20\nPS: you will remove this line later! PPS: If you run into 403 Forbidden errors latter, you need to change user agent line in setting.py, one way to change user agent on scrapy shell is\nscrapy shell -s USER_AGENT='Scrapy/2.8.0 (+https://scrapy.org)' https://www.themoviedb.org/...\n\n\n\n\nIn this section, we create a file tmdb_spider.py inside the spiders directory called tmdb_spider.py. Note we will write scraper codes in this file.\n\n# to run \n# scrapy crawl tmdb_spider -o movies.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    # Give a unique identifier for spider name, used to trigger this certain spider from the command line\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n        \"\"\"\n        Initialize the spider instance with a specific movie's subdirectory.\n        This subdirectory is essential for crafting the starting URL from which the spider begins scraping.\n        \n        :param subdir: Subdirectory for the movie on TMDB site, used to build the start URL\n        :param args: Positional arguments\n        :param kwargs: Keyword arguments\n        \"\"\"\n        super(TmdbSpider, self).__init__(*args, **kwargs)\n        # Set the starting URL to scrape based on the provided movie subdirectory.\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\n    def parse(self, response):\n        \"\"\"\n        Parses the main movie page, extracts the from the full cast, and makes a request to that link\n        :param response: The response object containing the content of the movies' main page\n        \"\"\"\n        # Extracts the link to the \"full cast and crew\" page from the main movie page\n        full_cast_link = response.css('p.new_button a::attr(href)').get()\n        if full_cast_link:\n            # If the link is found, make a request to the cast list page\n            yield response.follow(full_cast_link, self.parse_full_credits)\n    \n    def parse_full_credits(self, response):\n        \"\"\"\n        Parses the \"Full Cast & Crew\" page, extracts each individual actor's personal page links, and makes requests to those pages.\n        :param response: contains the content of the \"Full Cast & Crew\" page.\n        \"\"\"\n        # Selects only the first \"panel pad\" section of the page using CSS selectors\n        first_panel_pad = response.xpath('(//section[contains(@class, \"panel\") and contains(@class, \"pad\")])[1]')\n        for actor in first_panel_pad.css('ol.people.credits &gt; li'):\n            # Extracts the individual actor page link，not including crew members\n            actor_page = actor.css('a::attr(href)').get()\n            if actor_page:\n                # Makes a request to the actor's personal page, directing go to its acting role section\n                yield response.follow(actor_page + '?credit_department=Acting', self.parse_actor_page)\n                \n    def parse_actor_page(self, response):\n        \"\"\"\n        Parses the actor's personal page, extracting information about the movies or TV shows the actor has participated in.\n        :param response: The response object containing the content of the actor's personal page. \n        We want only the works listed in \"Acting\" section for the actor page.\n        We need to determine both the name of actor and the name of each movie/show.\n        \"\"\"\n        # Extracts the actor's name\n        actor_name = response.css('h2.title a::text').get()\n        # Directly gets all texts of this structure by using xpath a[@class='tooltip']/bdi\n        movies = response.xpath('//a[@class=\"tooltip\"]/bdi/text()').getall()\n        # Extracts the title of the work\n        for title in movies:\n            # Yields a dictionary (two key-value pairs) containing the actor's name and the title of the work\n            yield {\n                'actor': actor_name,\n                'movie_or_TV_name': title\n            }\n\nAfter successfully build the spider, we can run this command in terminal: \nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone \nWhich run the spider and save a results.csv file with columns for actor names and the movies and TV shows on which they featured in.\nOnce the spider is fully written, we can comment out the line  CLOSESPIDER_PAGECOUNT = 20  in the settings.py file, then run this command in the terminal to generate a results.csv  scrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nThis results.csv will contain columns for actor names and the movies and TV shows on which they featured in.\n\n\n\nIn this section, I will introduce visualization of numbers of shared actors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\ndata=pd.read_csv('results.csv')\nprint(data)\n\n                 actor                    movie_or_TV_name\n0     Daniel Radcliffe  Have I Got a Bit More News for You\n1     Daniel Radcliffe     David Holmes: The Boy Who Lived\n2     Daniel Radcliffe           100 Years of Warner Bros.\n3     Daniel Radcliffe                            Mulligan\n4     Daniel Radcliffe                             Digman!\n...                ...                                 ...\n2956      Rupert Grint                            The View\n2957      Rupert Grint                                GMTV\n2958      Rupert Grint      The Tonight Show with Jay Leno\n2959      Rupert Grint                 An Audience with...\n2960      Rupert Grint                               Today\n\n[2961 rows x 2 columns]\n\n\n\nprint(data.head(35))\n\n               actor                                   movie_or_TV_name\n0   Daniel Radcliffe                 Have I Got a Bit More News for You\n1   Daniel Radcliffe                    David Holmes: The Boy Who Lived\n2   Daniel Radcliffe                          100 Years of Warner Bros.\n3   Daniel Radcliffe                                           Mulligan\n4   Daniel Radcliffe                                            Digman!\n5   Daniel Radcliffe                                     Extrapolations\n6   Daniel Radcliffe                       Weird: The Al Yankovic Story\n7   Daniel Radcliffe                                      The Lost City\n8   Daniel Radcliffe  Harry Potter 20th Anniversary: Return to Hogwarts\n9   Daniel Radcliffe                         (K)nox: The Rob Knox Story\n10  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Music...\n11  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Reverend\n12  Daniel Radcliffe                     Endgame & Rough for Theatre II\n13  Daniel Radcliffe                               Escape from Pretoria\n14  Daniel Radcliffe                                        Guns Akimbo\n15  Daniel Radcliffe                            The Kelly Clarkson Show\n16  Daniel Radcliffe                               Playmobil: The Movie\n17  Daniel Radcliffe                                    Miracle Workers\n18  Daniel Radcliffe                                    Beast of Burden\n19  Daniel Radcliffe                                      2 Dope Queens\n20  Daniel Radcliffe  The Robot Chicken Walking Dead Special: Die wa...\n21  Daniel Radcliffe                                             Jungle\n22  Daniel Radcliffe  National Theatre Live: Rosencrantz & Guildenst...\n23  Daniel Radcliffe                                     Lost in London\n24  Daniel Radcliffe                                           Imperium\n25  Daniel Radcliffe                                     Swiss Army Man\n26  Daniel Radcliffe                                   Now You See Me 2\n27  Daniel Radcliffe                                Victor Frankenstein\n28  Daniel Radcliffe                                   The Gamechangers\n29  Daniel Radcliffe                 The Late Show with Stephen Colbert\n30  Daniel Radcliffe                                         Trainwreck\n31  Daniel Radcliffe                     Tom Felton Meets the Superfans\n32  Daniel Radcliffe                                           Hot Ones\n33  Daniel Radcliffe                                    BoJack Horseman\n34  Daniel Radcliffe                                 Trailblazer Honors\n\n\n\n\"\"\"\nCounts the occurrences of each unique value in the 'actor' column of the dataframe 'data' and returns a Series.\nThe index of the Series will be the actor names, and the values will be the count of movies each actor has appeared in.\n\"\"\"\nactor_counts = data['actor'].value_counts()\n\n\n\n\n\nactor_counts\n\nactor\nJohn Cleese          241\nJohn Hurt            233\nJulie Walters        152\nRobbie Coltrane      150\nLeslie Phillips      134\n                    ... \nBen Borowiecki         2\nEmily Dale             2\nWill Theakston         2\nLeilah Sutherland      1\nSaunders Triplets      1\nName: count, Length: 63, dtype: int64\n\n\n\n\"\"\"\nThis script visualizes the number of movies each actor has appeared in using a bar plot.\n\"\"\"\n\n# Creates a new figure with a specified size.\nplt.figure(figsize=(12,6))\n\n# Creates a bar plot using seaborn. The x-axis represents actors, and the y-axis represents the count of movies.\n# `actor_counts` is assumed to be a pandas Series where the index contains actor names and values represent movie counts.\nsns.barplot(x=actor_counts.index, y=actor_counts.values)\n\n# Rotates the x-axis labels (actor names) by 90 degrees to prevent overlap and improve readability.\nplt.xticks(rotation=90)\n\n# Sets the label for the x-axis as 'Actor'.\nplt.xlabel('Actor')\n\n# Sets the label for the y-axis as 'Movie Count'.\nplt.ylabel('Movie Count')\n\n# Sets the title of the plot as 'Number of Movies for Each Actor'.\nplt.title('Number of Movies for Each Actor')\n\n# Adjusts the layout to make sure everything fits within the figure area without any clipping.\nplt.tight_layout()\n\n# Displays the plot.\nplt.show()"
  },
  {
    "objectID": "posts/16BHW2/index.html#introduction",
    "href": "posts/16BHW2/index.html#introduction",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In today’s tutorial, we are going to learn how to use webscraping to build a “recommender system”, answering the following questions:  What movie or TV shows share a actor with your favorite movie or show? We assume that if Movie Y has many of the same actors as your favorite Movie X, you might also enjoy Y. To see how we develop a webscraper, please scroll down to section 2."
  },
  {
    "objectID": "posts/16BHW2/index.html#setup",
    "href": "posts/16BHW2/index.html#setup",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "We need to first choose one favorite movie on TMDB page, here I choose “Harry Potter and the Philosopher’s Stone”, with url: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/\n\n\n\nLet’s “reherse” what our scraper will do; follong these steps: First, we click on the Full Cast & Crew link, which leads us to the page origianl-url/cast (https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/cast) in this case. Second, we click on the portrait of one of the actors, which leads us to a different url, introducing the actor’s acting credit, like this: https://www.themoviedb.org/person/10980-daniel-radcliffe  Finally, we stay in this page, and scroll down to examine the actor’s Acting section, seeing the titles of a few movies and TV shows in this section. Remember our scraper is going to replicate the exact same process: “Staring with your favorite movie, it’s going to look at all the actors in that movie, and then log all the other movies of TV shows they worked on” **Note that it would be agood idea to use the Developer Tools to inspect individual HTML elements and look for patterns among the names you are looking for.\n\n\n\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nUse this code to initialize the project\n\n\n\nAdd the folloing line to the file settings.py to prevent scraper from downloading too much data while you’re still testing.\nCLOSESPIDER_PAGECOUNT = 20\nPS: you will remove this line later! PPS: If you run into 403 Forbidden errors latter, you need to change user agent line in setting.py, one way to change user agent on scrapy shell is\nscrapy shell -s USER_AGENT='Scrapy/2.8.0 (+https://scrapy.org)' https://www.themoviedb.org/..."
  },
  {
    "objectID": "posts/16BHW2/index.html#write-scraper",
    "href": "posts/16BHW2/index.html#write-scraper",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In this section, we create a file tmdb_spider.py inside the spiders directory called tmdb_spider.py. Note we will write scraper codes in this file.\n\n# to run \n# scrapy crawl tmdb_spider -o movies.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    # Give a unique identifier for spider name, used to trigger this certain spider from the command line\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n        \"\"\"\n        Initialize the spider instance with a specific movie's subdirectory.\n        This subdirectory is essential for crafting the starting URL from which the spider begins scraping.\n        \n        :param subdir: Subdirectory for the movie on TMDB site, used to build the start URL\n        :param args: Positional arguments\n        :param kwargs: Keyword arguments\n        \"\"\"\n        super(TmdbSpider, self).__init__(*args, **kwargs)\n        # Set the starting URL to scrape based on the provided movie subdirectory.\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\n    def parse(self, response):\n        \"\"\"\n        Parses the main movie page, extracts the from the full cast, and makes a request to that link\n        :param response: The response object containing the content of the movies' main page\n        \"\"\"\n        # Extracts the link to the \"full cast and crew\" page from the main movie page\n        full_cast_link = response.css('p.new_button a::attr(href)').get()\n        if full_cast_link:\n            # If the link is found, make a request to the cast list page\n            yield response.follow(full_cast_link, self.parse_full_credits)\n    \n    def parse_full_credits(self, response):\n        \"\"\"\n        Parses the \"Full Cast & Crew\" page, extracts each individual actor's personal page links, and makes requests to those pages.\n        :param response: contains the content of the \"Full Cast & Crew\" page.\n        \"\"\"\n        # Selects only the first \"panel pad\" section of the page using CSS selectors\n        first_panel_pad = response.xpath('(//section[contains(@class, \"panel\") and contains(@class, \"pad\")])[1]')\n        for actor in first_panel_pad.css('ol.people.credits &gt; li'):\n            # Extracts the individual actor page link，not including crew members\n            actor_page = actor.css('a::attr(href)').get()\n            if actor_page:\n                # Makes a request to the actor's personal page, directing go to its acting role section\n                yield response.follow(actor_page + '?credit_department=Acting', self.parse_actor_page)\n                \n    def parse_actor_page(self, response):\n        \"\"\"\n        Parses the actor's personal page, extracting information about the movies or TV shows the actor has participated in.\n        :param response: The response object containing the content of the actor's personal page. \n        We want only the works listed in \"Acting\" section for the actor page.\n        We need to determine both the name of actor and the name of each movie/show.\n        \"\"\"\n        # Extracts the actor's name\n        actor_name = response.css('h2.title a::text').get()\n        # Directly gets all texts of this structure by using xpath a[@class='tooltip']/bdi\n        movies = response.xpath('//a[@class=\"tooltip\"]/bdi/text()').getall()\n        # Extracts the title of the work\n        for title in movies:\n            # Yields a dictionary (two key-value pairs) containing the actor's name and the title of the work\n            yield {\n                'actor': actor_name,\n                'movie_or_TV_name': title\n            }\n\nAfter successfully build the spider, we can run this command in terminal: \nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone \nWhich run the spider and save a results.csv file with columns for actor names and the movies and TV shows on which they featured in.\nOnce the spider is fully written, we can comment out the line  CLOSESPIDER_PAGECOUNT = 20  in the settings.py file, then run this command in the terminal to generate a results.csv  scrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nThis results.csv will contain columns for actor names and the movies and TV shows on which they featured in."
  },
  {
    "objectID": "posts/16BHW2/index.html#make-your-recommendations-visualization",
    "href": "posts/16BHW2/index.html#make-your-recommendations-visualization",
    "title": "PIC 16B HW2",
    "section": "",
    "text": "In this section, I will introduce visualization of numbers of shared actors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\ndata=pd.read_csv('results.csv')\nprint(data)\n\n                 actor                    movie_or_TV_name\n0     Daniel Radcliffe  Have I Got a Bit More News for You\n1     Daniel Radcliffe     David Holmes: The Boy Who Lived\n2     Daniel Radcliffe           100 Years of Warner Bros.\n3     Daniel Radcliffe                            Mulligan\n4     Daniel Radcliffe                             Digman!\n...                ...                                 ...\n2956      Rupert Grint                            The View\n2957      Rupert Grint                                GMTV\n2958      Rupert Grint      The Tonight Show with Jay Leno\n2959      Rupert Grint                 An Audience with...\n2960      Rupert Grint                               Today\n\n[2961 rows x 2 columns]\n\n\n\nprint(data.head(35))\n\n               actor                                   movie_or_TV_name\n0   Daniel Radcliffe                 Have I Got a Bit More News for You\n1   Daniel Radcliffe                    David Holmes: The Boy Who Lived\n2   Daniel Radcliffe                          100 Years of Warner Bros.\n3   Daniel Radcliffe                                           Mulligan\n4   Daniel Radcliffe                                            Digman!\n5   Daniel Radcliffe                                     Extrapolations\n6   Daniel Radcliffe                       Weird: The Al Yankovic Story\n7   Daniel Radcliffe                                      The Lost City\n8   Daniel Radcliffe  Harry Potter 20th Anniversary: Return to Hogwarts\n9   Daniel Radcliffe                         (K)nox: The Rob Knox Story\n10  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Music...\n11  Daniel Radcliffe  Unbreakable Kimmy Schmidt: Kimmy vs. the Reverend\n12  Daniel Radcliffe                     Endgame & Rough for Theatre II\n13  Daniel Radcliffe                               Escape from Pretoria\n14  Daniel Radcliffe                                        Guns Akimbo\n15  Daniel Radcliffe                            The Kelly Clarkson Show\n16  Daniel Radcliffe                               Playmobil: The Movie\n17  Daniel Radcliffe                                    Miracle Workers\n18  Daniel Radcliffe                                    Beast of Burden\n19  Daniel Radcliffe                                      2 Dope Queens\n20  Daniel Radcliffe  The Robot Chicken Walking Dead Special: Die wa...\n21  Daniel Radcliffe                                             Jungle\n22  Daniel Radcliffe  National Theatre Live: Rosencrantz & Guildenst...\n23  Daniel Radcliffe                                     Lost in London\n24  Daniel Radcliffe                                           Imperium\n25  Daniel Radcliffe                                     Swiss Army Man\n26  Daniel Radcliffe                                   Now You See Me 2\n27  Daniel Radcliffe                                Victor Frankenstein\n28  Daniel Radcliffe                                   The Gamechangers\n29  Daniel Radcliffe                 The Late Show with Stephen Colbert\n30  Daniel Radcliffe                                         Trainwreck\n31  Daniel Radcliffe                     Tom Felton Meets the Superfans\n32  Daniel Radcliffe                                           Hot Ones\n33  Daniel Radcliffe                                    BoJack Horseman\n34  Daniel Radcliffe                                 Trailblazer Honors\n\n\n\n\"\"\"\nCounts the occurrences of each unique value in the 'actor' column of the dataframe 'data' and returns a Series.\nThe index of the Series will be the actor names, and the values will be the count of movies each actor has appeared in.\n\"\"\"\nactor_counts = data['actor'].value_counts()\n\n\n\n\n\nactor_counts\n\nactor\nJohn Cleese          241\nJohn Hurt            233\nJulie Walters        152\nRobbie Coltrane      150\nLeslie Phillips      134\n                    ... \nBen Borowiecki         2\nEmily Dale             2\nWill Theakston         2\nLeilah Sutherland      1\nSaunders Triplets      1\nName: count, Length: 63, dtype: int64\n\n\n\n\"\"\"\nThis script visualizes the number of movies each actor has appeared in using a bar plot.\n\"\"\"\n\n# Creates a new figure with a specified size.\nplt.figure(figsize=(12,6))\n\n# Creates a bar plot using seaborn. The x-axis represents actors, and the y-axis represents the count of movies.\n# `actor_counts` is assumed to be a pandas Series where the index contains actor names and values represent movie counts.\nsns.barplot(x=actor_counts.index, y=actor_counts.values)\n\n# Rotates the x-axis labels (actor names) by 90 degrees to prevent overlap and improve readability.\nplt.xticks(rotation=90)\n\n# Sets the label for the x-axis as 'Actor'.\nplt.xlabel('Actor')\n\n# Sets the label for the y-axis as 'Movie Count'.\nplt.ylabel('Movie Count')\n\n# Sets the title of the plot as 'Number of Movies for Each Actor'.\nplt.title('Number of Movies for Each Actor')\n\n# Adjusts the layout to make sure everything fits within the figure area without any clipping.\nplt.tight_layout()\n\n# Displays the plot.\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PIC16B",
    "section": "",
    "text": "PIC16B HW4\n\n\n\n\n\n\nweek 6\n\n\nhw4\n\n\n\n\n\n\n\n\n\nFeb 16, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC 16B HW2\n\n\n\n\n\n\nweek 5\n\n\nhw2\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nPIC 16B HW1\n\n\n\n\n\n\nweek 4\n\n\nhw1\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nManshu Huang\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nManshu Huang\n\n\n\n\n\n\nNo matching items"
  }
]